{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980dab00-9b65-4439-abf4-0b6c47fc9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAFTAR lIBRARY\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import optuna\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, confusion_matrix\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from uuid import uuid4\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c251f67f-09a7-4a5e-9df6-0b201a7e82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('student_monnitoring_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58619fa-b908-4c1b-842e-511598e0ea1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>4.56</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>3.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>3.93</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>9:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>1.30</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.07</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.67</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.99</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>9:00-16:00</td>\n",
       "      <td>Present</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Student ID        Date   Class Time Attendance Status  \\\n",
       "0               1  2024-12-01   9:00-15:00              Late   \n",
       "1               1  2024-12-02   8:00-16:00              Late   \n",
       "2               1  2024-12-03  11:00-14:00              Late   \n",
       "3               1  2024-12-04  11:00-16:00              Late   \n",
       "4               1  2024-12-05   9:00-13:00            Absent   \n",
       "...           ...         ...          ...               ...   \n",
       "14995         500  2024-12-26   9:00-16:00              Late   \n",
       "14996         500  2024-12-27   9:00-15:00            Absent   \n",
       "14997         500  2024-12-28  11:00-14:00            Absent   \n",
       "14998         500  2024-12-29  11:00-14:00              Late   \n",
       "14999         500  2024-12-30   9:00-16:00           Present   \n",
       "\n",
       "       Stress Level (GSR)  Sleep Hours  Anxiety Level  Mood Score Risk Level  \n",
       "0                    0.92          7.6              6           6        Low  \n",
       "1                    1.17          6.0              6           2     Medium  \n",
       "2                    4.56          6.3              4           8       High  \n",
       "3                    3.07          9.0              2          10        Low  \n",
       "4                    3.93          7.4              9           4       High  \n",
       "...                   ...          ...            ...         ...        ...  \n",
       "14995                1.30          7.2              7          10        Low  \n",
       "14996                1.07          7.9              4           6       High  \n",
       "14997                1.67          7.2              3           5       High  \n",
       "14998                0.99          7.2             10           9     Medium  \n",
       "14999                4.50          5.2              1           4       High  \n",
       "\n",
       "[15000 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Student ID          15000 non-null  int64  \n",
      " 1   Date                15000 non-null  object \n",
      " 2   Class Time          15000 non-null  object \n",
      " 3   Attendance Status   15000 non-null  object \n",
      " 4   Stress Level (GSR)  15000 non-null  float64\n",
      " 5   Sleep Hours         15000 non-null  float64\n",
      " 6   Anxiety Level       15000 non-null  int64  \n",
      " 7   Mood Score          15000 non-null  int64  \n",
      " 8   Risk Level          15000 non-null  object \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15000.00000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.50000</td>\n",
       "      <td>2.762538</td>\n",
       "      <td>6.996780</td>\n",
       "      <td>5.546867</td>\n",
       "      <td>5.471533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.34209</td>\n",
       "      <td>1.301927</td>\n",
       "      <td>1.150973</td>\n",
       "      <td>2.870323</td>\n",
       "      <td>2.868984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.75000</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.50000</td>\n",
       "      <td>2.760000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.25000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Student ID  Stress Level (GSR)   Sleep Hours  Anxiety Level  \\\n",
       "count  15000.00000        15000.000000  15000.000000   15000.000000   \n",
       "mean     250.50000            2.762538      6.996780       5.546867   \n",
       "std      144.34209            1.301927      1.150973       2.870323   \n",
       "min        1.00000            0.500000      5.000000       1.000000   \n",
       "25%      125.75000            1.640000      6.000000       3.000000   \n",
       "50%      250.50000            2.760000      7.000000       6.000000   \n",
       "75%      375.25000            3.900000      8.000000       8.000000   \n",
       "max      500.00000            5.000000      9.000000      10.000000   \n",
       "\n",
       "         Mood Score  \n",
       "count  15000.000000  \n",
       "mean       5.471533  \n",
       "std        2.868984  \n",
       "min        1.000000  \n",
       "25%        3.000000  \n",
       "50%        5.000000  \n",
       "75%        8.000000  \n",
       "max       10.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display((df))\n",
    "display(df.info())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c40d633-ff22-4370-be83-12fd9a111fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Missing Value pada setiap kolom:\n",
      "Student ID            0\n",
      "Date                  0\n",
      "Class Time            0\n",
      "Attendance Status     0\n",
      "Stress Level (GSR)    0\n",
      "Sleep Hours           0\n",
      "Anxiety Level         0\n",
      "Mood Score            0\n",
      "Risk Level            0\n",
      "dtype: int64\n",
      "\n",
      "Persentase Missing value pada setiap Kolim:\n",
      "Student ID            0.0\n",
      "Date                  0.0\n",
      "Class Time            0.0\n",
      "Attendance Status     0.0\n",
      "Stress Level (GSR)    0.0\n",
      "Sleep Hours           0.0\n",
      "Anxiety Level         0.0\n",
      "Mood Score            0.0\n",
      "Risk Level            0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Pengecekan Missing value pada setiap kolom\n",
    "missing_values = df.isna().sum()\n",
    "print(\"Jumlah Missing Value pada setiap kolom:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Pengecekan Presentasi Missing value per kolom\n",
    "missing_percentage = (df.isna().sum() / len(df)) * 100\n",
    "print(\"\\nPersentase Missing value pada setiap Kolim:\")\n",
    "print(missing_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9270f3a6-40b0-4555-a6aa-1963266fc757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected by Z-Score:\n",
      "Empty DataFrame\n",
      "Columns: [Student ID, Date, Class Time, Attendance Status, Stress Level (GSR), Sleep Hours, Anxiety Level, Mood Score, Risk Level]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Menghitung Z-Score untuk kolom-kolom numerik\n",
    "import numpy as np\n",
    "z_scores = zscore(df[['Stress Level (GSR)', 'Anxiety Level', 'Mood Score', 'Sleep Hours']])\n",
    "\n",
    "# Menyaring data dengan Z-Score > 3 atau < -3\n",
    "outliers_z = np.where(abs(z_scores) > 3)  # Menemukan posisi outlier berdasarkan Z-Score\n",
    "\n",
    "# Menampilkan data outlier berdasarkan Z-Score\n",
    "outliers_z_data = df.iloc[outliers_z[0]]\n",
    "print(\"Outliers detected by Z-Score:\")\n",
    "print(outliers_z_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fee54b8-9632-4157-b9de-be3f99104d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected by Z-Score per user:\n",
      "Empty DataFrame\n",
      "Columns: [Stress Level (GSR), Anxiety Level, Mood Score, Sleep Hours]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Menghitung Z-Score per user\n",
    "def calculate_zscore_per_user(df, columns):\n",
    "    outliers = []  # Untuk menyimpan hasil outlier per user\n",
    "    for user_id in df['Student ID'].unique():  # Loop melalui setiap user\n",
    "        user_data = df[df['Student ID'] == user_id][columns]\n",
    "        z_scores = zscore(user_data, axis=0)  # Menghitung Z-Score per kolom untuk user tertentu\n",
    "\n",
    "        # Mencari outlier untuk Z-Score > 3 atau < -3\n",
    "        outliers_for_user = user_data[(abs(z_scores) > 3).any(axis=1)]  # Filter baris dengan Z-Score > 3\n",
    "        outliers.append(outliers_for_user)\n",
    "\n",
    "    # Gabungkan semua outliers per user\n",
    "    return pd.concat(outliers)\n",
    "\n",
    "# Tentukan kolom yang ingin dianalisis (kolom numerik)\n",
    "columns_to_check = ['Stress Level (GSR)', 'Anxiety Level', 'Mood Score', 'Sleep Hours']\n",
    "\n",
    "# Temukan outliers untuk seluruh dataset\n",
    "outliers_z_data_per_user = calculate_zscore_per_user(df, columns_to_check)\n",
    "\n",
    "print(\"Outliers detected by Z-Score per user:\")\n",
    "print(outliers_z_data_per_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3249ab6-c8ad-4040-8891-2a05db87991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2024-12-01\n",
      "1   2024-12-02\n",
      "2   2024-12-03\n",
      "3   2024-12-04\n",
      "4   2024-12-05\n",
      "Name: Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Mengonversi kolom 'Date' menjadi format datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df['Date'].head())\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "df = df.sort_values(by=['Student ID', 'Date'])\n",
    "\n",
    "user_day_count = df.groupby('Student ID')['Date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a730061-cd44-418e-918f-b711d40a9256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>4.56</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>3.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>3.93</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late                0.92   \n",
       "1           1 2024-12-02   8:00-16:00              Late                1.17   \n",
       "2           1 2024-12-03  11:00-14:00              Late                4.56   \n",
       "3           1 2024-12-04  11:00-16:00              Late                3.07   \n",
       "4           1 2024-12-05   9:00-13:00            Absent                3.93   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0          7.6              6           6           1    1   \n",
       "1          6.0              6           2           2    2   \n",
       "2          6.3              4           8           0    3   \n",
       "3          9.0              2          10           1    4   \n",
       "4          7.4              9           4           0    5   \n",
       "\n",
       "   Attendance Status (Data)  \n",
       "0                         2  \n",
       "1                         2  \n",
       "2                         2  \n",
       "3                         2  \n",
       "4                         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label Encoding untuk Risk Level\n",
    "le = LabelEncoder()\n",
    "df['Risk Level'] = le.fit_transform(df['Risk Level'])\n",
    "\n",
    "\n",
    "# label Encoder Untuk ateendande Status\n",
    "attendance_mapping = {'Present': 0, 'Absent': 1, 'Late': 2}\n",
    "df['Attendance Status (Data)'] = df['Attendance Status'].map(attendance_mapping)\n",
    "df['Attendance Status (Data)'] = df['Attendance Status (Data)'].astype('Int64')\n",
    "df[['Attendance Status', 'Attendance Status (Data)']].head()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747cef87-3a89-49cc-b44b-761d50b06818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.350341</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late            0.093333   \n",
       "1           1 2024-12-02   8:00-16:00              Late            0.148889   \n",
       "2           1 2024-12-03  11:00-14:00              Late            0.902222   \n",
       "3           1 2024-12-04  11:00-16:00              Late            0.571111   \n",
       "4           1 2024-12-05   9:00-13:00            Absent            0.762222   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0     0.524113       0.555556    0.555556           1    1   \n",
       "1    -0.866061       0.555556    0.111111           2    2   \n",
       "2    -0.605403       0.333333    0.777778           0    3   \n",
       "3     1.740515       0.111111    1.000000           1    4   \n",
       "4     0.350341       0.888889    0.333333           0    5   \n",
       "\n",
       "   Attendance Status (Data)  \n",
       "0                         2  \n",
       "1                         2  \n",
       "2                         2  \n",
       "3                         2  \n",
       "4                         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Memilih kolom untuk Min-Max Scaling dan Standardization\n",
    "cols_min_max = ['Stress Level (GSR)', 'Anxiety Level', 'Mood Score']\n",
    "cols_standardize = ['Sleep Hours']\n",
    "\n",
    "# Membuat objek scaler untuk Min-Max dan Standardization\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Melakukan Min-Max Scaling pada kolom yang dipilih\n",
    "df[cols_min_max] = min_max_scaler.fit_transform(df[cols_min_max])\n",
    "\n",
    "# Melakukan Standardization pada kolom yang dipilih\n",
    "df[cols_standardize] = standard_scaler.fit_transform(df[cols_standardize])\n",
    "\n",
    "# Menampilkan hasil setelah scaling dan standardisasi\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e4bd196-1999-44e5-aef0-c58403f1abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "      <th>lag_1_stress</th>\n",
       "      <th>lag_1_sleep</th>\n",
       "      <th>rolling_mean_stress</th>\n",
       "      <th>rolling_std_stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.381481</td>\n",
       "      <td>0.451829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.350341</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.745185</td>\n",
       "      <td>0.166212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late            0.093333   \n",
       "1           1 2024-12-02   8:00-16:00              Late            0.148889   \n",
       "2           1 2024-12-03  11:00-14:00              Late            0.902222   \n",
       "3           1 2024-12-04  11:00-16:00              Late            0.571111   \n",
       "4           1 2024-12-05   9:00-13:00            Absent            0.762222   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0     0.524113       0.555556    0.555556           1    1   \n",
       "1    -0.866061       0.555556    0.111111           2    2   \n",
       "2    -0.605403       0.333333    0.777778           0    3   \n",
       "3     1.740515       0.111111    1.000000           1    4   \n",
       "4     0.350341       0.888889    0.333333           0    5   \n",
       "\n",
       "   Attendance Status (Data)  lag_1_stress  lag_1_sleep  rolling_mean_stress  \\\n",
       "0                         2           NaN          NaN                  NaN   \n",
       "1                         2      0.093333     0.524113                  NaN   \n",
       "2                         2      0.148889    -0.866061             0.381481   \n",
       "3                         2      0.902222    -0.605403             0.540741   \n",
       "4                         1      0.571111     1.740515             0.745185   \n",
       "\n",
       "   rolling_std_stress  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2            0.451829  \n",
       "3            0.377584  \n",
       "4            0.166212  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lag Features untuk Stress Level (GSR) dan Sleep Hours\n",
    "df['lag_1_stress'] = df.groupby('Student ID')['Stress Level (GSR)'].shift(1)\n",
    "df['lag_1_sleep'] = df.groupby('Student ID')['Sleep Hours'].shift(1)\n",
    "\n",
    "# Rolling Statistics untuk Stress Level (GSR) dengan window size 3 (misalnya 3 hari)\n",
    "df['rolling_mean_stress'] = df.groupby('Student ID')['Stress Level (GSR)'].rolling(window=3).mean().reset_index(0, drop=True)\n",
    "df['rolling_std_stress'] = df.groupby('Student ID')['Stress Level (GSR)'].rolling(window=3).std().reset_index(0, drop=True)\n",
    "\n",
    "# Menampilkan hasil setelah menambahkan lag features dan rolling statistics\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386eff1c-c31b-4de6-89fd-b7cd9136bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_7948\\23598078.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  p_values = df.groupby('Student ID').apply(lambda group: check_stationarity(group, 'Stress Level (GSR)'))\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Fungsi untuk uji ADF pada setiap Student ID\n",
    "def check_stationarity(data, col):\n",
    "    result = adfuller(df[col].dropna())\n",
    "    return result[1]  # Mengembalikan p-value\n",
    "\n",
    "# Menguji stasioneritas untuk setiap Student ID\n",
    "p_values = df.groupby('Student ID').apply(lambda group: check_stationarity(group, 'Stress Level (GSR)'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b90567-b7e9-46f7-90f9-1996f155f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HASIL UJI STASIONERITAS =====\n",
      "Student ID yang STASIONER:\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]\n",
      "\n",
      "Student ID yang BELUM STASIONER:\n",
      "[6, 456]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fungsi untuk mengecek stasioneritas\n",
    "def check_stationarity(data, col):\n",
    "    result = adfuller(data[col].dropna())\n",
    "    return result[1]  # Mengembalikan p-value\n",
    "\n",
    "# Fungsi untuk melakukan differencing\n",
    "def difference_data(data, col, d=1):\n",
    "    data_copy = data.copy()\n",
    "    for _ in range(d):\n",
    "        data_copy[col] = data_copy[col].diff()\n",
    "    return data_copy\n",
    "\n",
    "# Inisialisasi variabel\n",
    "stationary_ids = []\n",
    "non_stationary_ids = []\n",
    "p_values_initial = {}\n",
    "p_values_after_diff = {}\n",
    "df_processed = []\n",
    "\n",
    "# Loop per Student ID\n",
    "for student_id in df['Student ID'].unique():\n",
    "    data_sub = df[df['Student ID'] == student_id].copy()\n",
    "\n",
    "    # Cek stasioneritas awal\n",
    "    p_value = check_stationarity(data_sub, 'Stress Level (GSR)')\n",
    "    p_values_initial[student_id] = p_value\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        # Sudah stasioner\n",
    "        stationary_ids.append(student_id)\n",
    "        p_values_after_diff[student_id] = p_value\n",
    "    else:\n",
    "        # Belum stasioner, lakukan differencing pertama\n",
    "        data_sub = difference_data(data_sub, 'Stress Level (GSR)', d=1)\n",
    "        p_value = check_stationarity(data_sub, 'Stress Level (GSR)')\n",
    "        p_values_after_diff[student_id] = p_value\n",
    "\n",
    "        if p_value <= 0.05:\n",
    "            stationary_ids.append(student_id)\n",
    "        else:\n",
    "            # Lakukan differencing kedua\n",
    "            data_sub = difference_data(data_sub, 'Stress Level (GSR)', d=2)\n",
    "            p_value = check_stationarity(data_sub, 'Stress Level (GSR)')\n",
    "            p_values_after_diff[student_id] = p_value\n",
    "\n",
    "            if p_value <= 0.05:\n",
    "                stationary_ids.append(student_id)\n",
    "            else:\n",
    "                non_stationary_ids.append(student_id)\n",
    "\n",
    "    df_processed.append(data_sub)\n",
    "\n",
    "# Tampilkan daftar hasil akhir\n",
    "print(\"\\n===== HASIL UJI STASIONERITAS =====\")\n",
    "print(\"Student ID yang STASIONER:\")\n",
    "print(stationary_ids)\n",
    "\n",
    "print(\"\\nStudent ID yang BELUM STASIONER:\")\n",
    "print(non_stationary_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3058516e-9d11-4fd8-a631-5d040e0b3288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "      <th>lag_1_stress</th>\n",
       "      <th>lag_1_sleep</th>\n",
       "      <th>rolling_mean_stress</th>\n",
       "      <th>rolling_std_stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.381481</td>\n",
       "      <td>0.451829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.350341</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.745185</td>\n",
       "      <td>0.166212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late            0.093333   \n",
       "1           1 2024-12-02   8:00-16:00              Late            0.148889   \n",
       "2           1 2024-12-03  11:00-14:00              Late            0.902222   \n",
       "3           1 2024-12-04  11:00-16:00              Late            0.571111   \n",
       "4           1 2024-12-05   9:00-13:00            Absent            0.762222   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0     0.524113       0.555556    0.555556           1    1   \n",
       "1    -0.866061       0.555556    0.111111           2    2   \n",
       "2    -0.605403       0.333333    0.777778           0    3   \n",
       "3     1.740515       0.111111    1.000000           1    4   \n",
       "4     0.350341       0.888889    0.333333           0    5   \n",
       "\n",
       "   Attendance Status (Data)  lag_1_stress  lag_1_sleep  rolling_mean_stress  \\\n",
       "0                         2           NaN          NaN                  NaN   \n",
       "1                         2      0.093333     0.524113                  NaN   \n",
       "2                         2      0.148889    -0.866061             0.381481   \n",
       "3                         2      0.902222    -0.605403             0.540741   \n",
       "4                         1      0.571111     1.740515             0.745185   \n",
       "\n",
       "   rolling_std_stress  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2            0.451829  \n",
       "3            0.377584  \n",
       "4            0.166212  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menggunakan interpolasi linear untuk mengisi NaN setelah differencing\n",
    "df[['Stress Level (GSR)', 'Sleep Hours', 'Anxiety Level', 'Mood Score',\n",
    "      'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']] = \\\n",
    "    df[['Stress Level (GSR)', 'Sleep Hours', 'Anxiety Level', 'Mood Score',\n",
    "          'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']].interpolate(method='linear')\n",
    "\n",
    "# Menampilkan data setelah interpolasi\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6dfb4b3-b100-4007-b21a-87b9d7ac0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== JUMLAH OBSERVASI PER STUDENT ID =====\n",
      "Student ID 1: 30 observasi\n",
      "Student ID 2: 30 observasi\n",
      "Student ID 3: 30 observasi\n",
      "Student ID 4: 30 observasi\n",
      "Student ID 5: 30 observasi\n",
      "Student ID 6: 30 observasi\n",
      "Student ID 7: 30 observasi\n",
      "Student ID 8: 30 observasi\n",
      "Student ID 9: 30 observasi\n",
      "Student ID 10: 30 observasi\n",
      "Student ID 11: 30 observasi\n",
      "Student ID 12: 30 observasi\n",
      "Student ID 13: 30 observasi\n",
      "Student ID 14: 30 observasi\n",
      "Student ID 15: 30 observasi\n",
      "Student ID 16: 30 observasi\n",
      "Student ID 17: 30 observasi\n",
      "Student ID 18: 30 observasi\n",
      "Student ID 19: 30 observasi\n",
      "Student ID 20: 30 observasi\n",
      "Student ID 21: 30 observasi\n",
      "Student ID 22: 30 observasi\n",
      "Student ID 23: 30 observasi\n",
      "Student ID 24: 30 observasi\n",
      "Student ID 25: 30 observasi\n",
      "Student ID 26: 30 observasi\n",
      "Student ID 27: 30 observasi\n",
      "Student ID 28: 30 observasi\n",
      "Student ID 29: 30 observasi\n",
      "Student ID 30: 30 observasi\n",
      "Student ID 31: 30 observasi\n",
      "Student ID 32: 30 observasi\n",
      "Student ID 33: 30 observasi\n",
      "Student ID 34: 30 observasi\n",
      "Student ID 35: 30 observasi\n",
      "Student ID 36: 30 observasi\n",
      "Student ID 37: 30 observasi\n",
      "Student ID 38: 30 observasi\n",
      "Student ID 39: 30 observasi\n",
      "Student ID 40: 30 observasi\n",
      "Student ID 41: 30 observasi\n",
      "Student ID 42: 30 observasi\n",
      "Student ID 43: 30 observasi\n",
      "Student ID 44: 30 observasi\n",
      "Student ID 45: 30 observasi\n",
      "Student ID 46: 30 observasi\n",
      "Student ID 47: 30 observasi\n",
      "Student ID 48: 30 observasi\n",
      "Student ID 49: 30 observasi\n",
      "Student ID 50: 30 observasi\n",
      "Student ID 51: 30 observasi\n",
      "Student ID 52: 30 observasi\n",
      "Student ID 53: 30 observasi\n",
      "Student ID 54: 30 observasi\n",
      "Student ID 55: 30 observasi\n",
      "Student ID 56: 30 observasi\n",
      "Student ID 57: 30 observasi\n",
      "Student ID 58: 30 observasi\n",
      "Student ID 59: 30 observasi\n",
      "Student ID 60: 30 observasi\n",
      "Student ID 61: 30 observasi\n",
      "Student ID 62: 30 observasi\n",
      "Student ID 63: 30 observasi\n",
      "Student ID 64: 30 observasi\n",
      "Student ID 65: 30 observasi\n",
      "Student ID 66: 30 observasi\n",
      "Student ID 67: 30 observasi\n",
      "Student ID 68: 30 observasi\n",
      "Student ID 69: 30 observasi\n",
      "Student ID 70: 30 observasi\n",
      "Student ID 71: 30 observasi\n",
      "Student ID 72: 30 observasi\n",
      "Student ID 73: 30 observasi\n",
      "Student ID 74: 30 observasi\n",
      "Student ID 75: 30 observasi\n",
      "Student ID 76: 30 observasi\n",
      "Student ID 77: 30 observasi\n",
      "Student ID 78: 30 observasi\n",
      "Student ID 79: 30 observasi\n",
      "Student ID 80: 30 observasi\n",
      "Student ID 81: 30 observasi\n",
      "Student ID 82: 30 observasi\n",
      "Student ID 83: 30 observasi\n",
      "Student ID 84: 30 observasi\n",
      "Student ID 85: 30 observasi\n",
      "Student ID 86: 30 observasi\n",
      "Student ID 87: 30 observasi\n",
      "Student ID 88: 30 observasi\n",
      "Student ID 89: 30 observasi\n",
      "Student ID 90: 30 observasi\n",
      "Student ID 91: 30 observasi\n",
      "Student ID 92: 30 observasi\n",
      "Student ID 93: 30 observasi\n",
      "Student ID 94: 30 observasi\n",
      "Student ID 95: 30 observasi\n",
      "Student ID 96: 30 observasi\n",
      "Student ID 97: 30 observasi\n",
      "Student ID 98: 30 observasi\n",
      "Student ID 99: 30 observasi\n",
      "Student ID 100: 30 observasi\n",
      "Student ID 101: 30 observasi\n",
      "Student ID 102: 30 observasi\n",
      "Student ID 103: 30 observasi\n",
      "Student ID 104: 30 observasi\n",
      "Student ID 105: 30 observasi\n",
      "Student ID 106: 30 observasi\n",
      "Student ID 107: 30 observasi\n",
      "Student ID 108: 30 observasi\n",
      "Student ID 109: 30 observasi\n",
      "Student ID 110: 30 observasi\n",
      "Student ID 111: 30 observasi\n",
      "Student ID 112: 30 observasi\n",
      "Student ID 113: 30 observasi\n",
      "Student ID 114: 30 observasi\n",
      "Student ID 115: 30 observasi\n",
      "Student ID 116: 30 observasi\n",
      "Student ID 117: 30 observasi\n",
      "Student ID 118: 30 observasi\n",
      "Student ID 119: 30 observasi\n",
      "Student ID 120: 30 observasi\n",
      "Student ID 121: 30 observasi\n",
      "Student ID 122: 30 observasi\n",
      "Student ID 123: 30 observasi\n",
      "Student ID 124: 30 observasi\n",
      "Student ID 125: 30 observasi\n",
      "Student ID 126: 30 observasi\n",
      "Student ID 127: 30 observasi\n",
      "Student ID 128: 30 observasi\n",
      "Student ID 129: 30 observasi\n",
      "Student ID 130: 30 observasi\n",
      "Student ID 131: 30 observasi\n",
      "Student ID 132: 30 observasi\n",
      "Student ID 133: 30 observasi\n",
      "Student ID 134: 30 observasi\n",
      "Student ID 135: 30 observasi\n",
      "Student ID 136: 30 observasi\n",
      "Student ID 137: 30 observasi\n",
      "Student ID 138: 30 observasi\n",
      "Student ID 139: 30 observasi\n",
      "Student ID 140: 30 observasi\n",
      "Student ID 141: 30 observasi\n",
      "Student ID 142: 30 observasi\n",
      "Student ID 143: 30 observasi\n",
      "Student ID 144: 30 observasi\n",
      "Student ID 145: 30 observasi\n",
      "Student ID 146: 30 observasi\n",
      "Student ID 147: 30 observasi\n",
      "Student ID 148: 30 observasi\n",
      "Student ID 149: 30 observasi\n",
      "Student ID 150: 30 observasi\n",
      "Student ID 151: 30 observasi\n",
      "Student ID 152: 30 observasi\n",
      "Student ID 153: 30 observasi\n",
      "Student ID 154: 30 observasi\n",
      "Student ID 155: 30 observasi\n",
      "Student ID 156: 30 observasi\n",
      "Student ID 157: 30 observasi\n",
      "Student ID 158: 30 observasi\n",
      "Student ID 159: 30 observasi\n",
      "Student ID 160: 30 observasi\n",
      "Student ID 161: 30 observasi\n",
      "Student ID 162: 30 observasi\n",
      "Student ID 163: 30 observasi\n",
      "Student ID 164: 30 observasi\n",
      "Student ID 165: 30 observasi\n",
      "Student ID 166: 30 observasi\n",
      "Student ID 167: 30 observasi\n",
      "Student ID 168: 30 observasi\n",
      "Student ID 169: 30 observasi\n",
      "Student ID 170: 30 observasi\n",
      "Student ID 171: 30 observasi\n",
      "Student ID 172: 30 observasi\n",
      "Student ID 173: 30 observasi\n",
      "Student ID 174: 30 observasi\n",
      "Student ID 175: 30 observasi\n",
      "Student ID 176: 30 observasi\n",
      "Student ID 177: 30 observasi\n",
      "Student ID 178: 30 observasi\n",
      "Student ID 179: 30 observasi\n",
      "Student ID 180: 30 observasi\n",
      "Student ID 181: 30 observasi\n",
      "Student ID 182: 30 observasi\n",
      "Student ID 183: 30 observasi\n",
      "Student ID 184: 30 observasi\n",
      "Student ID 185: 30 observasi\n",
      "Student ID 186: 30 observasi\n",
      "Student ID 187: 30 observasi\n",
      "Student ID 188: 30 observasi\n",
      "Student ID 189: 30 observasi\n",
      "Student ID 190: 30 observasi\n",
      "Student ID 191: 30 observasi\n",
      "Student ID 192: 30 observasi\n",
      "Student ID 193: 30 observasi\n",
      "Student ID 194: 30 observasi\n",
      "Student ID 195: 30 observasi\n",
      "Student ID 196: 30 observasi\n",
      "Student ID 197: 30 observasi\n",
      "Student ID 198: 30 observasi\n",
      "Student ID 199: 30 observasi\n",
      "Student ID 200: 30 observasi\n",
      "Student ID 201: 30 observasi\n",
      "Student ID 202: 30 observasi\n",
      "Student ID 203: 30 observasi\n",
      "Student ID 204: 30 observasi\n",
      "Student ID 205: 30 observasi\n",
      "Student ID 206: 30 observasi\n",
      "Student ID 207: 30 observasi\n",
      "Student ID 208: 30 observasi\n",
      "Student ID 209: 30 observasi\n",
      "Student ID 210: 30 observasi\n",
      "Student ID 211: 30 observasi\n",
      "Student ID 212: 30 observasi\n",
      "Student ID 213: 30 observasi\n",
      "Student ID 214: 30 observasi\n",
      "Student ID 215: 30 observasi\n",
      "Student ID 216: 30 observasi\n",
      "Student ID 217: 30 observasi\n",
      "Student ID 218: 30 observasi\n",
      "Student ID 219: 30 observasi\n",
      "Student ID 220: 30 observasi\n",
      "Student ID 221: 30 observasi\n",
      "Student ID 222: 30 observasi\n",
      "Student ID 223: 30 observasi\n",
      "Student ID 224: 30 observasi\n",
      "Student ID 225: 30 observasi\n",
      "Student ID 226: 30 observasi\n",
      "Student ID 227: 30 observasi\n",
      "Student ID 228: 30 observasi\n",
      "Student ID 229: 30 observasi\n",
      "Student ID 230: 30 observasi\n",
      "Student ID 231: 30 observasi\n",
      "Student ID 232: 30 observasi\n",
      "Student ID 233: 30 observasi\n",
      "Student ID 234: 30 observasi\n",
      "Student ID 235: 30 observasi\n",
      "Student ID 236: 30 observasi\n",
      "Student ID 237: 30 observasi\n",
      "Student ID 238: 30 observasi\n",
      "Student ID 239: 30 observasi\n",
      "Student ID 240: 30 observasi\n",
      "Student ID 241: 30 observasi\n",
      "Student ID 242: 30 observasi\n",
      "Student ID 243: 30 observasi\n",
      "Student ID 244: 30 observasi\n",
      "Student ID 245: 30 observasi\n",
      "Student ID 246: 30 observasi\n",
      "Student ID 247: 30 observasi\n",
      "Student ID 248: 30 observasi\n",
      "Student ID 249: 30 observasi\n",
      "Student ID 250: 30 observasi\n",
      "Student ID 251: 30 observasi\n",
      "Student ID 252: 30 observasi\n",
      "Student ID 253: 30 observasi\n",
      "Student ID 254: 30 observasi\n",
      "Student ID 255: 30 observasi\n",
      "Student ID 256: 30 observasi\n",
      "Student ID 257: 30 observasi\n",
      "Student ID 258: 30 observasi\n",
      "Student ID 259: 30 observasi\n",
      "Student ID 260: 30 observasi\n",
      "Student ID 261: 30 observasi\n",
      "Student ID 262: 30 observasi\n",
      "Student ID 263: 30 observasi\n",
      "Student ID 264: 30 observasi\n",
      "Student ID 265: 30 observasi\n",
      "Student ID 266: 30 observasi\n",
      "Student ID 267: 30 observasi\n",
      "Student ID 268: 30 observasi\n",
      "Student ID 269: 30 observasi\n",
      "Student ID 270: 30 observasi\n",
      "Student ID 271: 30 observasi\n",
      "Student ID 272: 30 observasi\n",
      "Student ID 273: 30 observasi\n",
      "Student ID 274: 30 observasi\n",
      "Student ID 275: 30 observasi\n",
      "Student ID 276: 30 observasi\n",
      "Student ID 277: 30 observasi\n",
      "Student ID 278: 30 observasi\n",
      "Student ID 279: 30 observasi\n",
      "Student ID 280: 30 observasi\n",
      "Student ID 281: 30 observasi\n",
      "Student ID 282: 30 observasi\n",
      "Student ID 283: 30 observasi\n",
      "Student ID 284: 30 observasi\n",
      "Student ID 285: 30 observasi\n",
      "Student ID 286: 30 observasi\n",
      "Student ID 287: 30 observasi\n",
      "Student ID 288: 30 observasi\n",
      "Student ID 289: 30 observasi\n",
      "Student ID 290: 30 observasi\n",
      "Student ID 291: 30 observasi\n",
      "Student ID 292: 30 observasi\n",
      "Student ID 293: 30 observasi\n",
      "Student ID 294: 30 observasi\n",
      "Student ID 295: 30 observasi\n",
      "Student ID 296: 30 observasi\n",
      "Student ID 297: 30 observasi\n",
      "Student ID 298: 30 observasi\n",
      "Student ID 299: 30 observasi\n",
      "Student ID 300: 30 observasi\n",
      "Student ID 301: 30 observasi\n",
      "Student ID 302: 30 observasi\n",
      "Student ID 303: 30 observasi\n",
      "Student ID 304: 30 observasi\n",
      "Student ID 305: 30 observasi\n",
      "Student ID 306: 30 observasi\n",
      "Student ID 307: 30 observasi\n",
      "Student ID 308: 30 observasi\n",
      "Student ID 309: 30 observasi\n",
      "Student ID 310: 30 observasi\n",
      "Student ID 311: 30 observasi\n",
      "Student ID 312: 30 observasi\n",
      "Student ID 313: 30 observasi\n",
      "Student ID 314: 30 observasi\n",
      "Student ID 315: 30 observasi\n",
      "Student ID 316: 30 observasi\n",
      "Student ID 317: 30 observasi\n",
      "Student ID 318: 30 observasi\n",
      "Student ID 319: 30 observasi\n",
      "Student ID 320: 30 observasi\n",
      "Student ID 321: 30 observasi\n",
      "Student ID 322: 30 observasi\n",
      "Student ID 323: 30 observasi\n",
      "Student ID 324: 30 observasi\n",
      "Student ID 325: 30 observasi\n",
      "Student ID 326: 30 observasi\n",
      "Student ID 327: 30 observasi\n",
      "Student ID 328: 30 observasi\n",
      "Student ID 329: 30 observasi\n",
      "Student ID 330: 30 observasi\n",
      "Student ID 331: 30 observasi\n",
      "Student ID 332: 30 observasi\n",
      "Student ID 333: 30 observasi\n",
      "Student ID 334: 30 observasi\n",
      "Student ID 335: 30 observasi\n",
      "Student ID 336: 30 observasi\n",
      "Student ID 337: 30 observasi\n",
      "Student ID 338: 30 observasi\n",
      "Student ID 339: 30 observasi\n",
      "Student ID 340: 30 observasi\n",
      "Student ID 341: 30 observasi\n",
      "Student ID 342: 30 observasi\n",
      "Student ID 343: 30 observasi\n",
      "Student ID 344: 30 observasi\n",
      "Student ID 345: 30 observasi\n",
      "Student ID 346: 30 observasi\n",
      "Student ID 347: 30 observasi\n",
      "Student ID 348: 30 observasi\n",
      "Student ID 349: 30 observasi\n",
      "Student ID 350: 30 observasi\n",
      "Student ID 351: 30 observasi\n",
      "Student ID 352: 30 observasi\n",
      "Student ID 353: 30 observasi\n",
      "Student ID 354: 30 observasi\n",
      "Student ID 355: 30 observasi\n",
      "Student ID 356: 30 observasi\n",
      "Student ID 357: 30 observasi\n",
      "Student ID 358: 30 observasi\n",
      "Student ID 359: 30 observasi\n",
      "Student ID 360: 30 observasi\n",
      "Student ID 361: 30 observasi\n",
      "Student ID 362: 30 observasi\n",
      "Student ID 363: 30 observasi\n",
      "Student ID 364: 30 observasi\n",
      "Student ID 365: 30 observasi\n",
      "Student ID 366: 30 observasi\n",
      "Student ID 367: 30 observasi\n",
      "Student ID 368: 30 observasi\n",
      "Student ID 369: 30 observasi\n",
      "Student ID 370: 30 observasi\n",
      "Student ID 371: 30 observasi\n",
      "Student ID 372: 30 observasi\n",
      "Student ID 373: 30 observasi\n",
      "Student ID 374: 30 observasi\n",
      "Student ID 375: 30 observasi\n",
      "Student ID 376: 30 observasi\n",
      "Student ID 377: 30 observasi\n",
      "Student ID 378: 30 observasi\n",
      "Student ID 379: 30 observasi\n",
      "Student ID 380: 30 observasi\n",
      "Student ID 381: 30 observasi\n",
      "Student ID 382: 30 observasi\n",
      "Student ID 383: 30 observasi\n",
      "Student ID 384: 30 observasi\n",
      "Student ID 385: 30 observasi\n",
      "Student ID 386: 30 observasi\n",
      "Student ID 387: 30 observasi\n",
      "Student ID 388: 30 observasi\n",
      "Student ID 389: 30 observasi\n",
      "Student ID 390: 30 observasi\n",
      "Student ID 391: 30 observasi\n",
      "Student ID 392: 30 observasi\n",
      "Student ID 393: 30 observasi\n",
      "Student ID 394: 30 observasi\n",
      "Student ID 395: 30 observasi\n",
      "Student ID 396: 30 observasi\n",
      "Student ID 397: 30 observasi\n",
      "Student ID 398: 30 observasi\n",
      "Student ID 399: 30 observasi\n",
      "Student ID 400: 30 observasi\n",
      "Student ID 401: 30 observasi\n",
      "Student ID 402: 30 observasi\n",
      "Student ID 403: 30 observasi\n",
      "Student ID 404: 30 observasi\n",
      "Student ID 405: 30 observasi\n",
      "Student ID 406: 30 observasi\n",
      "Student ID 407: 30 observasi\n",
      "Student ID 408: 30 observasi\n",
      "Student ID 409: 30 observasi\n",
      "Student ID 410: 30 observasi\n",
      "Student ID 411: 30 observasi\n",
      "Student ID 412: 30 observasi\n",
      "Student ID 413: 30 observasi\n",
      "Student ID 414: 30 observasi\n",
      "Student ID 415: 30 observasi\n",
      "Student ID 416: 30 observasi\n",
      "Student ID 417: 30 observasi\n",
      "Student ID 418: 30 observasi\n",
      "Student ID 419: 30 observasi\n",
      "Student ID 420: 30 observasi\n",
      "Student ID 421: 30 observasi\n",
      "Student ID 422: 30 observasi\n",
      "Student ID 423: 30 observasi\n",
      "Student ID 424: 30 observasi\n",
      "Student ID 425: 30 observasi\n",
      "Student ID 426: 30 observasi\n",
      "Student ID 427: 30 observasi\n",
      "Student ID 428: 30 observasi\n",
      "Student ID 429: 30 observasi\n",
      "Student ID 430: 30 observasi\n",
      "Student ID 431: 30 observasi\n",
      "Student ID 432: 30 observasi\n",
      "Student ID 433: 30 observasi\n",
      "Student ID 434: 30 observasi\n",
      "Student ID 435: 30 observasi\n",
      "Student ID 436: 30 observasi\n",
      "Student ID 437: 30 observasi\n",
      "Student ID 438: 30 observasi\n",
      "Student ID 439: 30 observasi\n",
      "Student ID 440: 30 observasi\n",
      "Student ID 441: 30 observasi\n",
      "Student ID 442: 30 observasi\n",
      "Student ID 443: 30 observasi\n",
      "Student ID 444: 30 observasi\n",
      "Student ID 445: 30 observasi\n",
      "Student ID 446: 30 observasi\n",
      "Student ID 447: 30 observasi\n",
      "Student ID 448: 30 observasi\n",
      "Student ID 449: 30 observasi\n",
      "Student ID 450: 30 observasi\n",
      "Student ID 451: 30 observasi\n",
      "Student ID 452: 30 observasi\n",
      "Student ID 453: 30 observasi\n",
      "Student ID 454: 30 observasi\n",
      "Student ID 455: 30 observasi\n",
      "Student ID 456: 30 observasi\n",
      "Student ID 457: 30 observasi\n",
      "Student ID 458: 30 observasi\n",
      "Student ID 459: 30 observasi\n",
      "Student ID 460: 30 observasi\n",
      "Student ID 461: 30 observasi\n",
      "Student ID 462: 30 observasi\n",
      "Student ID 463: 30 observasi\n",
      "Student ID 464: 30 observasi\n",
      "Student ID 465: 30 observasi\n",
      "Student ID 466: 30 observasi\n",
      "Student ID 467: 30 observasi\n",
      "Student ID 468: 30 observasi\n",
      "Student ID 469: 30 observasi\n",
      "Student ID 470: 30 observasi\n",
      "Student ID 471: 30 observasi\n",
      "Student ID 472: 30 observasi\n",
      "Student ID 473: 30 observasi\n",
      "Student ID 474: 30 observasi\n",
      "Student ID 475: 30 observasi\n",
      "Student ID 476: 30 observasi\n",
      "Student ID 477: 30 observasi\n",
      "Student ID 478: 30 observasi\n",
      "Student ID 479: 30 observasi\n",
      "Student ID 480: 30 observasi\n",
      "Student ID 481: 30 observasi\n",
      "Student ID 482: 30 observasi\n",
      "Student ID 483: 30 observasi\n",
      "Student ID 484: 30 observasi\n",
      "Student ID 485: 30 observasi\n",
      "Student ID 486: 30 observasi\n",
      "Student ID 487: 30 observasi\n",
      "Student ID 488: 30 observasi\n",
      "Student ID 489: 30 observasi\n",
      "Student ID 490: 30 observasi\n",
      "Student ID 491: 30 observasi\n",
      "Student ID 492: 30 observasi\n",
      "Student ID 493: 30 observasi\n",
      "Student ID 494: 30 observasi\n",
      "Student ID 495: 30 observasi\n",
      "Student ID 496: 30 observasi\n",
      "Student ID 497: 30 observasi\n",
      "Student ID 498: 30 observasi\n",
      "Student ID 499: 30 observasi\n",
      "Student ID 500: 30 observasi\n"
     ]
    }
   ],
   "source": [
    "# Menghitung jumlah observasi asli untuk setiap Student ID\n",
    "jumlah_observasi = df.groupby('Student ID').size()\n",
    "\n",
    "print(\"\\n===== JUMLAH OBSERVASI PER STUDENT ID =====\")\n",
    "for student_id, jumlah in jumlah_observasi.items():\n",
    "    print(f\"Student ID {student_id}: {jumlah} observasi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70301fa1-cbc1-4a2d-82ff-29e0267ae994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menyimpan dataset baru setelah preprocessing \n",
    "df.to_csv('dataset_baru.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46472597-61ec-437e-ac2f-9e9f7348b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEMULAI EKSPERIMEN: 1_Hybrid_NoAttn_FullFeatures\n",
      "================================================================================\n",
      "\n",
      " Proses tuning ARIMA dimulai...\n",
      " - ARIMA(0,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(0,1,0) â†’ MAE: 0.3456\n",
      " - ARIMA(0,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(0,2,0) â†’ MAE: 312.1551\n",
      " - ARIMA(0,2,1) â†’ MAE: 0.4441\n",
      " - ARIMA(0,2,2) â†’ MAE: 0.2538\n",
      " - ARIMA(0,2,3) â†’ MAE: 0.4975\n",
      " - ARIMA(0,2,4) â†’ MAE: 0.6869\n",
      " - ARIMA(1,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(1,1,0) â†’ MAE: 0.3140\n",
      " - ARIMA(1,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(1,2,0) â†’ MAE: 232.0128\n",
      " - ARIMA(1,2,1) â†’ MAE: 0.3684\n",
      " - ARIMA(1,2,2) â†’ MAE: 0.6106\n",
      " - ARIMA(1,2,3) â†’ MAE: 0.2514\n",
      " - ARIMA(1,2,4) â†’ MAE: 0.2513\n",
      " - ARIMA(2,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(2,1,0) â†’ MAE: 0.2897\n",
      " - ARIMA(2,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(2,1,2) â†’ MAE: 0.2509\n",
      " - ARIMA(2,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(2,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(2,2,0) â†’ MAE: 151.2047\n",
      " - ARIMA(2,2,1) â†’ MAE: 0.3139\n",
      " - ARIMA(2,2,2) â†’ MAE: 0.2533\n",
      " - ARIMA(2,2,3) â†’ MAE: 0.2517\n",
      " - ARIMA(2,2,4) â†’ MAE: 0.2519\n",
      " - ARIMA(3,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(3,1,0) â†’ MAE: 0.2792\n",
      " - ARIMA(3,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(3,2,0) â†’ MAE: 93.9271\n",
      " - ARIMA(3,2,1) â†’ MAE: 0.2936\n",
      " - ARIMA(3,2,2) â†’ MAE: 0.4290\n",
      " - ARIMA(3,2,3) â†’ MAE: 0.2511\n",
      " - ARIMA(3,2,4) â†’ MAE: 0.2549\n",
      " - ARIMA(4,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(4,1,0) â†’ MAE: 0.2733\n",
      " - ARIMA(4,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,4) â†’ MAE: 0.2509\n",
      " - ARIMA(4,2,0) â†’ MAE: 76.4725\n",
      " - ARIMA(4,2,1) â†’ MAE: 0.2840\n",
      " - ARIMA(4,2,2) â†’ MAE: 0.3312\n",
      " - ARIMA(4,2,3) â†’ MAE: 0.2511\n",
      " - ARIMA(4,2,4) â†’ MAE: 0.2812\n",
      "\n",
      " Parameter ARIMA terbaik:\n",
      " - ARIMA(1, 1, 4) dengan MAE: 0.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 15:23:10,315] A new study created in memory with name: no-name-cdc67c21-7360-468c-a9de-fc7dfb4725d6\n",
      "[I 2025-06-24 15:29:00,396] Trial 0 finished with value: 0.6063584685325623 and parameters: {'hidden_dim': 72, 'dropout_rate': 0.2803579230020786, 'lr': 0.0003282239857402389, 'risk_weight': 0.808761666534412, 'embed_dim': 11}. Best is trial 0 with value: 0.6063584685325623.\n",
      "[I 2025-06-24 15:29:04,811] Trial 3 finished with value: 1.1481482982635498 and parameters: {'hidden_dim': 88, 'dropout_rate': 0.23926029694173978, 'lr': 0.0050006969910464565, 'risk_weight': 1.5390869036247872, 'embed_dim': 14}. Best is trial 0 with value: 0.6063584685325623.\n",
      "[I 2025-06-24 15:29:07,503] Trial 6 finished with value: 0.8044189810752869 and parameters: {'hidden_dim': 80, 'dropout_rate': 0.3266743281315773, 'lr': 0.0004603207174744077, 'risk_weight': 1.043690635435045, 'embed_dim': 40}. Best is trial 0 with value: 0.6063584685325623.\n",
      "[I 2025-06-24 15:30:06,279] Trial 2 finished with value: 0.6526947021484375 and parameters: {'hidden_dim': 224, 'dropout_rate': 0.4311748863971354, 'lr': 0.0008967760675986133, 'risk_weight': 0.87590047819726, 'embed_dim': 18}. Best is trial 0 with value: 0.6063584685325623.\n",
      "[I 2025-06-24 15:30:07,811] Trial 7 finished with value: 1.2175004482269287 and parameters: {'hidden_dim': 224, 'dropout_rate': 0.29662669233444383, 'lr': 0.00321691034499183, 'risk_weight': 1.6366803002525012, 'embed_dim': 21}. Best is trial 0 with value: 0.6063584685325623.\n",
      "[I 2025-06-24 15:30:16,184] Trial 5 finished with value: 0.9288809299468994 and parameters: {'hidden_dim': 248, 'dropout_rate': 0.2475605698012642, 'lr': 0.00016250727018190096, 'risk_weight': 1.2202946398563586, 'embed_dim': 23}. Best is trial 0 with value: 0.6063584685325623.\n",
      "[I 2025-06-24 15:30:17,957] Trial 4 finished with value: 1.2838630676269531 and parameters: {'hidden_dim': 200, 'dropout_rate': 0.22639299003761032, 'lr': 0.009133983216783985, 'risk_weight': 1.719693434249561, 'embed_dim': 39}. Best is trial 0 with value: 0.6063584685325623.\n",
      "[I 2025-06-24 15:30:21,482] Trial 1 finished with value: 0.7388261556625366 and parameters: {'hidden_dim': 216, 'dropout_rate': 0.4991786852230338, 'lr': 0.00011927358728064605, 'risk_weight': 0.9656989962677323, 'embed_dim': 40}. Best is trial 0 with value: 0.6063584685325623.\n",
      "[I 2025-06-24 15:31:09,125] Trial 9 finished with value: 1.347070574760437 and parameters: {'hidden_dim': 64, 'dropout_rate': 0.23038005197240027, 'lr': 0.0004542086257043654, 'risk_weight': 1.797504939920537, 'embed_dim': 15}. Best is trial 0 with value: 0.6063584685325623.\n",
      "[I 2025-06-24 15:31:12,534] Trial 8 finished with value: 1.1183457374572754 and parameters: {'hidden_dim': 88, 'dropout_rate': 0.3130084164733496, 'lr': 0.0071447447134723565, 'risk_weight': 1.496677210509783, 'embed_dim': 27}. Best is trial 0 with value: 0.6063584685325623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Hyperparameter LSTM terbaik dari tuning:\n",
      " - hidden_dim: 72\n",
      " - dropout_rate: 0.2803579230020786\n",
      " - lr: 0.0003282239857402389\n",
      " - risk_weight: 0.808761666534412\n",
      " - embed_dim: 11\n",
      "\n",
      "--- HASIL UNTUK EKSPERIMEN: 1_Hybrid_NoAttn_FullFeatures ---\n",
      "Metrik Akhir (Hybrid pada Set Uji):\n",
      " - MAE  (Tingkat Stres): 0.0233\n",
      " - RMSE (Tingkat Stres): 0.0285\n",
      "\n",
      "Peramalan Masa Depan Dinamis (Contoh):\n",
      "        Date  Student ID  Forecasted Stress Level\n",
      "0 2024-12-31           1                 0.525178\n",
      "1 2025-01-01           1                 0.896470\n",
      "2 2025-01-02           1                 0.836251\n",
      "3 2025-01-03           1                 0.714216\n",
      "4 2025-01-04           1                 0.880792\n",
      "\n",
      "Grafik prediksi, peramalan, dan kurva loss telah disimpan di folder 'hasil_eksperimen baru_1_hybrid_no_attn_full_features'\n",
      "Waktu Eksekusi Eksperimen: 0 jam, 21 menit, 59.62 detik\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "MEMULAI EKSPERIMEN: 2_Hybrid_WithAttn_FullFeatures\n",
      "================================================================================\n",
      "\n",
      " Proses tuning ARIMA dimulai...\n",
      " - ARIMA(0,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(0,1,0) â†’ MAE: 0.3456\n",
      " - ARIMA(0,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(0,2,0) â†’ MAE: 312.1551\n",
      " - ARIMA(0,2,1) â†’ MAE: 0.4441\n",
      " - ARIMA(0,2,2) â†’ MAE: 0.2538\n",
      " - ARIMA(0,2,3) â†’ MAE: 0.4975\n",
      " - ARIMA(0,2,4) â†’ MAE: 0.6869\n",
      " - ARIMA(1,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(1,1,0) â†’ MAE: 0.3140\n",
      " - ARIMA(1,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(1,2,0) â†’ MAE: 232.0128\n",
      " - ARIMA(1,2,1) â†’ MAE: 0.3684\n",
      " - ARIMA(1,2,2) â†’ MAE: 0.6106\n",
      " - ARIMA(1,2,3) â†’ MAE: 0.2514\n",
      " - ARIMA(1,2,4) â†’ MAE: 0.2513\n",
      " - ARIMA(2,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(2,1,0) â†’ MAE: 0.2897\n",
      " - ARIMA(2,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(2,1,2) â†’ MAE: 0.2509\n",
      " - ARIMA(2,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(2,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(2,2,0) â†’ MAE: 151.2047\n",
      " - ARIMA(2,2,1) â†’ MAE: 0.3139\n",
      " - ARIMA(2,2,2) â†’ MAE: 0.2533\n",
      " - ARIMA(2,2,3) â†’ MAE: 0.2517\n",
      " - ARIMA(2,2,4) â†’ MAE: 0.2519\n",
      " - ARIMA(3,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(3,1,0) â†’ MAE: 0.2792\n",
      " - ARIMA(3,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(3,2,0) â†’ MAE: 93.9271\n",
      " - ARIMA(3,2,1) â†’ MAE: 0.2936\n",
      " - ARIMA(3,2,2) â†’ MAE: 0.4290\n",
      " - ARIMA(3,2,3) â†’ MAE: 0.2511\n",
      " - ARIMA(3,2,4) â†’ MAE: 0.2549\n",
      " - ARIMA(4,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(4,1,0) â†’ MAE: 0.2733\n",
      " - ARIMA(4,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,4) â†’ MAE: 0.2509\n",
      " - ARIMA(4,2,0) â†’ MAE: 76.4725\n",
      " - ARIMA(4,2,1) â†’ MAE: 0.2840\n",
      " - ARIMA(4,2,2) â†’ MAE: 0.3312\n",
      " - ARIMA(4,2,3) â†’ MAE: 0.2511\n",
      " - ARIMA(4,2,4) â†’ MAE: 0.2812\n",
      "\n",
      " Parameter ARIMA terbaik:\n",
      " - ARIMA(1, 1, 4) dengan MAE: 0.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 15:45:22,011] A new study created in memory with name: no-name-722f4174-945d-4db7-a6d6-73c950f4db18\n",
      "[I 2025-06-24 15:52:44,290] Trial 0 finished with value: 1.0687808990478516 and parameters: {'hidden_dim': 64, 'dropout_rate': 0.30952491261654075, 'lr': 0.0037983000541339236, 'risk_weight': 1.4283239445198985, 'embed_dim': 21, 'num_heads': 8}. Best is trial 0 with value: 1.0687808990478516.\n",
      "[I 2025-06-24 15:53:15,902] Trial 5 finished with value: 0.7746705412864685 and parameters: {'hidden_dim': 96, 'dropout_rate': 0.4856737922430505, 'lr': 0.00041956474394577243, 'risk_weight': 1.0288423975524237, 'embed_dim': 28, 'num_heads': 4}. Best is trial 5 with value: 0.7746705412864685.\n",
      "[I 2025-06-24 15:53:24,416] Trial 6 finished with value: 0.8445502519607544 and parameters: {'hidden_dim': 120, 'dropout_rate': 0.2470502904200109, 'lr': 0.003963181005962017, 'risk_weight': 1.1246617432035289, 'embed_dim': 26, 'num_heads': 2}. Best is trial 5 with value: 0.7746705412864685.\n",
      "[I 2025-06-24 15:53:38,568] Trial 2 finished with value: 1.2886545658111572 and parameters: {'hidden_dim': 136, 'dropout_rate': 0.22052558477773285, 'lr': 0.00036239568281020476, 'risk_weight': 1.7001380155615506, 'embed_dim': 45, 'num_heads': 2}. Best is trial 5 with value: 0.7746705412864685.\n",
      "[I 2025-06-24 15:53:55,548] Trial 1 finished with value: 0.740342915058136 and parameters: {'hidden_dim': 136, 'dropout_rate': 0.23761659451656744, 'lr': 0.00016883642989725422, 'risk_weight': 0.9685614534488018, 'embed_dim': 19, 'num_heads': 8}. Best is trial 1 with value: 0.740342915058136.\n",
      "[I 2025-06-24 15:54:15,345] Trial 3 finished with value: 0.8063602447509766 and parameters: {'hidden_dim': 200, 'dropout_rate': 0.3730327675396381, 'lr': 0.00011091309515627545, 'risk_weight': 1.0512558324314254, 'embed_dim': 12, 'num_heads': 8}. Best is trial 1 with value: 0.740342915058136.\n",
      "[I 2025-06-24 15:54:40,399] Trial 7 finished with value: 0.7680153846740723 and parameters: {'hidden_dim': 200, 'dropout_rate': 0.2976876673632979, 'lr': 0.0008167928564248255, 'risk_weight': 1.0150566566321417, 'embed_dim': 50, 'num_heads': 8}. Best is trial 1 with value: 0.740342915058136.\n",
      "[I 2025-06-24 15:54:45,652] Trial 4 finished with value: 0.9334035515785217 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.43544159275165273, 'lr': 0.0026340532933860935, 'risk_weight': 1.2455549058522717, 'embed_dim': 41, 'num_heads': 2}. Best is trial 1 with value: 0.740342915058136.\n",
      "[I 2025-06-24 15:56:08,480] Trial 8 finished with value: 0.8645671606063843 and parameters: {'hidden_dim': 112, 'dropout_rate': 0.2788131215299584, 'lr': 0.0030947213991588127, 'risk_weight': 1.1535341092888902, 'embed_dim': 42, 'num_heads': 4}. Best is trial 1 with value: 0.740342915058136.\n",
      "[I 2025-06-24 15:56:21,809] Trial 9 finished with value: 0.6289905905723572 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.371578150372286, 'lr': 0.0049056784269915265, 'risk_weight': 0.8404431201749435, 'embed_dim': 34, 'num_heads': 4}. Best is trial 9 with value: 0.6289905905723572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Hyperparameter LSTM terbaik dari tuning:\n",
      " - hidden_dim: 160\n",
      " - dropout_rate: 0.371578150372286\n",
      " - lr: 0.0049056784269915265\n",
      " - risk_weight: 0.8404431201749435\n",
      " - embed_dim: 34\n",
      " - num_heads: 4\n",
      "\n",
      "--- HASIL UNTUK EKSPERIMEN: 2_Hybrid_WithAttn_FullFeatures ---\n",
      "Metrik Akhir (Hybrid pada Set Uji):\n",
      " - MAE  (Tingkat Stres): 0.0367\n",
      " - RMSE (Tingkat Stres): 0.0466\n",
      "\n",
      "Peramalan Masa Depan Dinamis (Contoh):\n",
      "        Date  Student ID  Forecasted Stress Level\n",
      "0 2024-12-31           1                 0.202460\n",
      "1 2025-01-01           1                 0.852869\n",
      "2 2025-01-02           1                 0.788973\n",
      "3 2025-01-03           1                 0.201564\n",
      "4 2025-01-04           1                 0.771974\n",
      "\n",
      "Grafik prediksi, peramalan, dan kurva loss telah disimpan di folder 'hasil_eksperimen baru_2_hybrid_with_attn_full_features'\n",
      "Waktu Eksekusi Eksperimen: 0 jam, 26 menit, 9.11 detik\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "MEMULAI EKSPERIMEN: 3_Hybrid_NoAttn_ReducedFeatures\n",
      "================================================================================\n",
      "\n",
      " Proses tuning ARIMA dimulai...\n",
      " - ARIMA(0,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(0,1,0) â†’ MAE: 0.3456\n",
      " - ARIMA(0,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(0,2,0) â†’ MAE: 312.1551\n",
      " - ARIMA(0,2,1) â†’ MAE: 0.4441\n",
      " - ARIMA(0,2,2) â†’ MAE: 0.2538\n",
      " - ARIMA(0,2,3) â†’ MAE: 0.4975\n",
      " - ARIMA(0,2,4) â†’ MAE: 0.6869\n",
      " - ARIMA(1,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(1,1,0) â†’ MAE: 0.3140\n",
      " - ARIMA(1,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(1,2,0) â†’ MAE: 232.0128\n",
      " - ARIMA(1,2,1) â†’ MAE: 0.3684\n",
      " - ARIMA(1,2,2) â†’ MAE: 0.6106\n",
      " - ARIMA(1,2,3) â†’ MAE: 0.2514\n",
      " - ARIMA(1,2,4) â†’ MAE: 0.2513\n",
      " - ARIMA(2,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(2,1,0) â†’ MAE: 0.2897\n",
      " - ARIMA(2,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(2,1,2) â†’ MAE: 0.2509\n",
      " - ARIMA(2,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(2,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(2,2,0) â†’ MAE: 151.2047\n",
      " - ARIMA(2,2,1) â†’ MAE: 0.3139\n",
      " - ARIMA(2,2,2) â†’ MAE: 0.2533\n",
      " - ARIMA(2,2,3) â†’ MAE: 0.2517\n",
      " - ARIMA(2,2,4) â†’ MAE: 0.2519\n",
      " - ARIMA(3,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(3,1,0) â†’ MAE: 0.2792\n",
      " - ARIMA(3,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(3,2,0) â†’ MAE: 93.9271\n",
      " - ARIMA(3,2,1) â†’ MAE: 0.2936\n",
      " - ARIMA(3,2,2) â†’ MAE: 0.4290\n",
      " - ARIMA(3,2,3) â†’ MAE: 0.2511\n",
      " - ARIMA(3,2,4) â†’ MAE: 0.2549\n",
      " - ARIMA(4,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(4,1,0) â†’ MAE: 0.2733\n",
      " - ARIMA(4,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,4) â†’ MAE: 0.2509\n",
      " - ARIMA(4,2,0) â†’ MAE: 76.4725\n",
      " - ARIMA(4,2,1) â†’ MAE: 0.2840\n",
      " - ARIMA(4,2,2) â†’ MAE: 0.3312\n",
      " - ARIMA(4,2,3) â†’ MAE: 0.2511\n",
      " - ARIMA(4,2,4) â†’ MAE: 0.2812\n",
      "\n",
      " Parameter ARIMA terbaik:\n",
      " - ARIMA(1, 1, 4) dengan MAE: 0.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 16:11:13,598] A new study created in memory with name: no-name-3ae1f53d-a87c-4278-b6a2-e37b2e98cad3\n",
      "[I 2025-06-24 16:16:27,542] Trial 3 finished with value: 0.941009521484375 and parameters: {'hidden_dim': 88, 'dropout_rate': 0.3128087687342327, 'lr': 0.0028836143234617444, 'risk_weight': 1.270247181888909, 'embed_dim': 13}. Best is trial 3 with value: 0.941009521484375.\n",
      "[I 2025-06-24 16:16:46,802] Trial 5 finished with value: 0.6351321339607239 and parameters: {'hidden_dim': 96, 'dropout_rate': 0.3144555093846444, 'lr': 0.001557900823174226, 'risk_weight': 0.8518990439562047, 'embed_dim': 16}. Best is trial 5 with value: 0.6351321339607239.\n",
      "[I 2025-06-24 16:16:47,917] Trial 0 finished with value: 1.0826919078826904 and parameters: {'hidden_dim': 96, 'dropout_rate': 0.2698953992970763, 'lr': 0.00013390709521056605, 'risk_weight': 1.426840507250898, 'embed_dim': 27}. Best is trial 5 with value: 0.6351321339607239.\n",
      "[I 2025-06-24 16:17:09,621] Trial 7 finished with value: 1.098163366317749 and parameters: {'hidden_dim': 168, 'dropout_rate': 0.283567895267365, 'lr': 0.0016613777007368068, 'risk_weight': 1.4764369009553435, 'embed_dim': 21}. Best is trial 5 with value: 0.6351321339607239.\n",
      "[I 2025-06-24 16:17:22,885] Trial 4 finished with value: 1.3450233936309814 and parameters: {'hidden_dim': 168, 'dropout_rate': 0.4358050952656731, 'lr': 0.0003369169061027598, 'risk_weight': 1.7833994393048038, 'embed_dim': 39}. Best is trial 5 with value: 0.6351321339607239.\n",
      "[I 2025-06-24 16:17:34,930] Trial 2 finished with value: 0.915276825428009 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.20327803572565897, 'lr': 0.0019443987507050083, 'risk_weight': 1.2253787049477014, 'embed_dim': 44}. Best is trial 5 with value: 0.6351321339607239.\n",
      "[I 2025-06-24 16:17:39,172] Trial 6 finished with value: 1.340149164199829 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.3062204552839542, 'lr': 0.009877897740546449, 'risk_weight': 1.8084895221401793, 'embed_dim': 40}. Best is trial 5 with value: 0.6351321339607239.\n",
      "[I 2025-06-24 16:17:39,412] Trial 1 finished with value: 1.2163927555084229 and parameters: {'hidden_dim': 216, 'dropout_rate': 0.49793796042736777, 'lr': 0.0002749014357048165, 'risk_weight': 1.6307438744902973, 'embed_dim': 28}. Best is trial 5 with value: 0.6351321339607239.\n",
      "[I 2025-06-24 16:18:34,541] Trial 9 finished with value: 1.1186273097991943 and parameters: {'hidden_dim': 64, 'dropout_rate': 0.20076708820463693, 'lr': 0.002764401396557367, 'risk_weight': 1.503311984389788, 'embed_dim': 25}. Best is trial 5 with value: 0.6351321339607239.\n",
      "[I 2025-06-24 16:18:48,780] Trial 8 finished with value: 1.3503530025482178 and parameters: {'hidden_dim': 184, 'dropout_rate': 0.29316986974490944, 'lr': 0.007532823357282586, 'risk_weight': 1.8118505399568454, 'embed_dim': 36}. Best is trial 5 with value: 0.6351321339607239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Hyperparameter LSTM terbaik dari tuning:\n",
      " - hidden_dim: 96\n",
      " - dropout_rate: 0.3144555093846444\n",
      " - lr: 0.001557900823174226\n",
      " - risk_weight: 0.8518990439562047\n",
      " - embed_dim: 16\n",
      "\n",
      "--- HASIL UNTUK EKSPERIMEN: 3_Hybrid_NoAttn_ReducedFeatures ---\n",
      "Metrik Akhir (Hybrid pada Set Uji):\n",
      " - MAE  (Tingkat Stres): 0.0234\n",
      " - RMSE (Tingkat Stres): 0.0303\n",
      "\n",
      "Peramalan Masa Depan Dinamis (Contoh):\n",
      "        Date  Student ID  Forecasted Stress Level\n",
      "0 2024-12-31           1                 0.640553\n",
      "1 2025-01-01           1                 0.866719\n",
      "2 2025-01-02           1                 0.804636\n",
      "3 2025-01-03           1                 0.731241\n",
      "4 2025-01-04           1                 0.805133\n",
      "\n",
      "Grafik prediksi, peramalan, dan kurva loss telah disimpan di folder 'hasil_eksperimen baru_3_hybrid_no_attn_reduced_features'\n",
      "Waktu Eksekusi Eksperimen: 0 jam, 21 menit, 28.93 detik\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "MEMULAI EKSPERIMEN: 4_Hybrid_WithAttn_ReducedFeatures\n",
      "================================================================================\n",
      "\n",
      " Proses tuning ARIMA dimulai...\n",
      " - ARIMA(0,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(0,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(0,1,0) â†’ MAE: 0.3456\n",
      " - ARIMA(0,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(0,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(0,2,0) â†’ MAE: 312.1551\n",
      " - ARIMA(0,2,1) â†’ MAE: 0.4441\n",
      " - ARIMA(0,2,2) â†’ MAE: 0.2538\n",
      " - ARIMA(0,2,3) â†’ MAE: 0.4975\n",
      " - ARIMA(0,2,4) â†’ MAE: 0.6869\n",
      " - ARIMA(1,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(1,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(1,1,0) â†’ MAE: 0.3140\n",
      " - ARIMA(1,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(1,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(1,2,0) â†’ MAE: 232.0128\n",
      " - ARIMA(1,2,1) â†’ MAE: 0.3684\n",
      " - ARIMA(1,2,2) â†’ MAE: 0.6106\n",
      " - ARIMA(1,2,3) â†’ MAE: 0.2514\n",
      " - ARIMA(1,2,4) â†’ MAE: 0.2513\n",
      " - ARIMA(2,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(2,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(2,1,0) â†’ MAE: 0.2897\n",
      " - ARIMA(2,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(2,1,2) â†’ MAE: 0.2509\n",
      " - ARIMA(2,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(2,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(2,2,0) â†’ MAE: 151.2047\n",
      " - ARIMA(2,2,1) â†’ MAE: 0.3139\n",
      " - ARIMA(2,2,2) â†’ MAE: 0.2533\n",
      " - ARIMA(2,2,3) â†’ MAE: 0.2517\n",
      " - ARIMA(2,2,4) â†’ MAE: 0.2519\n",
      " - ARIMA(3,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(3,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(3,1,0) â†’ MAE: 0.2792\n",
      " - ARIMA(3,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(3,1,4) â†’ MAE: 0.2508\n",
      " - ARIMA(3,2,0) â†’ MAE: 93.9271\n",
      " - ARIMA(3,2,1) â†’ MAE: 0.2936\n",
      " - ARIMA(3,2,2) â†’ MAE: 0.4290\n",
      " - ARIMA(3,2,3) â†’ MAE: 0.2511\n",
      " - ARIMA(3,2,4) â†’ MAE: 0.2549\n",
      " - ARIMA(4,0,0) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,1) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,2) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,3) â†’ MAE: 0.2509\n",
      " - ARIMA(4,0,4) â†’ MAE: 0.2509\n",
      " - ARIMA(4,1,0) â†’ MAE: 0.2733\n",
      " - ARIMA(4,1,1) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,2) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,3) â†’ MAE: 0.2508\n",
      " - ARIMA(4,1,4) â†’ MAE: 0.2509\n",
      " - ARIMA(4,2,0) â†’ MAE: 76.4725\n",
      " - ARIMA(4,2,1) â†’ MAE: 0.2840\n",
      " - ARIMA(4,2,2) â†’ MAE: 0.3312\n",
      " - ARIMA(4,2,3) â†’ MAE: 0.2511\n",
      " - ARIMA(4,2,4) â†’ MAE: 0.2812\n",
      "\n",
      " Parameter ARIMA terbaik:\n",
      " - ARIMA(1, 1, 4) dengan MAE: 0.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 16:32:46,891] A new study created in memory with name: no-name-38c758d8-e48a-462e-b2f1-fb1fcad46182\n",
      "[I 2025-06-24 16:40:07,547] Trial 7 finished with value: 1.2477144002914429 and parameters: {'hidden_dim': 64, 'dropout_rate': 0.23815693380341355, 'lr': 0.0008814687720308008, 'risk_weight': 1.671791547763339, 'embed_dim': 16, 'num_heads': 4}. Best is trial 7 with value: 1.2477144002914429.\n",
      "[I 2025-06-24 16:40:54,516] Trial 2 finished with value: 1.3142988681793213 and parameters: {'hidden_dim': 96, 'dropout_rate': 0.4914605452607248, 'lr': 0.0011955875904742226, 'risk_weight': 1.7691294731653135, 'embed_dim': 43, 'num_heads': 8}. Best is trial 7 with value: 1.2477144002914429.\n",
      "[I 2025-06-24 16:41:26,043] Trial 6 finished with value: 1.1068897247314453 and parameters: {'hidden_dim': 136, 'dropout_rate': 0.24459019486123115, 'lr': 0.0010613378600294132, 'risk_weight': 1.4876160481188698, 'embed_dim': 38, 'num_heads': 8}. Best is trial 6 with value: 1.1068897247314453.\n",
      "[I 2025-06-24 16:41:26,574] Trial 3 finished with value: 1.0837056636810303 and parameters: {'hidden_dim': 152, 'dropout_rate': 0.48622624045754254, 'lr': 0.0001108483508782331, 'risk_weight': 1.4141108425825184, 'embed_dim': 27, 'num_heads': 2}. Best is trial 3 with value: 1.0837056636810303.\n",
      "[I 2025-06-24 16:42:09,559] Trial 1 finished with value: 1.2702840566635132 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.21618110185944645, 'lr': 0.005995108486912999, 'risk_weight': 1.7090210123016902, 'embed_dim': 35, 'num_heads': 8}. Best is trial 3 with value: 1.0837056636810303.\n",
      "[I 2025-06-24 16:42:34,467] Trial 5 finished with value: 1.3379919528961182 and parameters: {'hidden_dim': 184, 'dropout_rate': 0.3152678259475316, 'lr': 0.0005102183091130147, 'risk_weight': 1.7991568147332606, 'embed_dim': 24, 'num_heads': 8}. Best is trial 3 with value: 1.0837056636810303.\n",
      "[I 2025-06-24 16:42:50,674] Trial 4 finished with value: 1.0428334474563599 and parameters: {'hidden_dim': 208, 'dropout_rate': 0.40536449164030786, 'lr': 0.0008131835048437879, 'risk_weight': 1.3942190171411801, 'embed_dim': 41, 'num_heads': 2}. Best is trial 4 with value: 1.0428334474563599.\n",
      "[I 2025-06-24 16:42:53,173] Trial 0 finished with value: 1.3371156454086304 and parameters: {'hidden_dim': 232, 'dropout_rate': 0.41170004024349177, 'lr': 0.0005240002662236117, 'risk_weight': 1.7997348764737744, 'embed_dim': 10, 'num_heads': 8}. Best is trial 4 with value: 1.0428334474563599.\n",
      "[I 2025-06-24 16:43:38,931] Trial 8 finished with value: 0.8100636005401611 and parameters: {'hidden_dim': 80, 'dropout_rate': 0.3011118633273589, 'lr': 0.0003453255589258589, 'risk_weight': 1.0540173738183432, 'embed_dim': 48, 'num_heads': 4}. Best is trial 8 with value: 0.8100636005401611.\n",
      "[I 2025-06-24 16:43:49,526] Trial 9 finished with value: 0.6999372839927673 and parameters: {'hidden_dim': 144, 'dropout_rate': 0.3820001443286044, 'lr': 0.00040648639300275324, 'risk_weight': 0.9295214029538166, 'embed_dim': 48, 'num_heads': 2}. Best is trial 9 with value: 0.6999372839927673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Hyperparameter LSTM terbaik dari tuning:\n",
      " - hidden_dim: 144\n",
      " - dropout_rate: 0.3820001443286044\n",
      " - lr: 0.00040648639300275324\n",
      " - risk_weight: 0.9295214029538166\n",
      " - embed_dim: 48\n",
      " - num_heads: 2\n",
      "\n",
      "--- HASIL UNTUK EKSPERIMEN: 4_Hybrid_WithAttn_ReducedFeatures ---\n",
      "Metrik Akhir (Hybrid pada Set Uji):\n",
      " - MAE  (Tingkat Stres): 0.0313\n",
      " - RMSE (Tingkat Stres): 0.0395\n",
      "\n",
      "Peramalan Masa Depan Dinamis (Contoh):\n",
      "        Date  Student ID  Forecasted Stress Level\n",
      "0 2024-12-31           1                 0.431749\n",
      "1 2025-01-01           1                 0.791111\n",
      "2 2025-01-02           1                 0.729630\n",
      "3 2025-01-03           1                 0.523448\n",
      "4 2025-01-04           1                 0.687164\n",
      "\n",
      "Grafik prediksi, peramalan, dan kurva loss telah disimpan di folder 'hasil_eksperimen baru_4_hybrid_with_attn_reduced_features'\n",
      "Waktu Eksekusi Eksperimen: 0 jam, 25 menit, 2.73 detik\n",
      "================================================================================\n",
      "\n",
      "Total Waktu Eksekusi Semua Eksperimen: 1 jam, 34 menit, 40.49 detik\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 1: FUNGSI DAN KELAS MODEL (DIMODIFIKASI DENGAN MULTI-HEAD ATTENTION)\n",
    "# =============================================================================\n",
    "\n",
    "def setup_logging(model_dir, experiment_name):\n",
    "    \"\"\"Mengatur logging untuk menyimpan output ke file.\"\"\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    log_file = os.path.join(model_dir, f'log_{experiment_name}.log')\n",
    "    # Hapus handler lama jika ada untuk menghindari duplikasi log\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# MODIFIKASI: Fungsi MAPE dihapus sesuai permintaan\n",
    "# def mean_absolute_percentage_error(y_true, y_pred):\n",
    "#     \"\"\"Menghitung Mean Absolute Percentage Error (MAPE).\"\"\"\n",
    "#     y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "#     non_zero_mask = y_true != 0\n",
    "#     if not np.any(non_zero_mask): return 0.0\n",
    "#     return np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "\n",
    "def create_sequences(data, student_ids, target_cols, timesteps=3):\n",
    "    \"\"\"Membuat sekuens data untuk model time series.\"\"\"\n",
    "    X, X_ids, y = [], [], []\n",
    "    for i in range(len(data) - timesteps):\n",
    "        X.append(data[i:i + timesteps])\n",
    "        X_ids.append(student_ids[i + timesteps])\n",
    "        y.append(data[i + timesteps, -len(target_cols):])\n",
    "    return np.array(X), np.array(X_ids), np.array(y)\n",
    "\n",
    "# MODIFIKASI: Kelas Attention diganti dengan MultiHeadAttention wrapper\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper untuk nn.MultiheadAttention dari PyTorch.\n",
    "    Memungkinkan model untuk fokus pada timestep yang relevan dengan lebih efektif.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Pastikan hidden_dim dapat dibagi oleh num_heads\n",
    "        assert hidden_dim % num_heads == 0, \"hidden_dim must be divisible by num_heads\"\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, lstm_outputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lstm_outputs: Output dari layer LSTM, shape: (batch, seq_len, hidden_dim)\n",
    "        Returns:\n",
    "            context_vector: Vektor konteks hasil pembobotan, shape: (batch, hidden_dim)\n",
    "            attn_weights: Bobot atensi, shape: (batch, seq_len)\n",
    "        \"\"\"\n",
    "        # Query, Key, dan Value adalah output LSTM itu sendiri\n",
    "        attn_output, attn_weights = self.mha(lstm_outputs, lstm_outputs, lstm_outputs)\n",
    "        # Gunakan output dari attention layer sebagai context vector\n",
    "        # Kita ambil output terakhir yang telah diberi bobot atensi, atau bisa juga di-average\n",
    "        context_vector = attn_output[:, -1, :]\n",
    "        return context_vector, attn_weights.mean(dim=1) # Rata-ratakan bobot dari semua head\n",
    "\n",
    "class LSTMAttentionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model LSTM yang diintegrasikan dengan Multi-Head Attention Mechanism.\n",
    "    \"\"\"\n",
    "    # MODIFIKASI: Menambahkan num_heads\n",
    "    def __init__(self, input_dim, num_students, embed_dim, hidden_dim, num_heads, timesteps=3, dropout_rate=0.4):\n",
    "        super(LSTMAttentionModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_students, embed_dim)\n",
    "        self.lstm = nn.LSTM(input_dim + embed_dim, hidden_dim, batch_first=True)\n",
    "        # MODIFIKASI: Menggunakan kelas MultiHeadAttention yang baru\n",
    "        self.attention = MultiHeadAttention(hidden_dim, num_heads)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.risk_head = nn.Sequential(nn.Linear(hidden_dim, hidden_dim // 2), nn.ReLU(), nn.Dropout(dropout_rate - 0.1 if dropout_rate > 0.1 else 0.0), nn.Linear(hidden_dim // 2, 3))\n",
    "        self.fc_residual = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, student_ids):\n",
    "        if student_ids.ndim == 1: student_ids = student_ids.unsqueeze(1)\n",
    "        embed = self.embedding(student_ids.squeeze(1))\n",
    "        embed = embed.unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        x = torch.cat([x, embed], dim=2)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # MODIFIKASI: Attention layer memproses output LSTM\n",
    "        context_vector, _ = self.attention(lstm_out)\n",
    "        \n",
    "        out = self.bn(context_vector)\n",
    "        out = self.dropout(out)\n",
    "        risk_logits = self.risk_head(out)\n",
    "        residual_pred = self.fc_residual(out)\n",
    "        return risk_logits, residual_pred.squeeze(1)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model LSTM standar tanpa Attention Mechanism.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_students, embed_dim, hidden_dim, timesteps=3, dropout_rate=0.4):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_students, embed_dim)\n",
    "        self.lstm = nn.LSTM(input_dim + embed_dim, hidden_dim, batch_first=True)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.risk_head = nn.Sequential(nn.Linear(hidden_dim, hidden_dim // 2), nn.ReLU(), nn.Dropout(dropout_rate - 0.1 if dropout_rate > 0.1 else 0.0), nn.Linear(hidden_dim // 2, 3))\n",
    "        self.fc_residual = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, student_ids):\n",
    "        if student_ids.ndim == 1: student_ids = student_ids.unsqueeze(1)\n",
    "        embed = self.embedding(student_ids.squeeze(1))\n",
    "        embed = embed.unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        x = torch.cat([x, embed], dim=2)\n",
    "\n",
    "        lstm_out, (h_n, _) = self.lstm(x)\n",
    "        last_hidden_state = h_n.squeeze(0)\n",
    "        \n",
    "        out = self.bn(last_hidden_state)\n",
    "        out = self.dropout(out)\n",
    "        risk_logits = self.risk_head(out)\n",
    "        residual_pred = self.fc_residual(out)\n",
    "        return risk_logits, residual_pred.squeeze(1)\n",
    "\n",
    "\n",
    "# def tune_arima(train_data, val_data, p_range=range(0, 5), d_range=range(0, 3), q_range=range(0, 5)):\n",
    "#     \"\"\"Mencari parameter ARIMA terbaik menggunakan time series cross-validation.\"\"\"\n",
    "#     best_mae = float('inf')\n",
    "#     best_params = (1, 1, 1)\n",
    "#     tscv = TimeSeriesSplit(n_splits=3)\n",
    "#     for p in p_range:\n",
    "#         for d in d_range:\n",
    "#             for q in q_range:\n",
    "#                 try:\n",
    "#                     mae_list = []\n",
    "#                     for train_index, val_index in tscv.split(train_data):\n",
    "#                         train_fold, val_fold = train_data.iloc[train_index], train_data.iloc[val_index]\n",
    "#                         model = ARIMA(train_fold['Stress Level (GSR)'], order=(p, d, q)).fit()\n",
    "#                         predictions = model.forecast(steps=len(val_fold))\n",
    "#                         mae = mean_absolute_error(val_fold['Stress Level (GSR)'], predictions)\n",
    "#                         mae_list.append(mae)\n",
    "#                     mean_mae = np.mean(mae_list)\n",
    "#                     if mean_mae < best_mae:\n",
    "#                         best_mae, best_params = mean_mae, (p, d, q)\n",
    "#                 except Exception:\n",
    "#                     continue\n",
    "#     return best_params, best_mae\n",
    "\n",
    "def tune_arima(train_data, val_data, p_range=range(0, 5), d_range=range(0, 3), q_range=range(0, 5)):\n",
    "    best_mae = float('inf')\n",
    "    best_params = (1, 1, 1)\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    print(\"\\n Proses tuning ARIMA dimulai...\")\n",
    "    \n",
    "    for p in p_range:\n",
    "        for d in d_range:\n",
    "            for q in q_range:\n",
    "                try:\n",
    "                    mae_list = []\n",
    "                    for train_index, val_index in tscv.split(train_data):\n",
    "                        train_fold, val_fold = train_data.iloc[train_index], train_data.iloc[val_index]\n",
    "                        model = ARIMA(train_fold['Stress Level (GSR)'], order=(p, d, q)).fit()\n",
    "                        predictions = model.forecast(steps=len(val_fold))\n",
    "                        mae = mean_absolute_error(val_fold['Stress Level (GSR)'], predictions)\n",
    "                        mae_list.append(mae)\n",
    "                    mean_mae = np.mean(mae_list)\n",
    "                    print(f\" - ARIMA({p},{d},{q}) â†’ MAE: {mean_mae:.4f}\")\n",
    "                    if mean_mae < best_mae:\n",
    "                        best_mae, best_params = mean_mae, (p, d, q)\n",
    "                except Exception as e:\n",
    "                    print(f\"Gagal ARIMA({p},{d},{q}): {e}\")\n",
    "                    continue\n",
    "\n",
    "    print(\"\\n Parameter ARIMA terbaik:\")\n",
    "    print(f\" - ARIMA{best_params} dengan MAE: {best_mae:.4f}\")\n",
    "    \n",
    "    return best_params, best_mae\n",
    "\n",
    "\n",
    "# def tune_lstm(X_train_tensor, X_train_ids_tensor, y_train_risk, y_train_residual, timesteps, num_students, device, use_attention):\n",
    "#     \"\"\"Mencari hyperparameter terbaik untuk model LSTM (dengan/tanpa Attention) menggunakan Optuna.\"\"\"\n",
    "#     def objective(trial):\n",
    "#         # MODIFIKASI: Pastikan hidden_dim kelipatan dari num_heads (misal 8)\n",
    "#         hidden_dim = trial.suggest_int('hidden_dim', 64, 256, step=8)\n",
    "#         dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "#         lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "#         risk_weight = trial.suggest_float('risk_weight', 0.8, 2.0)\n",
    "#         embed_dim = trial.suggest_int('embed_dim', 10, 50)\n",
    "        \n",
    "#         if use_attention:\n",
    "#             # MODIFIKASI: Tambahkan num_heads ke tuning\n",
    "#             num_heads = trial.suggest_categorical('num_heads', [2, 4, 8])\n",
    "#             model = LSTMAttentionModel(input_dim=X_train_tensor.shape[2], num_students=num_students, embed_dim=embed_dim, hidden_dim=hidden_dim, num_heads=num_heads, timesteps=timesteps, dropout_rate=dropout_rate).to(device)\n",
    "#         else:\n",
    "#             model = LSTMModel(input_dim=X_train_tensor.shape[2], num_students=num_students, embed_dim=embed_dim, hidden_dim=hidden_dim, timesteps=timesteps, dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "#         loss_risk, loss_residual = nn.CrossEntropyLoss(), nn.MSELoss()\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        \n",
    "#         val_size = int(len(X_train_tensor) * 0.2)\n",
    "#         X_train_lstm, X_val_lstm = X_train_tensor[:-val_size], X_train_tensor[-val_size:]\n",
    "#         X_train_ids_lstm, X_val_ids_lstm = X_train_ids_tensor[:-val_size], X_train_ids_tensor[-val_size:]\n",
    "#         y_train_risk_lstm, y_val_risk_lstm = y_train_risk[:-val_size], y_train_risk[-val_size:]\n",
    "#         y_train_residual_lstm, y_val_residual_lstm = y_train_residual[:-val_size], y_train_residual[-val_size:]\n",
    "        \n",
    "#         train_dataset = TensorDataset(X_train_lstm, X_train_ids_lstm, y_train_risk_lstm, y_train_residual_lstm)\n",
    "#         train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "#         best_val_loss = float('inf')\n",
    "        \n",
    "#         for epoch in range(40):\n",
    "#             model.train()\n",
    "#             for batch_x, batch_ids, batch_y_risk, batch_y_residual in train_loader:\n",
    "#                 batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "#                 optimizer.zero_grad()\n",
    "#                 risk_logits, residual_pred = model(batch_x, batch_ids)\n",
    "#                 loss = risk_weight * loss_risk(risk_logits, batch_y_risk) + 1.0 * loss_residual(residual_pred, batch_y_residual)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "            \n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 val_risk_logits, val_residual_pred = model(X_val_lstm, X_val_ids_lstm)\n",
    "#                 val_loss = (risk_weight * loss_risk(val_risk_logits, y_val_risk_lstm) + 1.0 * loss_residual(val_residual_pred, y_val_residual_lstm)).item()\n",
    "#                 if val_loss < best_val_loss: best_val_loss = val_loss\n",
    "#         return best_val_loss\n",
    "        \n",
    "#     study = optuna.create_study(direction='minimize')\n",
    "#     study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "#     return study.best_params\n",
    "\n",
    "def tune_lstm(X_train_tensor, X_train_ids_tensor, y_train_risk, y_train_residual, timesteps, num_students, device, use_attention):\n",
    "    \"\"\"Mencari hyperparameter terbaik untuk model LSTM (dengan/tanpa Attention) menggunakan Optuna.\"\"\"\n",
    "    def objective(trial):\n",
    "        hidden_dim = trial.suggest_int('hidden_dim', 64, 256, step=8)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "        risk_weight = trial.suggest_float('risk_weight', 0.8, 2.0)\n",
    "        embed_dim = trial.suggest_int('embed_dim', 10, 50)\n",
    "        \n",
    "        if use_attention:\n",
    "            num_heads = trial.suggest_categorical('num_heads', [2, 4, 8])\n",
    "            model = LSTMAttentionModel(\n",
    "                input_dim=X_train_tensor.shape[2],\n",
    "                num_students=num_students,\n",
    "                embed_dim=embed_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                num_heads=num_heads,\n",
    "                timesteps=timesteps,\n",
    "                dropout_rate=dropout_rate\n",
    "            ).to(device)\n",
    "        else:\n",
    "            model = LSTMModel(\n",
    "                input_dim=X_train_tensor.shape[2],\n",
    "                num_students=num_students,\n",
    "                embed_dim=embed_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                timesteps=timesteps,\n",
    "                dropout_rate=dropout_rate\n",
    "            ).to(device)\n",
    "\n",
    "        loss_risk, loss_residual = nn.CrossEntropyLoss(), nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        \n",
    "        val_size = int(len(X_train_tensor) * 0.2)\n",
    "        X_train_lstm, X_val_lstm = X_train_tensor[:-val_size], X_train_tensor[-val_size:]\n",
    "        X_train_ids_lstm, X_val_ids_lstm = X_train_ids_tensor[:-val_size], X_train_ids_tensor[-val_size:]\n",
    "        y_train_risk_lstm, y_val_risk_lstm = y_train_risk[:-val_size], y_train_risk[-val_size:]\n",
    "        y_train_residual_lstm, y_val_residual_lstm = y_train_residual[:-val_size], y_train_residual[-val_size:]\n",
    "        \n",
    "        train_dataset = TensorDataset(X_train_lstm, X_train_ids_lstm, y_train_risk_lstm, y_train_residual_lstm)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(40):\n",
    "            model.train()\n",
    "            for batch_x, batch_ids, batch_y_risk, batch_y_residual in train_loader:\n",
    "                batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                risk_logits, residual_pred = model(batch_x, batch_ids)\n",
    "                loss = risk_weight * loss_risk(risk_logits, batch_y_risk) + 1.0 * loss_residual(residual_pred, batch_y_residual)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_risk_logits, val_residual_pred = model(X_val_lstm, X_val_ids_lstm)\n",
    "                val_loss = (risk_weight * loss_risk(val_risk_logits, y_val_risk_lstm) + 1.0 * loss_residual(val_residual_pred, y_val_residual_lstm)).item()\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "        return best_val_loss\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # ðŸ”½ CETAK PARAMETER HASIL TUNING\n",
    "    print(\"\\nðŸ“Œ Hyperparameter LSTM terbaik dari tuning:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\" - {k}: {v}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 2: FUNGSI PERAMALAN DINAMIS (TIDAK BERUBAH)\n",
    "# =============================================================================\n",
    "\n",
    "def create_feature_forecasters(data, primary_feature_cols):\n",
    "    \"\"\"Membuat model peramalan sederhana untuk setiap fitur primer.\"\"\"\n",
    "    forecasters = {}\n",
    "    for col in primary_feature_cols:\n",
    "        try:\n",
    "            model = ARIMA(data[col], order=(2,1,1)).fit()\n",
    "            forecasters[col] = model\n",
    "            logging.info(f\"Feature forecaster created for {col}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Could not create forecaster for {col}: {e}\")\n",
    "            forecasters[col] = None\n",
    "    return forecasters\n",
    "\n",
    "def forecast_future(data, arima_stress_fit, model_lstm, le_student, feature_forecasters, timesteps, n_forecast, feature_cols, primary_feature_cols):\n",
    "    \"\"\"Meramalkan tingkat stres secara iteratif dengan meramalkan fitur inputnya juga.\"\"\"\n",
    "    logging.info(\"Memulai peramalan bertingkat yang dinamis...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_lstm.to(device).eval()\n",
    "\n",
    "    arima_stress_forecast = arima_stress_fit.forecast(steps=n_forecast)\n",
    "    all_forecasts = []\n",
    "\n",
    "    for student_id in data['Student ID'].unique():\n",
    "        student_history = data[data['Student ID'] == student_id].copy().reset_index(drop=True)\n",
    "        if len(student_history) < timesteps:\n",
    "            logging.warning(f\"Skipping forecast for student {student_id} due to insufficient historical data ({len(student_history)} < {timesteps}).\")\n",
    "            continue\n",
    "            \n",
    "        student_id_encoded = le_student.transform([student_id])[0]\n",
    "        \n",
    "        student_future_predictions = []\n",
    "\n",
    "        future_features_forecasts = {}\n",
    "        for col, forecaster in feature_forecasters.items():\n",
    "            if forecaster:\n",
    "                future_features_forecasts[col] = forecaster.forecast(steps=n_forecast)\n",
    "            else:\n",
    "                future_features_forecasts[col] = [student_history[col].iloc[-1]] * n_forecast\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(n_forecast):\n",
    "                input_data = student_history.tail(timesteps)\n",
    "                \n",
    "                current_features = [col for col in feature_cols if col in input_data.columns]\n",
    "                missing_features = set(feature_cols) - set(current_features)\n",
    "                if missing_features:\n",
    "                    logging.error(f\"Missing features for forecast: {missing_features}\")\n",
    "                    break\n",
    "                    \n",
    "                input_features_sequence = input_data[current_features].values.astype(np.float32)\n",
    "                \n",
    "                if 'residual' in input_data.columns:\n",
    "                    input_residuals_sequence = input_data['residual'].values.astype(np.float32).reshape(-1, 1)\n",
    "                else:\n",
    "                    input_residuals_sequence = np.zeros((timesteps, 1), dtype=np.float32)\n",
    "                    \n",
    "                input_aug = np.concatenate((input_features_sequence, input_residuals_sequence), axis=1)\n",
    "                \n",
    "                current_sequence = torch.tensor(input_aug, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                current_id_tensor = torch.tensor([student_id_encoded], dtype=torch.long).to(device)\n",
    "\n",
    "                _, lstm_residual_pred = model_lstm(current_sequence, current_id_tensor)\n",
    "                lstm_residual_pred = lstm_residual_pred.cpu().item()\n",
    "                \n",
    "                final_stress_pred = arima_stress_forecast.iloc[i] + lstm_residual_pred\n",
    "                student_future_predictions.append(final_stress_pred)\n",
    "\n",
    "                new_row_data = {\n",
    "                    'Date': student_history['Date'].iloc[-1] + pd.DateOffset(days=1),\n",
    "                    'Student ID': student_id,\n",
    "                    'Student ID Encoded': student_id_encoded,\n",
    "                    'Stress Level (GSR)': final_stress_pred,\n",
    "                    'residual': lstm_residual_pred,\n",
    "                }\n",
    "                for col in primary_feature_cols:\n",
    "                    new_row_data[col] = future_features_forecasts[col].iloc[i] if hasattr(future_features_forecasts[col], 'iloc') else future_features_forecasts[col][i]\n",
    "\n",
    "                new_row_df = pd.DataFrame([new_row_data])\n",
    "                student_history = pd.concat([student_history, new_row_df], ignore_index=True)\n",
    "                \n",
    "                student_history['lag_1_stress'] = student_history['Stress Level (GSR)'].shift(1)\n",
    "                if 'Sleep Hours' in student_history.columns:\n",
    "                    student_history['lag_1_sleep'] = student_history['Sleep Hours'].shift(1)\n",
    "                student_history['rolling_mean_stress'] = student_history['Stress Level (GSR)'].rolling(window=7, min_periods=1).mean()\n",
    "                student_history['rolling_std_stress'] = student_history['Stress Level (GSR)'].rolling(window=7, min_periods=1).std()\n",
    "                student_history.ffill(inplace=True)\n",
    "                student_history.bfill(inplace=True)\n",
    "\n",
    "        forecast_dates = pd.to_datetime([data[data['Student ID']==student_id]['Date'].max() + pd.DateOffset(days=j) for j in range(1, n_forecast + 1)])\n",
    "        forecast_df_student = pd.DataFrame({'Date': forecast_dates, 'Student ID': student_id, 'Forecasted Stress Level': student_future_predictions})\n",
    "        all_forecasts.append(forecast_df_student)\n",
    "\n",
    "    if not all_forecasts: return None\n",
    "    return pd.concat(all_forecasts, ignore_index=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 3: FUNGSI UTAMA EKSPERIMEN\n",
    "# =============================================================================\n",
    "\n",
    "def run_experiment(data, experiment_name, model_dir, feature_cols, primary_feature_cols, use_attention, timesteps=3):\n",
    "    \"\"\"Menjalankan satu siklus eksperimen penuh: training, validasi, prediksi, dan peramalan.\"\"\"\n",
    "    setup_logging(model_dir, experiment_name)\n",
    "    logging.info(f\"===== MEMULAI EKSPERIMEN: {experiment_name} =====\")\n",
    "    logging.info(f\"Menggunakan fitur: {feature_cols}\")\n",
    "    logging.info(f\"Menggunakan Attention: {use_attention}\")\n",
    "\n",
    "    # ===== Persiapan Data =====\n",
    "    all_required_cols = ['Student ID', 'Date', 'Stress Level (GSR)', 'Risk Level'] + feature_cols\n",
    "    all_required_cols = sorted(list(set(all_required_cols)))\n",
    "\n",
    "    if any(col not in data.columns for col in all_required_cols): \n",
    "        missing = [col for col in all_required_cols if col not in data.columns]\n",
    "        raise ValueError(f\"Kolom yang dibutuhkan hilang untuk eksperimen ini: {missing}\")\n",
    "    \n",
    "    data_exp = data.copy()\n",
    "    data_exp['Date'] = pd.to_datetime(data_exp['Date'])\n",
    "    data_exp = data_exp.sort_values(by=['Student ID', 'Date']).reset_index(drop=True)\n",
    "    \n",
    "    le_student = LabelEncoder()\n",
    "    data_exp['Student ID Encoded'] = le_student.fit_transform(data_exp['Student ID'])\n",
    "    with open(os.path.join(model_dir, f'label_encoder_{experiment_name}.pkl'), 'wb') as f: pickle.dump(le_student, f)\n",
    "    \n",
    "    unique_dates = data_exp['Date'].dt.date.unique()\n",
    "    if len(unique_dates) < 30: raise ValueError(f\"Tanggal unik tidak cukup: {len(unique_dates)}\")\n",
    "    \n",
    "    train_dates, test_dates = unique_dates[:24], unique_dates[24:30]\n",
    "    train_data = data_exp[data_exp['Date'].dt.date.isin(train_dates)].copy().reset_index(drop=True)\n",
    "    test_data = data_exp[data_exp['Date'].dt.date.isin(test_dates)].copy().reset_index(drop=True)\n",
    "    if len(test_data) == 0 or len(train_data) == 0: raise ValueError(\"Data latih atau uji kosong\")\n",
    "\n",
    "    target_cols = ['Risk Level', 'Stress Level (GSR)']\n",
    "    for col in feature_cols + target_cols:\n",
    "        for df in [train_data, test_data]:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(np.float32)\n",
    "            df[col] = df.groupby('Student ID')[col].transform(lambda x: x.ffill().bfill()).fillna(df[col].mean())\n",
    "\n",
    "\n",
    "    # ===== Pelatihan Model ARIMA =====\n",
    "    logging.info(\"Membuat model peramal untuk fitur-fitur primer...\")\n",
    "    feature_forecasters = create_feature_forecasters(train_data, primary_feature_cols)\n",
    "    with open(os.path.join(model_dir, f'feature_forecasters_{experiment_name}.pkl'), 'wb') as f: pickle.dump(feature_forecasters, f)\n",
    "\n",
    "    arima_train_size = int(len(train_data) * 0.8)\n",
    "    train_arima, val_arima = train_data.iloc[:arima_train_size], train_data.iloc[arima_train_size:]\n",
    "    best_params_arima, best_mae_arima = tune_arima(train_arima, val_arima)\n",
    "    logging.info(f\"Parameter ARIMA global: {best_params_arima} dengan MAE: {best_mae_arima}\")\n",
    "    \n",
    "    arima_stress_fit = ARIMA(train_data['Stress Level (GSR)'], order=best_params_arima).fit()\n",
    "    with open(os.path.join(model_dir, f'arima_stress_model_{experiment_name}.pkl'), 'wb') as f: pickle.dump(arima_stress_fit, f)\n",
    "\n",
    "    arima_train_pred = arima_stress_fit.predict(start=0, end=len(train_data) - 1)\n",
    "    arima_test_pred = arima_stress_fit.forecast(steps=len(test_data))\n",
    "    \n",
    "    train_data['residual'] = train_data['Stress Level (GSR)'].values - arima_train_pred.values\n",
    "    test_data['residual'] = test_data['Stress Level (GSR)'].values - arima_test_pred.values\n",
    "    \n",
    "    # ===== Persiapan Data untuk LSTM =====\n",
    "    train_values = train_data[feature_cols + target_cols].values\n",
    "    test_values = test_data[feature_cols + target_cols].values\n",
    "    train_student_ids = train_data['Student ID Encoded'].values\n",
    "    test_student_ids = test_data['Student ID Encoded'].values\n",
    "    X_train, X_train_ids, y_train = create_sequences(train_values, train_student_ids, target_cols, timesteps)\n",
    "    X_test, X_test_ids, y_test = create_sequences(test_values, test_student_ids, target_cols, timesteps)\n",
    "    \n",
    "    residual_train_seq = train_data.loc[timesteps:, 'residual'].values[:len(X_train)].astype(np.float32)\n",
    "    residual_test_seq = test_data.loc[timesteps:, 'residual'].values[:len(X_test)].astype(np.float32)\n",
    "    \n",
    "    X_train_aug = np.concatenate((X_train[:, :, :len(feature_cols)], residual_train_seq[:, np.newaxis, np.newaxis].repeat(timesteps, axis=1)), axis=2).astype(np.float32)\n",
    "    X_test_aug = np.concatenate((X_test[:, :, :len(feature_cols)], residual_test_seq[:, np.newaxis, np.newaxis].repeat(timesteps, axis=1)), axis=2).astype(np.float32)\n",
    "    \n",
    "    # ===== Pelatihan Model LSTM =====\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f\"Tuning LSTM (use_attention={use_attention})...\")\n",
    "    best_params_lstm = tune_lstm(torch.tensor(X_train_aug).to(device), torch.tensor(X_train_ids).to(device), torch.tensor(y_train[:, 0], dtype=torch.long).to(device), torch.tensor(residual_train_seq).to(device), timesteps, len(le_student.classes_), device, use_attention)\n",
    "    logging.info(f\"Parameter LSTM Terbaik: {best_params_lstm}\")\n",
    "\n",
    "    if use_attention:\n",
    "        model_lstm = LSTMAttentionModel(input_dim=X_train_aug.shape[2], num_students=len(le_student.classes_), embed_dim=best_params_lstm['embed_dim'], hidden_dim=best_params_lstm['hidden_dim'], num_heads=best_params_lstm['num_heads'], timesteps=timesteps, dropout_rate=best_params_lstm['dropout_rate']).to(device)\n",
    "    else:\n",
    "        model_lstm = LSTMModel(input_dim=X_train_aug.shape[2], num_students=len(le_student.classes_), embed_dim=best_params_lstm['embed_dim'], hidden_dim=best_params_lstm['hidden_dim'], timesteps=timesteps, dropout_rate=best_params_lstm['dropout_rate']).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model_lstm.parameters(), lr=best_params_lstm['lr'], weight_decay=1e-5)\n",
    "    \n",
    "    # MODIFIKASI: Split data latih menjadi train & validation untuk plotting loss curve\n",
    "    full_train_dataset = TensorDataset(torch.tensor(X_train_aug), torch.tensor(X_train_ids), torch.tensor(y_train[:, 0], dtype=torch.long), torch.tensor(residual_train_seq))\n",
    "    val_size = int(len(full_train_dataset) * 0.2)\n",
    "    train_size = len(full_train_dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # MODIFIKASI: Variabel untuk menyimpan history loss\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    logging.info(\"Memulai pelatihan akhir model LSTM...\")\n",
    "    for epoch in range(50):\n",
    "        model_lstm.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        for batch_x, batch_ids, batch_y_risk, batch_y_residual in train_loader:\n",
    "            batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            risk_logits, residual_pred = model_lstm(batch_x, batch_ids)\n",
    "            loss = best_params_lstm['risk_weight'] * nn.CrossEntropyLoss()(risk_logits, batch_y_risk) + nn.MSELoss()(residual_pred, batch_y_residual)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(epoch_train_loss / len(train_loader))\n",
    "\n",
    "        # MODIFIKASI: Kalkulasi validation loss per epoch\n",
    "        model_lstm.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_ids, batch_y_risk, batch_y_residual in val_loader:\n",
    "                batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "                risk_logits, residual_pred = model_lstm(batch_x, batch_ids)\n",
    "                loss = best_params_lstm['risk_weight'] * nn.CrossEntropyLoss()(risk_logits, batch_y_risk) + nn.MSELoss()(residual_pred, batch_y_residual)\n",
    "                epoch_val_loss += loss.item()\n",
    "        val_losses.append(epoch_val_loss / len(val_loader))\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            logging.info(f\"Epoch {epoch+1}/50, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "            \n",
    "    torch.save(model_lstm.state_dict(), os.path.join(model_dir, f'lstm_model_{experiment_name}.pth'))\n",
    "\n",
    "    # ===== Evaluasi dan Prediksi =====\n",
    "    model_lstm.eval()\n",
    "    with torch.no_grad():\n",
    "        lstm_residual_pred = model_lstm(torch.tensor(X_test_aug).to(device), torch.tensor(X_test_ids).to(device))[1].cpu().numpy()\n",
    "    \n",
    "    arima_test_pred_aligned = arima_test_pred.values[timesteps:][:len(lstm_residual_pred)]\n",
    "    hybrid_test_pred = arima_test_pred_aligned + lstm_residual_pred\n",
    "    y_true_test = y_test[:, -1]\n",
    "    \n",
    "    hybrid_mae = mean_absolute_error(y_true_test, hybrid_test_pred)\n",
    "    hybrid_rmse = np.sqrt(mean_squared_error(y_true_test, hybrid_test_pred))\n",
    "    # MODIFIKASI: MAPE tidak dihitung\n",
    "    # hybrid_mape = mean_absolute_percentage_error(y_true_test, hybrid_test_pred)\n",
    "    logging.info(f\"Kinerja Hybrid {experiment_name}:\\n - MAE: {hybrid_mae:.4f}\\n - RMSE: {hybrid_rmse:.4f}\")\n",
    "\n",
    "    # ===== Peramalan Masa Depan =====\n",
    "    test_dates_for_df = test_data['Date'].iloc[timesteps:].iloc[:len(y_true_test)]\n",
    "    test_student_ids_for_df = test_data['Student ID'].iloc[timesteps:].iloc[:len(y_true_test)]\n",
    "    predictions_df = pd.DataFrame({'Date': test_dates_for_df, 'Student ID': test_student_ids_for_df, 'Predicted Stress Level': hybrid_test_pred, 'Actual Stress Level': y_true_test})\n",
    "    \n",
    "    full_data_with_residuals = pd.concat([train_data, test_data]).sort_values(by=['Student ID', 'Date'])\n",
    "    \n",
    "    future_forecasts = forecast_future(full_data_with_residuals, arima_stress_fit, model_lstm, le_student, feature_forecasters, timesteps, 10, feature_cols, primary_feature_cols)\n",
    "\n",
    "    # ===== Plotting =====\n",
    "    logging.info(\"Membuat grafik dan file CSV untuk visualisasi...\")\n",
    "    \n",
    "    # MODIFIKASI: Membuat plot loss curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title(f'Training & Validation Loss Curve\\nEksperimen: {experiment_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(model_dir, f'plot_loss_curve_{experiment_name}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # MODIFIKASI: Buat DataFrame untuk menyimpan semua data visualisasi\n",
    "    visualization_data = []\n",
    "    \n",
    "    # 1. Tambahkan data aktual dari data_exp\n",
    "    for student_id in data_exp['Student ID'].unique():\n",
    "        student_actual_data = data_exp[data_exp['Student ID'] == student_id][['Date', 'Student ID', 'Stress Level (GSR)']]\n",
    "        for _, row in student_actual_data.iterrows():\n",
    "            visualization_data.append({\n",
    "                'Date': row['Date'],\n",
    "                'Student ID': row['Student ID'],\n",
    "                'Actual Stress Level': row['Stress Level (GSR)'],\n",
    "                'Predicted Stress Level': np.nan,\n",
    "                'Residuals': np.nan,\n",
    "                'Forecasted Stress Level': np.nan\n",
    "            })\n",
    "    \n",
    "    # 2. Tambahkan data prediksi dari predictions_df\n",
    "    for _, row in predictions_df.iterrows():\n",
    "        visualization_data.append({\n",
    "            'Date': row['Date'],\n",
    "            'Student ID': row['Student ID'],\n",
    "            'Actual Stress Level': row['Actual Stress Level'],\n",
    "            'Predicted Stress Level': row['Predicted Stress Level'],\n",
    "            'Residuals': row['Actual Stress Level'] - row['Predicted Stress Level'],\n",
    "            'Forecasted Stress Level': np.nan\n",
    "        })\n",
    "    \n",
    "    # 3. Tambahkan data peramalan dari future_forecasts (jika ada)\n",
    "    if future_forecasts is not None:\n",
    "        for _, row in future_forecasts.iterrows():\n",
    "            visualization_data.append({\n",
    "                'Date': row['Date'],\n",
    "                'Student ID': row['Student ID'],\n",
    "                'Actual Stress Level': np.nan,\n",
    "                'Predicted Stress Level': np.nan,\n",
    "                'Residuals': np.nan,\n",
    "                'Forecasted Stress Level': row['Forecasted Stress Level']\n",
    "            })\n",
    "    \n",
    "    # Buat DataFrame dari visualization_data\n",
    "    visualization_df = pd.DataFrame(visualization_data)\n",
    "    visualization_df = visualization_df.sort_values(by=['Student ID', 'Date']).reset_index(drop=True)\n",
    "    \n",
    "    # Simpan ke file CSV\n",
    "    csv_path = os.path.join(model_dir, f'visualization_data_{experiment_name}.csv')\n",
    "    visualization_df.to_csv(csv_path, index=False)\n",
    "    logging.info(f\"Data visualisasi disimpan ke {csv_path}\")\n",
    "    \n",
    "    # Plotting per siswa (tetap dipertahankan)\n",
    "    for student_id in data_exp['Student ID'].unique():\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        student_actual_data = data_exp[data_exp['Student ID'] == student_id]\n",
    "        plt.plot(student_actual_data['Date'], student_actual_data['Stress Level (GSR)'], label='Actual Stress Level', color='blue', linestyle='-')\n",
    "        \n",
    "        student_pred_data = predictions_df[predictions_df['Student ID'] == student_id]\n",
    "        if not student_pred_data.empty:\n",
    "            plt.plot(student_pred_data['Date'], student_pred_data['Predicted Stress Level'], label=f'Hybrid Prediction ({experiment_name})', color='green', linestyle='--')\n",
    "            residuals = student_pred_data['Actual Stress Level'] - student_pred_data['Predicted Stress Level']\n",
    "            plt.plot(student_pred_data['Date'], residuals, label='Residuals', color='red', linestyle=':')\n",
    "        \n",
    "        if future_forecasts is not None:\n",
    "            student_forecast_data = future_forecasts[future_forecasts['Student ID'] == student_id]\n",
    "\n",
    "            if not student_forecast_data.empty:\n",
    "                if not student_pred_data.empty:\n",
    "                    # last_pred_date = student_pred_data['Date'].last()\n",
    "                    last_pred_date = student_pred_data['Date'].iloc[-1]\n",
    "\n",
    "                    last_pred_value = student_pred_data['Predicted Stress Level'].values[-1]\n",
    "                    combined_forecast_dates = pd.concat([pd.Series([last_pred_date]), pd.Series(student_forecast_data['Date'])]).reset_index(drop=True)\n",
    "                    combined_forecast_values = pd.concat([pd.Series([last_pred_value]), pd.Series(student_forecast_data['Forecasted Stress Level'])]).reset_index(drop=True)\n",
    "                    plt.plot(combined_forecast_dates, combined_forecast_values, color='green', linestyle='--')\n",
    "                \n",
    "                plt.plot(student_forecast_data['Date'], student_forecast_data['Forecasted Stress Level'], color='orange', marker='o', linestyle='--', label='Dynamic Forecast')\n",
    "        \n",
    "        plt.title(f'Stress Level Prediction for Student {student_id}\\nEksperimen: {experiment_name}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Stress Level (GSR)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=3))\n",
    "        plt.gcf().autofmt_xdate(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(model_dir, f'plot_{experiment_name}_student_{student_id}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    logging.info(f\"===== EKSPERIMEN SELESAI: {experiment_name} =====\")\n",
    "    # MODIFIKASI: Menghapus mape_stress dari return dictionary\n",
    "    return {'mae_stress': hybrid_mae, 'rmse_stress': hybrid_rmse, 'predictions': predictions_df, 'future_forecasts': future_forecasts}\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 4: EKSEKUSI EKSPERIMEN\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data_main = pd.read_csv('dataset_baru.csv')\n",
    "        # Lakukan rekayasa fitur dasar sekali saja\n",
    "        data_main = data_main.sort_values(by=['Student ID', 'Date']).reset_index(drop=True)\n",
    "        data_main['lag_1_stress'] = data_main.groupby('Student ID')['Stress Level (GSR)'].shift(1)\n",
    "        data_main['lag_1_sleep'] = data_main.groupby('Student ID')['Sleep Hours'].shift(1)\n",
    "        data_main['rolling_mean_stress'] = data_main.groupby('Student ID')['Stress Level (GSR)'].rolling(window=7, min_periods=1).mean().reset_index(0,drop=True)\n",
    "        data_main['rolling_std_stress'] = data_main.groupby('Student ID')['Stress Level (GSR)'].rolling(window=7, min_periods=1).std().reset_index(0,drop=True)\n",
    "        data_main.ffill(inplace=True)\n",
    "        data_main.bfill(inplace=True)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File 'dataset_baru.csv' tidak ditemukan.\")\n",
    "        exit()\n",
    "\n",
    "    # Definisikan set fitur\n",
    "    features_full = ['Sleep Hours', 'Anxiety Level', 'Mood Score', 'Attendance Status (Data)', 'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']\n",
    "    primary_features_full = ['Sleep Hours', 'Anxiety Level', 'Mood Score', 'Attendance Status (Data)']\n",
    "    \n",
    "    features_reduced = ['Anxiety Level', 'Mood Score']\n",
    "    primary_features_reduced = ['Anxiety Level', 'Mood Score']\n",
    "\n",
    "    # Konfigurasi untuk 4 eksperimen\n",
    "    experiments = [\n",
    "        {\n",
    "            \"name\": \"1_Hybrid_NoAttn_FullFeatures\",\n",
    "            \"dir\": \"hasil_eksperimen baru_1_hybrid_no_attn_full_features\",\n",
    "            \"features\": features_full,\n",
    "            \"primary_features\": primary_features_full,\n",
    "            \"use_attention\": False\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"2_Hybrid_WithAttn_FullFeatures\",\n",
    "            \"dir\": \"hasil_eksperimen baru_2_hybrid_with_attn_full_features\",\n",
    "            \"features\": features_full,\n",
    "            \"primary_features\": primary_features_full,\n",
    "            \"use_attention\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"3_Hybrid_NoAttn_ReducedFeatures\",\n",
    "            \"dir\": \"hasil_eksperimen baru_3_hybrid_no_attn_reduced_features\",\n",
    "            \"features\": features_reduced,\n",
    "            \"primary_features\": primary_features_reduced,\n",
    "            \"use_attention\": False\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"4_Hybrid_WithAttn_ReducedFeatures\",\n",
    "            \"dir\": \"hasil_eksperimen baru_4_hybrid_with_attn_reduced_features\",\n",
    "            \"features\": features_reduced,\n",
    "            \"primary_features\": primary_features_reduced,\n",
    "            \"use_attention\": True\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for exp in experiments:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"MEMULAI EKSPERIMEN: {exp['name']}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        exp_start_time = time.time()\n",
    "        \n",
    "        metrics = run_experiment(\n",
    "            data=data_main,\n",
    "            experiment_name=exp['name'],\n",
    "            model_dir=exp['dir'],\n",
    "            feature_cols=exp['features'],\n",
    "            primary_feature_cols=exp['primary_features'],\n",
    "            use_attention=exp['use_attention']\n",
    "        )\n",
    "        \n",
    "        exp_end_time = time.time()\n",
    "        duration = exp_end_time - exp_start_time\n",
    "        hours, rem = divmod(duration, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "        print(f\"\\n--- HASIL UNTUK EKSPERIMEN: {exp['name']} ---\")\n",
    "        if metrics:\n",
    "            print(f\"Metrik Akhir (Hybrid pada Set Uji):\")\n",
    "            print(f\" - MAE  (Tingkat Stres): {metrics['mae_stress']:.4f}\")\n",
    "            print(f\" - RMSE (Tingkat Stres): {metrics['rmse_stress']:.4f}\")\n",
    "            # MODIFIKASI: Menghapus print MAPE\n",
    "            # print(f\" - MAPE (Tingkat Stres): {metrics['mape_stress']:.2f}%\")\n",
    "            if metrics['future_forecasts'] is not None:\n",
    "                print(\"\\nPeramalan Masa Depan Dinamis (Contoh):\")\n",
    "                print(metrics['future_forecasts'].head())\n",
    "            print(f\"\\nGrafik prediksi, peramalan, dan kurva loss telah disimpan di folder '{exp['dir']}'\") # MODIFIKASI: Menambahkan info kurva loss\n",
    "        print(f\"Waktu Eksekusi Eksperimen: {int(hours)} jam, {int(minutes)} menit, {seconds:.2f} detik\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "    total_end_time = time.time()\n",
    "    total_duration = total_end_time - total_start_time\n",
    "    total_hours, total_rem = divmod(total_duration, 3600)\n",
    "    total_minutes, total_seconds = divmod(total_rem, 60)\n",
    "    print(f\"\\nTotal Waktu Eksekusi Semua Eksperimen: {int(total_hours)} jam, {int(total_minutes)} menit, {total_seconds:.2f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31456ce-53c4-48eb-a6ad-3581f8014264",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea035747-4c03-4aac-a84e-f9cb1fa4e93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980dab00-9b65-4439-abf4-0b6c47fc9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # DAFTAR lIBRARY\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import optuna\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, confusion_matrix\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from uuid import uuid4\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c251f67f-09a7-4a5e-9df6-0b201a7e82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('student_monnitoring_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58619fa-b908-4c1b-842e-511598e0ea1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>4.56</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>3.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>3.93</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>9:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>1.30</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.07</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.67</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.99</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>9:00-16:00</td>\n",
       "      <td>Present</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Student ID        Date   Class Time Attendance Status  \\\n",
       "0               1  2024-12-01   9:00-15:00              Late   \n",
       "1               1  2024-12-02   8:00-16:00              Late   \n",
       "2               1  2024-12-03  11:00-14:00              Late   \n",
       "3               1  2024-12-04  11:00-16:00              Late   \n",
       "4               1  2024-12-05   9:00-13:00            Absent   \n",
       "...           ...         ...          ...               ...   \n",
       "14995         500  2024-12-26   9:00-16:00              Late   \n",
       "14996         500  2024-12-27   9:00-15:00            Absent   \n",
       "14997         500  2024-12-28  11:00-14:00            Absent   \n",
       "14998         500  2024-12-29  11:00-14:00              Late   \n",
       "14999         500  2024-12-30   9:00-16:00           Present   \n",
       "\n",
       "       Stress Level (GSR)  Sleep Hours  Anxiety Level  Mood Score Risk Level  \n",
       "0                    0.92          7.6              6           6        Low  \n",
       "1                    1.17          6.0              6           2     Medium  \n",
       "2                    4.56          6.3              4           8       High  \n",
       "3                    3.07          9.0              2          10        Low  \n",
       "4                    3.93          7.4              9           4       High  \n",
       "...                   ...          ...            ...         ...        ...  \n",
       "14995                1.30          7.2              7          10        Low  \n",
       "14996                1.07          7.9              4           6       High  \n",
       "14997                1.67          7.2              3           5       High  \n",
       "14998                0.99          7.2             10           9     Medium  \n",
       "14999                4.50          5.2              1           4       High  \n",
       "\n",
       "[15000 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Student ID          15000 non-null  int64  \n",
      " 1   Date                15000 non-null  object \n",
      " 2   Class Time          15000 non-null  object \n",
      " 3   Attendance Status   15000 non-null  object \n",
      " 4   Stress Level (GSR)  15000 non-null  float64\n",
      " 5   Sleep Hours         15000 non-null  float64\n",
      " 6   Anxiety Level       15000 non-null  int64  \n",
      " 7   Mood Score          15000 non-null  int64  \n",
      " 8   Risk Level          15000 non-null  object \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15000.00000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.50000</td>\n",
       "      <td>2.762538</td>\n",
       "      <td>6.996780</td>\n",
       "      <td>5.546867</td>\n",
       "      <td>5.471533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.34209</td>\n",
       "      <td>1.301927</td>\n",
       "      <td>1.150973</td>\n",
       "      <td>2.870323</td>\n",
       "      <td>2.868984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.75000</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.50000</td>\n",
       "      <td>2.760000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.25000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Student ID  Stress Level (GSR)   Sleep Hours  Anxiety Level  \\\n",
       "count  15000.00000        15000.000000  15000.000000   15000.000000   \n",
       "mean     250.50000            2.762538      6.996780       5.546867   \n",
       "std      144.34209            1.301927      1.150973       2.870323   \n",
       "min        1.00000            0.500000      5.000000       1.000000   \n",
       "25%      125.75000            1.640000      6.000000       3.000000   \n",
       "50%      250.50000            2.760000      7.000000       6.000000   \n",
       "75%      375.25000            3.900000      8.000000       8.000000   \n",
       "max      500.00000            5.000000      9.000000      10.000000   \n",
       "\n",
       "         Mood Score  \n",
       "count  15000.000000  \n",
       "mean       5.471533  \n",
       "std        2.868984  \n",
       "min        1.000000  \n",
       "25%        3.000000  \n",
       "50%        5.000000  \n",
       "75%        8.000000  \n",
       "max       10.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display((df))\n",
    "display(df.info())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c40d633-ff22-4370-be83-12fd9a111fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Missing Value pada setiap kolom:\n",
      "Student ID            0\n",
      "Date                  0\n",
      "Class Time            0\n",
      "Attendance Status     0\n",
      "Stress Level (GSR)    0\n",
      "Sleep Hours           0\n",
      "Anxiety Level         0\n",
      "Mood Score            0\n",
      "Risk Level            0\n",
      "dtype: int64\n",
      "\n",
      "Persentase Missing value pada setiap Kolim:\n",
      "Student ID            0.0\n",
      "Date                  0.0\n",
      "Class Time            0.0\n",
      "Attendance Status     0.0\n",
      "Stress Level (GSR)    0.0\n",
      "Sleep Hours           0.0\n",
      "Anxiety Level         0.0\n",
      "Mood Score            0.0\n",
      "Risk Level            0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Pengecekan Missing value pada setiap kolom\n",
    "missing_values = df.isna().sum()\n",
    "print(\"Jumlah Missing Value pada setiap kolom:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Pengecekan Presentasi Missing value per kolom\n",
    "missing_percentage = (df.isna().sum() / len(df)) * 100\n",
    "print(\"\\nPersentase Missing value pada setiap Kolim:\")\n",
    "print(missing_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9270f3a6-40b0-4555-a6aa-1963266fc757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected by Z-Score:\n",
      "Empty DataFrame\n",
      "Columns: [Student ID, Date, Class Time, Attendance Status, Stress Level (GSR), Sleep Hours, Anxiety Level, Mood Score, Risk Level]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Menghitung Z-Score untuk kolom-kolom numerik\n",
    "import numpy as np\n",
    "z_scores = zscore(df[['Stress Level (GSR)', 'Anxiety Level', 'Mood Score', 'Sleep Hours']])\n",
    "\n",
    "# Menyaring data dengan Z-Score > 3 atau < -3\n",
    "outliers_z = np.where(abs(z_scores) > 3)  # Menemukan posisi outlier berdasarkan Z-Score\n",
    "\n",
    "# Menampilkan data outlier berdasarkan Z-Score\n",
    "outliers_z_data = df.iloc[outliers_z[0]]\n",
    "print(\"Outliers detected by Z-Score:\")\n",
    "print(outliers_z_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fee54b8-9632-4157-b9de-be3f99104d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected by Z-Score per user:\n",
      "Empty DataFrame\n",
      "Columns: [Stress Level (GSR), Anxiety Level, Mood Score, Sleep Hours]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Menghitung Z-Score per user\n",
    "def calculate_zscore_per_user(df, columns):\n",
    "    outliers = []  # Untuk menyimpan hasil outlier per user\n",
    "    for user_id in df['Student ID'].unique():  # Loop melalui setiap user\n",
    "        user_data = df[df['Student ID'] == user_id][columns]\n",
    "        z_scores = zscore(user_data, axis=0)  # Menghitung Z-Score per kolom untuk user tertentu\n",
    "\n",
    "        # Mencari outlier untuk Z-Score > 3 atau < -3\n",
    "        outliers_for_user = user_data[(abs(z_scores) > 3).any(axis=1)]  # Filter baris dengan Z-Score > 3\n",
    "        outliers.append(outliers_for_user)\n",
    "\n",
    "    # Gabungkan semua outliers per user\n",
    "    return pd.concat(outliers)\n",
    "\n",
    "# Tentukan kolom yang ingin dianalisis (kolom numerik)\n",
    "columns_to_check = ['Stress Level (GSR)', 'Anxiety Level', 'Mood Score', 'Sleep Hours']\n",
    "\n",
    "# Temukan outliers untuk seluruh dataset\n",
    "outliers_z_data_per_user = calculate_zscore_per_user(df, columns_to_check)\n",
    "\n",
    "print(\"Outliers detected by Z-Score per user:\")\n",
    "print(outliers_z_data_per_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3249ab6-c8ad-4040-8891-2a05db87991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2024-12-01\n",
      "1   2024-12-02\n",
      "2   2024-12-03\n",
      "3   2024-12-04\n",
      "4   2024-12-05\n",
      "Name: Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Mengonversi kolom 'Date' menjadi format datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df['Date'].head())\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "df = df.sort_values(by=['Student ID', 'Date'])\n",
    "\n",
    "user_day_count = df.groupby('Student ID')['Date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a730061-cd44-418e-918f-b711d40a9256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>4.56</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>3.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>3.93</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late                0.92   \n",
       "1           1 2024-12-02   8:00-16:00              Late                1.17   \n",
       "2           1 2024-12-03  11:00-14:00              Late                4.56   \n",
       "3           1 2024-12-04  11:00-16:00              Late                3.07   \n",
       "4           1 2024-12-05   9:00-13:00            Absent                3.93   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0          7.6              6           6           1    1   \n",
       "1          6.0              6           2           2    2   \n",
       "2          6.3              4           8           0    3   \n",
       "3          9.0              2          10           1    4   \n",
       "4          7.4              9           4           0    5   \n",
       "\n",
       "   Attendance Status (Data)  \n",
       "0                         2  \n",
       "1                         2  \n",
       "2                         2  \n",
       "3                         2  \n",
       "4                         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label Encoding untuk Risk Level\n",
    "le = LabelEncoder()\n",
    "df['Risk Level'] = le.fit_transform(df['Risk Level'])\n",
    "\n",
    "\n",
    "# label Encoder Untuk ateendande Status\n",
    "attendance_mapping = {'Present': 0, 'Absent': 1, 'Late': 2}\n",
    "df['Attendance Status (Data)'] = df['Attendance Status'].map(attendance_mapping)\n",
    "df['Attendance Status (Data)'] = df['Attendance Status (Data)'].astype('Int64')\n",
    "df[['Attendance Status', 'Attendance Status (Data)']].head()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747cef87-3a89-49cc-b44b-761d50b06818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.350341</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late            0.093333   \n",
       "1           1 2024-12-02   8:00-16:00              Late            0.148889   \n",
       "2           1 2024-12-03  11:00-14:00              Late            0.902222   \n",
       "3           1 2024-12-04  11:00-16:00              Late            0.571111   \n",
       "4           1 2024-12-05   9:00-13:00            Absent            0.762222   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0     0.524113       0.555556    0.555556           1    1   \n",
       "1    -0.866061       0.555556    0.111111           2    2   \n",
       "2    -0.605403       0.333333    0.777778           0    3   \n",
       "3     1.740515       0.111111    1.000000           1    4   \n",
       "4     0.350341       0.888889    0.333333           0    5   \n",
       "\n",
       "   Attendance Status (Data)  \n",
       "0                         2  \n",
       "1                         2  \n",
       "2                         2  \n",
       "3                         2  \n",
       "4                         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Memilih kolom untuk Min-Max Scaling dan Standardization\n",
    "cols_min_max = ['Stress Level (GSR)', 'Anxiety Level', 'Mood Score']\n",
    "cols_standardize = ['Sleep Hours']\n",
    "\n",
    "# Membuat objek scaler untuk Min-Max dan Standardization\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Melakukan Min-Max Scaling pada kolom yang dipilih\n",
    "df[cols_min_max] = min_max_scaler.fit_transform(df[cols_min_max])\n",
    "\n",
    "# Melakukan Standardization pada kolom yang dipilih\n",
    "df[cols_standardize] = standard_scaler.fit_transform(df[cols_standardize])\n",
    "\n",
    "# Menampilkan hasil setelah scaling dan standardisasi\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e4bd196-1999-44e5-aef0-c58403f1abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "      <th>lag_1_stress</th>\n",
       "      <th>lag_1_sleep</th>\n",
       "      <th>rolling_mean_stress</th>\n",
       "      <th>rolling_std_stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.381481</td>\n",
       "      <td>0.451829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.350341</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.745185</td>\n",
       "      <td>0.166212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late            0.093333   \n",
       "1           1 2024-12-02   8:00-16:00              Late            0.148889   \n",
       "2           1 2024-12-03  11:00-14:00              Late            0.902222   \n",
       "3           1 2024-12-04  11:00-16:00              Late            0.571111   \n",
       "4           1 2024-12-05   9:00-13:00            Absent            0.762222   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0     0.524113       0.555556    0.555556           1    1   \n",
       "1    -0.866061       0.555556    0.111111           2    2   \n",
       "2    -0.605403       0.333333    0.777778           0    3   \n",
       "3     1.740515       0.111111    1.000000           1    4   \n",
       "4     0.350341       0.888889    0.333333           0    5   \n",
       "\n",
       "   Attendance Status (Data)  lag_1_stress  lag_1_sleep  rolling_mean_stress  \\\n",
       "0                         2           NaN          NaN                  NaN   \n",
       "1                         2      0.093333     0.524113                  NaN   \n",
       "2                         2      0.148889    -0.866061             0.381481   \n",
       "3                         2      0.902222    -0.605403             0.540741   \n",
       "4                         1      0.571111     1.740515             0.745185   \n",
       "\n",
       "   rolling_std_stress  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2            0.451829  \n",
       "3            0.377584  \n",
       "4            0.166212  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lag Features untuk Stress Level (GSR) dan Sleep Hours\n",
    "df['lag_1_stress'] = df.groupby('Student ID')['Stress Level (GSR)'].shift(1)\n",
    "df['lag_1_sleep'] = df.groupby('Student ID')['Sleep Hours'].shift(1)\n",
    "\n",
    "# Rolling Statistics untuk Stress Level (GSR) dengan window size 3 (misalnya 3 hari)\n",
    "df['rolling_mean_stress'] = df.groupby('Student ID')['Stress Level (GSR)'].rolling(window=3).mean().reset_index(0, drop=True)\n",
    "df['rolling_std_stress'] = df.groupby('Student ID')['Stress Level (GSR)'].rolling(window=3).std().reset_index(0, drop=True)\n",
    "\n",
    "# Menampilkan hasil setelah menambahkan lag features dan rolling statistics\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386eff1c-c31b-4de6-89fd-b7cd9136bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_5636\\23598078.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  p_values = df.groupby('Student ID').apply(lambda group: check_stationarity(group, 'Stress Level (GSR)'))\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Fungsi untuk uji ADF pada setiap Student ID\n",
    "def check_stationarity(data, col):\n",
    "    result = adfuller(df[col].dropna())\n",
    "    return result[1]  # Mengembalikan p-value\n",
    "\n",
    "# Menguji stasioneritas untuk setiap Student ID\n",
    "p_values = df.groupby('Student ID').apply(lambda group: check_stationarity(group, 'Stress Level (GSR)'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b90567-b7e9-46f7-90f9-1996f155f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HASIL UJI STASIONERITAS =====\n",
      "Student ID yang STASIONER:\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]\n",
      "\n",
      "Student ID yang BELUM STASIONER:\n",
      "[6, 456]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Fungsi untuk mengecek stasioneritas\n",
    "def check_stationarity(data, col):\n",
    "    result = adfuller(data[col].dropna())\n",
    "    return result[1]  # Mengembalikan p-value\n",
    "\n",
    "# Fungsi untuk melakukan differencing\n",
    "def difference_data(data, col, d=1):\n",
    "    data_copy = data.copy()\n",
    "    for _ in range(d):\n",
    "        data_copy[col] = data_copy[col].diff()\n",
    "    return data_copy\n",
    "\n",
    "# Inisialisasi variabel\n",
    "stationary_ids = []\n",
    "non_stationary_ids = []\n",
    "p_values_initial = {}\n",
    "p_values_after_diff = {}\n",
    "df_processed = []\n",
    "\n",
    "# Loop per Student ID\n",
    "for student_id in df['Student ID'].unique():\n",
    "    data_sub = df[df['Student ID'] == student_id].copy()\n",
    "\n",
    "    # Cek stasioneritas awal\n",
    "    p_value = check_stationarity(data_sub, 'Stress Level (GSR)')\n",
    "    p_values_initial[student_id] = p_value\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        # Sudah stasioner\n",
    "        stationary_ids.append(student_id)\n",
    "        p_values_after_diff[student_id] = p_value\n",
    "    else:\n",
    "        # Belum stasioner, lakukan differencing pertama\n",
    "        data_sub = difference_data(data_sub, 'Stress Level (GSR)', d=1)\n",
    "        p_value = check_stationarity(data_sub, 'Stress Level (GSR)')\n",
    "        p_values_after_diff[student_id] = p_value\n",
    "\n",
    "        if p_value <= 0.05:\n",
    "            stationary_ids.append(student_id)\n",
    "        else:\n",
    "            # Lakukan differencing kedua\n",
    "            data_sub = difference_data(data_sub, 'Stress Level (GSR)', d=2)\n",
    "            p_value = check_stationarity(data_sub, 'Stress Level (GSR)')\n",
    "            p_values_after_diff[student_id] = p_value\n",
    "\n",
    "            if p_value <= 0.05:\n",
    "                stationary_ids.append(student_id)\n",
    "            else:\n",
    "                non_stationary_ids.append(student_id)\n",
    "\n",
    "    df_processed.append(data_sub)\n",
    "\n",
    "# Tampilkan daftar hasil akhir\n",
    "print(\"\\n===== HASIL UJI STASIONERITAS =====\")\n",
    "print(\"Student ID yang STASIONER:\")\n",
    "print(stationary_ids)\n",
    "\n",
    "print(\"\\nStudent ID yang BELUM STASIONER:\")\n",
    "print(non_stationary_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3058516e-9d11-4fd8-a631-5d040e0b3288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "      <th>lag_1_stress</th>\n",
       "      <th>lag_1_sleep</th>\n",
       "      <th>rolling_mean_stress</th>\n",
       "      <th>rolling_std_stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.381481</td>\n",
       "      <td>0.451829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.350341</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.745185</td>\n",
       "      <td>0.166212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late            0.093333   \n",
       "1           1 2024-12-02   8:00-16:00              Late            0.148889   \n",
       "2           1 2024-12-03  11:00-14:00              Late            0.902222   \n",
       "3           1 2024-12-04  11:00-16:00              Late            0.571111   \n",
       "4           1 2024-12-05   9:00-13:00            Absent            0.762222   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0     0.524113       0.555556    0.555556           1    1   \n",
       "1    -0.866061       0.555556    0.111111           2    2   \n",
       "2    -0.605403       0.333333    0.777778           0    3   \n",
       "3     1.740515       0.111111    1.000000           1    4   \n",
       "4     0.350341       0.888889    0.333333           0    5   \n",
       "\n",
       "   Attendance Status (Data)  lag_1_stress  lag_1_sleep  rolling_mean_stress  \\\n",
       "0                         2           NaN          NaN                  NaN   \n",
       "1                         2      0.093333     0.524113                  NaN   \n",
       "2                         2      0.148889    -0.866061             0.381481   \n",
       "3                         2      0.902222    -0.605403             0.540741   \n",
       "4                         1      0.571111     1.740515             0.745185   \n",
       "\n",
       "   rolling_std_stress  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2            0.451829  \n",
       "3            0.377584  \n",
       "4            0.166212  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menggunakan interpolasi linear untuk mengisi NaN setelah differencing\n",
    "df[['Stress Level (GSR)', 'Sleep Hours', 'Anxiety Level', 'Mood Score',\n",
    "      'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']] = \\\n",
    "    df[['Stress Level (GSR)', 'Sleep Hours', 'Anxiety Level', 'Mood Score',\n",
    "          'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']].interpolate(method='linear')\n",
    "\n",
    "# Menampilkan data setelah interpolasi\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6dfb4b3-b100-4007-b21a-87b9d7ac0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== JUMLAH OBSERVASI PER STUDENT ID =====\n",
      "Student ID 1: 30 observasi\n",
      "Student ID 2: 30 observasi\n",
      "Student ID 3: 30 observasi\n",
      "Student ID 4: 30 observasi\n",
      "Student ID 5: 30 observasi\n",
      "Student ID 6: 30 observasi\n",
      "Student ID 7: 30 observasi\n",
      "Student ID 8: 30 observasi\n",
      "Student ID 9: 30 observasi\n",
      "Student ID 10: 30 observasi\n",
      "Student ID 11: 30 observasi\n",
      "Student ID 12: 30 observasi\n",
      "Student ID 13: 30 observasi\n",
      "Student ID 14: 30 observasi\n",
      "Student ID 15: 30 observasi\n",
      "Student ID 16: 30 observasi\n",
      "Student ID 17: 30 observasi\n",
      "Student ID 18: 30 observasi\n",
      "Student ID 19: 30 observasi\n",
      "Student ID 20: 30 observasi\n",
      "Student ID 21: 30 observasi\n",
      "Student ID 22: 30 observasi\n",
      "Student ID 23: 30 observasi\n",
      "Student ID 24: 30 observasi\n",
      "Student ID 25: 30 observasi\n",
      "Student ID 26: 30 observasi\n",
      "Student ID 27: 30 observasi\n",
      "Student ID 28: 30 observasi\n",
      "Student ID 29: 30 observasi\n",
      "Student ID 30: 30 observasi\n",
      "Student ID 31: 30 observasi\n",
      "Student ID 32: 30 observasi\n",
      "Student ID 33: 30 observasi\n",
      "Student ID 34: 30 observasi\n",
      "Student ID 35: 30 observasi\n",
      "Student ID 36: 30 observasi\n",
      "Student ID 37: 30 observasi\n",
      "Student ID 38: 30 observasi\n",
      "Student ID 39: 30 observasi\n",
      "Student ID 40: 30 observasi\n",
      "Student ID 41: 30 observasi\n",
      "Student ID 42: 30 observasi\n",
      "Student ID 43: 30 observasi\n",
      "Student ID 44: 30 observasi\n",
      "Student ID 45: 30 observasi\n",
      "Student ID 46: 30 observasi\n",
      "Student ID 47: 30 observasi\n",
      "Student ID 48: 30 observasi\n",
      "Student ID 49: 30 observasi\n",
      "Student ID 50: 30 observasi\n",
      "Student ID 51: 30 observasi\n",
      "Student ID 52: 30 observasi\n",
      "Student ID 53: 30 observasi\n",
      "Student ID 54: 30 observasi\n",
      "Student ID 55: 30 observasi\n",
      "Student ID 56: 30 observasi\n",
      "Student ID 57: 30 observasi\n",
      "Student ID 58: 30 observasi\n",
      "Student ID 59: 30 observasi\n",
      "Student ID 60: 30 observasi\n",
      "Student ID 61: 30 observasi\n",
      "Student ID 62: 30 observasi\n",
      "Student ID 63: 30 observasi\n",
      "Student ID 64: 30 observasi\n",
      "Student ID 65: 30 observasi\n",
      "Student ID 66: 30 observasi\n",
      "Student ID 67: 30 observasi\n",
      "Student ID 68: 30 observasi\n",
      "Student ID 69: 30 observasi\n",
      "Student ID 70: 30 observasi\n",
      "Student ID 71: 30 observasi\n",
      "Student ID 72: 30 observasi\n",
      "Student ID 73: 30 observasi\n",
      "Student ID 74: 30 observasi\n",
      "Student ID 75: 30 observasi\n",
      "Student ID 76: 30 observasi\n",
      "Student ID 77: 30 observasi\n",
      "Student ID 78: 30 observasi\n",
      "Student ID 79: 30 observasi\n",
      "Student ID 80: 30 observasi\n",
      "Student ID 81: 30 observasi\n",
      "Student ID 82: 30 observasi\n",
      "Student ID 83: 30 observasi\n",
      "Student ID 84: 30 observasi\n",
      "Student ID 85: 30 observasi\n",
      "Student ID 86: 30 observasi\n",
      "Student ID 87: 30 observasi\n",
      "Student ID 88: 30 observasi\n",
      "Student ID 89: 30 observasi\n",
      "Student ID 90: 30 observasi\n",
      "Student ID 91: 30 observasi\n",
      "Student ID 92: 30 observasi\n",
      "Student ID 93: 30 observasi\n",
      "Student ID 94: 30 observasi\n",
      "Student ID 95: 30 observasi\n",
      "Student ID 96: 30 observasi\n",
      "Student ID 97: 30 observasi\n",
      "Student ID 98: 30 observasi\n",
      "Student ID 99: 30 observasi\n",
      "Student ID 100: 30 observasi\n",
      "Student ID 101: 30 observasi\n",
      "Student ID 102: 30 observasi\n",
      "Student ID 103: 30 observasi\n",
      "Student ID 104: 30 observasi\n",
      "Student ID 105: 30 observasi\n",
      "Student ID 106: 30 observasi\n",
      "Student ID 107: 30 observasi\n",
      "Student ID 108: 30 observasi\n",
      "Student ID 109: 30 observasi\n",
      "Student ID 110: 30 observasi\n",
      "Student ID 111: 30 observasi\n",
      "Student ID 112: 30 observasi\n",
      "Student ID 113: 30 observasi\n",
      "Student ID 114: 30 observasi\n",
      "Student ID 115: 30 observasi\n",
      "Student ID 116: 30 observasi\n",
      "Student ID 117: 30 observasi\n",
      "Student ID 118: 30 observasi\n",
      "Student ID 119: 30 observasi\n",
      "Student ID 120: 30 observasi\n",
      "Student ID 121: 30 observasi\n",
      "Student ID 122: 30 observasi\n",
      "Student ID 123: 30 observasi\n",
      "Student ID 124: 30 observasi\n",
      "Student ID 125: 30 observasi\n",
      "Student ID 126: 30 observasi\n",
      "Student ID 127: 30 observasi\n",
      "Student ID 128: 30 observasi\n",
      "Student ID 129: 30 observasi\n",
      "Student ID 130: 30 observasi\n",
      "Student ID 131: 30 observasi\n",
      "Student ID 132: 30 observasi\n",
      "Student ID 133: 30 observasi\n",
      "Student ID 134: 30 observasi\n",
      "Student ID 135: 30 observasi\n",
      "Student ID 136: 30 observasi\n",
      "Student ID 137: 30 observasi\n",
      "Student ID 138: 30 observasi\n",
      "Student ID 139: 30 observasi\n",
      "Student ID 140: 30 observasi\n",
      "Student ID 141: 30 observasi\n",
      "Student ID 142: 30 observasi\n",
      "Student ID 143: 30 observasi\n",
      "Student ID 144: 30 observasi\n",
      "Student ID 145: 30 observasi\n",
      "Student ID 146: 30 observasi\n",
      "Student ID 147: 30 observasi\n",
      "Student ID 148: 30 observasi\n",
      "Student ID 149: 30 observasi\n",
      "Student ID 150: 30 observasi\n",
      "Student ID 151: 30 observasi\n",
      "Student ID 152: 30 observasi\n",
      "Student ID 153: 30 observasi\n",
      "Student ID 154: 30 observasi\n",
      "Student ID 155: 30 observasi\n",
      "Student ID 156: 30 observasi\n",
      "Student ID 157: 30 observasi\n",
      "Student ID 158: 30 observasi\n",
      "Student ID 159: 30 observasi\n",
      "Student ID 160: 30 observasi\n",
      "Student ID 161: 30 observasi\n",
      "Student ID 162: 30 observasi\n",
      "Student ID 163: 30 observasi\n",
      "Student ID 164: 30 observasi\n",
      "Student ID 165: 30 observasi\n",
      "Student ID 166: 30 observasi\n",
      "Student ID 167: 30 observasi\n",
      "Student ID 168: 30 observasi\n",
      "Student ID 169: 30 observasi\n",
      "Student ID 170: 30 observasi\n",
      "Student ID 171: 30 observasi\n",
      "Student ID 172: 30 observasi\n",
      "Student ID 173: 30 observasi\n",
      "Student ID 174: 30 observasi\n",
      "Student ID 175: 30 observasi\n",
      "Student ID 176: 30 observasi\n",
      "Student ID 177: 30 observasi\n",
      "Student ID 178: 30 observasi\n",
      "Student ID 179: 30 observasi\n",
      "Student ID 180: 30 observasi\n",
      "Student ID 181: 30 observasi\n",
      "Student ID 182: 30 observasi\n",
      "Student ID 183: 30 observasi\n",
      "Student ID 184: 30 observasi\n",
      "Student ID 185: 30 observasi\n",
      "Student ID 186: 30 observasi\n",
      "Student ID 187: 30 observasi\n",
      "Student ID 188: 30 observasi\n",
      "Student ID 189: 30 observasi\n",
      "Student ID 190: 30 observasi\n",
      "Student ID 191: 30 observasi\n",
      "Student ID 192: 30 observasi\n",
      "Student ID 193: 30 observasi\n",
      "Student ID 194: 30 observasi\n",
      "Student ID 195: 30 observasi\n",
      "Student ID 196: 30 observasi\n",
      "Student ID 197: 30 observasi\n",
      "Student ID 198: 30 observasi\n",
      "Student ID 199: 30 observasi\n",
      "Student ID 200: 30 observasi\n",
      "Student ID 201: 30 observasi\n",
      "Student ID 202: 30 observasi\n",
      "Student ID 203: 30 observasi\n",
      "Student ID 204: 30 observasi\n",
      "Student ID 205: 30 observasi\n",
      "Student ID 206: 30 observasi\n",
      "Student ID 207: 30 observasi\n",
      "Student ID 208: 30 observasi\n",
      "Student ID 209: 30 observasi\n",
      "Student ID 210: 30 observasi\n",
      "Student ID 211: 30 observasi\n",
      "Student ID 212: 30 observasi\n",
      "Student ID 213: 30 observasi\n",
      "Student ID 214: 30 observasi\n",
      "Student ID 215: 30 observasi\n",
      "Student ID 216: 30 observasi\n",
      "Student ID 217: 30 observasi\n",
      "Student ID 218: 30 observasi\n",
      "Student ID 219: 30 observasi\n",
      "Student ID 220: 30 observasi\n",
      "Student ID 221: 30 observasi\n",
      "Student ID 222: 30 observasi\n",
      "Student ID 223: 30 observasi\n",
      "Student ID 224: 30 observasi\n",
      "Student ID 225: 30 observasi\n",
      "Student ID 226: 30 observasi\n",
      "Student ID 227: 30 observasi\n",
      "Student ID 228: 30 observasi\n",
      "Student ID 229: 30 observasi\n",
      "Student ID 230: 30 observasi\n",
      "Student ID 231: 30 observasi\n",
      "Student ID 232: 30 observasi\n",
      "Student ID 233: 30 observasi\n",
      "Student ID 234: 30 observasi\n",
      "Student ID 235: 30 observasi\n",
      "Student ID 236: 30 observasi\n",
      "Student ID 237: 30 observasi\n",
      "Student ID 238: 30 observasi\n",
      "Student ID 239: 30 observasi\n",
      "Student ID 240: 30 observasi\n",
      "Student ID 241: 30 observasi\n",
      "Student ID 242: 30 observasi\n",
      "Student ID 243: 30 observasi\n",
      "Student ID 244: 30 observasi\n",
      "Student ID 245: 30 observasi\n",
      "Student ID 246: 30 observasi\n",
      "Student ID 247: 30 observasi\n",
      "Student ID 248: 30 observasi\n",
      "Student ID 249: 30 observasi\n",
      "Student ID 250: 30 observasi\n",
      "Student ID 251: 30 observasi\n",
      "Student ID 252: 30 observasi\n",
      "Student ID 253: 30 observasi\n",
      "Student ID 254: 30 observasi\n",
      "Student ID 255: 30 observasi\n",
      "Student ID 256: 30 observasi\n",
      "Student ID 257: 30 observasi\n",
      "Student ID 258: 30 observasi\n",
      "Student ID 259: 30 observasi\n",
      "Student ID 260: 30 observasi\n",
      "Student ID 261: 30 observasi\n",
      "Student ID 262: 30 observasi\n",
      "Student ID 263: 30 observasi\n",
      "Student ID 264: 30 observasi\n",
      "Student ID 265: 30 observasi\n",
      "Student ID 266: 30 observasi\n",
      "Student ID 267: 30 observasi\n",
      "Student ID 268: 30 observasi\n",
      "Student ID 269: 30 observasi\n",
      "Student ID 270: 30 observasi\n",
      "Student ID 271: 30 observasi\n",
      "Student ID 272: 30 observasi\n",
      "Student ID 273: 30 observasi\n",
      "Student ID 274: 30 observasi\n",
      "Student ID 275: 30 observasi\n",
      "Student ID 276: 30 observasi\n",
      "Student ID 277: 30 observasi\n",
      "Student ID 278: 30 observasi\n",
      "Student ID 279: 30 observasi\n",
      "Student ID 280: 30 observasi\n",
      "Student ID 281: 30 observasi\n",
      "Student ID 282: 30 observasi\n",
      "Student ID 283: 30 observasi\n",
      "Student ID 284: 30 observasi\n",
      "Student ID 285: 30 observasi\n",
      "Student ID 286: 30 observasi\n",
      "Student ID 287: 30 observasi\n",
      "Student ID 288: 30 observasi\n",
      "Student ID 289: 30 observasi\n",
      "Student ID 290: 30 observasi\n",
      "Student ID 291: 30 observasi\n",
      "Student ID 292: 30 observasi\n",
      "Student ID 293: 30 observasi\n",
      "Student ID 294: 30 observasi\n",
      "Student ID 295: 30 observasi\n",
      "Student ID 296: 30 observasi\n",
      "Student ID 297: 30 observasi\n",
      "Student ID 298: 30 observasi\n",
      "Student ID 299: 30 observasi\n",
      "Student ID 300: 30 observasi\n",
      "Student ID 301: 30 observasi\n",
      "Student ID 302: 30 observasi\n",
      "Student ID 303: 30 observasi\n",
      "Student ID 304: 30 observasi\n",
      "Student ID 305: 30 observasi\n",
      "Student ID 306: 30 observasi\n",
      "Student ID 307: 30 observasi\n",
      "Student ID 308: 30 observasi\n",
      "Student ID 309: 30 observasi\n",
      "Student ID 310: 30 observasi\n",
      "Student ID 311: 30 observasi\n",
      "Student ID 312: 30 observasi\n",
      "Student ID 313: 30 observasi\n",
      "Student ID 314: 30 observasi\n",
      "Student ID 315: 30 observasi\n",
      "Student ID 316: 30 observasi\n",
      "Student ID 317: 30 observasi\n",
      "Student ID 318: 30 observasi\n",
      "Student ID 319: 30 observasi\n",
      "Student ID 320: 30 observasi\n",
      "Student ID 321: 30 observasi\n",
      "Student ID 322: 30 observasi\n",
      "Student ID 323: 30 observasi\n",
      "Student ID 324: 30 observasi\n",
      "Student ID 325: 30 observasi\n",
      "Student ID 326: 30 observasi\n",
      "Student ID 327: 30 observasi\n",
      "Student ID 328: 30 observasi\n",
      "Student ID 329: 30 observasi\n",
      "Student ID 330: 30 observasi\n",
      "Student ID 331: 30 observasi\n",
      "Student ID 332: 30 observasi\n",
      "Student ID 333: 30 observasi\n",
      "Student ID 334: 30 observasi\n",
      "Student ID 335: 30 observasi\n",
      "Student ID 336: 30 observasi\n",
      "Student ID 337: 30 observasi\n",
      "Student ID 338: 30 observasi\n",
      "Student ID 339: 30 observasi\n",
      "Student ID 340: 30 observasi\n",
      "Student ID 341: 30 observasi\n",
      "Student ID 342: 30 observasi\n",
      "Student ID 343: 30 observasi\n",
      "Student ID 344: 30 observasi\n",
      "Student ID 345: 30 observasi\n",
      "Student ID 346: 30 observasi\n",
      "Student ID 347: 30 observasi\n",
      "Student ID 348: 30 observasi\n",
      "Student ID 349: 30 observasi\n",
      "Student ID 350: 30 observasi\n",
      "Student ID 351: 30 observasi\n",
      "Student ID 352: 30 observasi\n",
      "Student ID 353: 30 observasi\n",
      "Student ID 354: 30 observasi\n",
      "Student ID 355: 30 observasi\n",
      "Student ID 356: 30 observasi\n",
      "Student ID 357: 30 observasi\n",
      "Student ID 358: 30 observasi\n",
      "Student ID 359: 30 observasi\n",
      "Student ID 360: 30 observasi\n",
      "Student ID 361: 30 observasi\n",
      "Student ID 362: 30 observasi\n",
      "Student ID 363: 30 observasi\n",
      "Student ID 364: 30 observasi\n",
      "Student ID 365: 30 observasi\n",
      "Student ID 366: 30 observasi\n",
      "Student ID 367: 30 observasi\n",
      "Student ID 368: 30 observasi\n",
      "Student ID 369: 30 observasi\n",
      "Student ID 370: 30 observasi\n",
      "Student ID 371: 30 observasi\n",
      "Student ID 372: 30 observasi\n",
      "Student ID 373: 30 observasi\n",
      "Student ID 374: 30 observasi\n",
      "Student ID 375: 30 observasi\n",
      "Student ID 376: 30 observasi\n",
      "Student ID 377: 30 observasi\n",
      "Student ID 378: 30 observasi\n",
      "Student ID 379: 30 observasi\n",
      "Student ID 380: 30 observasi\n",
      "Student ID 381: 30 observasi\n",
      "Student ID 382: 30 observasi\n",
      "Student ID 383: 30 observasi\n",
      "Student ID 384: 30 observasi\n",
      "Student ID 385: 30 observasi\n",
      "Student ID 386: 30 observasi\n",
      "Student ID 387: 30 observasi\n",
      "Student ID 388: 30 observasi\n",
      "Student ID 389: 30 observasi\n",
      "Student ID 390: 30 observasi\n",
      "Student ID 391: 30 observasi\n",
      "Student ID 392: 30 observasi\n",
      "Student ID 393: 30 observasi\n",
      "Student ID 394: 30 observasi\n",
      "Student ID 395: 30 observasi\n",
      "Student ID 396: 30 observasi\n",
      "Student ID 397: 30 observasi\n",
      "Student ID 398: 30 observasi\n",
      "Student ID 399: 30 observasi\n",
      "Student ID 400: 30 observasi\n",
      "Student ID 401: 30 observasi\n",
      "Student ID 402: 30 observasi\n",
      "Student ID 403: 30 observasi\n",
      "Student ID 404: 30 observasi\n",
      "Student ID 405: 30 observasi\n",
      "Student ID 406: 30 observasi\n",
      "Student ID 407: 30 observasi\n",
      "Student ID 408: 30 observasi\n",
      "Student ID 409: 30 observasi\n",
      "Student ID 410: 30 observasi\n",
      "Student ID 411: 30 observasi\n",
      "Student ID 412: 30 observasi\n",
      "Student ID 413: 30 observasi\n",
      "Student ID 414: 30 observasi\n",
      "Student ID 415: 30 observasi\n",
      "Student ID 416: 30 observasi\n",
      "Student ID 417: 30 observasi\n",
      "Student ID 418: 30 observasi\n",
      "Student ID 419: 30 observasi\n",
      "Student ID 420: 30 observasi\n",
      "Student ID 421: 30 observasi\n",
      "Student ID 422: 30 observasi\n",
      "Student ID 423: 30 observasi\n",
      "Student ID 424: 30 observasi\n",
      "Student ID 425: 30 observasi\n",
      "Student ID 426: 30 observasi\n",
      "Student ID 427: 30 observasi\n",
      "Student ID 428: 30 observasi\n",
      "Student ID 429: 30 observasi\n",
      "Student ID 430: 30 observasi\n",
      "Student ID 431: 30 observasi\n",
      "Student ID 432: 30 observasi\n",
      "Student ID 433: 30 observasi\n",
      "Student ID 434: 30 observasi\n",
      "Student ID 435: 30 observasi\n",
      "Student ID 436: 30 observasi\n",
      "Student ID 437: 30 observasi\n",
      "Student ID 438: 30 observasi\n",
      "Student ID 439: 30 observasi\n",
      "Student ID 440: 30 observasi\n",
      "Student ID 441: 30 observasi\n",
      "Student ID 442: 30 observasi\n",
      "Student ID 443: 30 observasi\n",
      "Student ID 444: 30 observasi\n",
      "Student ID 445: 30 observasi\n",
      "Student ID 446: 30 observasi\n",
      "Student ID 447: 30 observasi\n",
      "Student ID 448: 30 observasi\n",
      "Student ID 449: 30 observasi\n",
      "Student ID 450: 30 observasi\n",
      "Student ID 451: 30 observasi\n",
      "Student ID 452: 30 observasi\n",
      "Student ID 453: 30 observasi\n",
      "Student ID 454: 30 observasi\n",
      "Student ID 455: 30 observasi\n",
      "Student ID 456: 30 observasi\n",
      "Student ID 457: 30 observasi\n",
      "Student ID 458: 30 observasi\n",
      "Student ID 459: 30 observasi\n",
      "Student ID 460: 30 observasi\n",
      "Student ID 461: 30 observasi\n",
      "Student ID 462: 30 observasi\n",
      "Student ID 463: 30 observasi\n",
      "Student ID 464: 30 observasi\n",
      "Student ID 465: 30 observasi\n",
      "Student ID 466: 30 observasi\n",
      "Student ID 467: 30 observasi\n",
      "Student ID 468: 30 observasi\n",
      "Student ID 469: 30 observasi\n",
      "Student ID 470: 30 observasi\n",
      "Student ID 471: 30 observasi\n",
      "Student ID 472: 30 observasi\n",
      "Student ID 473: 30 observasi\n",
      "Student ID 474: 30 observasi\n",
      "Student ID 475: 30 observasi\n",
      "Student ID 476: 30 observasi\n",
      "Student ID 477: 30 observasi\n",
      "Student ID 478: 30 observasi\n",
      "Student ID 479: 30 observasi\n",
      "Student ID 480: 30 observasi\n",
      "Student ID 481: 30 observasi\n",
      "Student ID 482: 30 observasi\n",
      "Student ID 483: 30 observasi\n",
      "Student ID 484: 30 observasi\n",
      "Student ID 485: 30 observasi\n",
      "Student ID 486: 30 observasi\n",
      "Student ID 487: 30 observasi\n",
      "Student ID 488: 30 observasi\n",
      "Student ID 489: 30 observasi\n",
      "Student ID 490: 30 observasi\n",
      "Student ID 491: 30 observasi\n",
      "Student ID 492: 30 observasi\n",
      "Student ID 493: 30 observasi\n",
      "Student ID 494: 30 observasi\n",
      "Student ID 495: 30 observasi\n",
      "Student ID 496: 30 observasi\n",
      "Student ID 497: 30 observasi\n",
      "Student ID 498: 30 observasi\n",
      "Student ID 499: 30 observasi\n",
      "Student ID 500: 30 observasi\n"
     ]
    }
   ],
   "source": [
    "# Menghitung jumlah observasi asli untuk setiap Student ID\n",
    "jumlah_observasi = df.groupby('Student ID').size()\n",
    "\n",
    "print(\"\\n===== JUMLAH OBSERVASI PER STUDENT ID =====\")\n",
    "for student_id, jumlah in jumlah_observasi.items():\n",
    "    print(f\"Student ID {student_id}: {jumlah} observasi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70301fa1-cbc1-4a2d-82ff-29e0267ae994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menyimpan dataset baru setelah preprocessing \n",
    "df.to_csv('dataset_baru.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46472597-61ec-437e-ac2f-9e9f7348b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membuat model peramal untuk fitur-fitur primer...\n",
      "Parameter ARIMA global: (1, 1, 4) dengan MAE: 0.2507924953813955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-24 07:55:27,965] A new study created in memory with name: no-name-54941a14-fb8f-4620-a85e-30f8a80de47a\n",
      "[I 2025-06-24 08:07:49,153] Trial 0 finished with value: 1.2948766946792603 and parameters: {'hidden_dim': 74, 'dropout_rate': 0.24661234750702282, 'lr': 0.0009487709801796939, 'risk_weight': 1.6497407358507115, 'embed_dim': 10}. Best is trial 0 with value: 1.2948766946792603.\n",
      "[I 2025-06-24 08:08:01,216] Trial 6 finished with value: 1.228351354598999 and parameters: {'hidden_dim': 140, 'dropout_rate': 0.4081405650763297, 'lr': 0.0015231487332167436, 'risk_weight': 1.5741892770061736, 'embed_dim': 27}. Best is trial 6 with value: 1.228351354598999.\n",
      "[I 2025-06-24 08:08:13,848] Trial 7 finished with value: 0.9765678644180298 and parameters: {'hidden_dim': 110, 'dropout_rate': 0.22305516068658726, 'lr': 0.0020011589884113648, 'risk_weight': 1.2634776869405866, 'embed_dim': 40}. Best is trial 7 with value: 0.9765678644180298.\n",
      "[I 2025-06-24 08:08:41,243] Trial 2 finished with value: 1.0460301637649536 and parameters: {'hidden_dim': 191, 'dropout_rate': 0.3950521185408783, 'lr': 0.003229199393221711, 'risk_weight': 1.3450551710012664, 'embed_dim': 28}. Best is trial 7 with value: 0.9765678644180298.\n",
      "[I 2025-06-24 08:09:49,010] Trial 4 finished with value: 0.738654613494873 and parameters: {'hidden_dim': 201, 'dropout_rate': 0.3836764125347686, 'lr': 0.0006827878275448907, 'risk_weight': 0.948380049145275, 'embed_dim': 15}. Best is trial 4 with value: 0.738654613494873.\n",
      "[I 2025-06-24 08:10:05,897] Trial 3 finished with value: 0.973564863204956 and parameters: {'hidden_dim': 251, 'dropout_rate': 0.3293682909752091, 'lr': 0.0018026774004279926, 'risk_weight': 1.228823029241282, 'embed_dim': 45}. Best is trial 4 with value: 0.738654613494873.\n",
      "[I 2025-06-24 08:10:07,446] Trial 1 finished with value: 1.5369993448257446 and parameters: {'hidden_dim': 216, 'dropout_rate': 0.4102397720258204, 'lr': 0.004574252926443483, 'risk_weight': 1.9795329003475963, 'embed_dim': 24}. Best is trial 4 with value: 0.738654613494873.\n",
      "[I 2025-06-24 08:10:36,181] Trial 5 finished with value: 0.8392248749732971 and parameters: {'hidden_dim': 232, 'dropout_rate': 0.3736242120940104, 'lr': 0.0017431868726803044, 'risk_weight': 1.082142404829895, 'embed_dim': 38}. Best is trial 4 with value: 0.738654613494873.\n",
      "[I 2025-06-24 08:11:33,320] Trial 8 finished with value: 1.4605162143707275 and parameters: {'hidden_dim': 136, 'dropout_rate': 0.23810140162725338, 'lr': 0.006900620803898113, 'risk_weight': 1.8798593941946735, 'embed_dim': 11}. Best is trial 4 with value: 0.738654613494873.\n",
      "[I 2025-06-24 08:12:11,991] Trial 9 finished with value: 0.862760066986084 and parameters: {'hidden_dim': 227, 'dropout_rate': 0.201717360230873, 'lr': 0.0002775172470726887, 'risk_weight': 1.0766642759980538, 'embed_dim': 35}. Best is trial 4 with value: 0.738654613494873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter LSTM Terbaik: {'hidden_dim': 201, 'dropout_rate': 0.3836764125347686, 'lr': 0.0006827878275448907, 'risk_weight': 0.948380049145275, 'embed_dim': 15}\n",
      "Kinerja Hybrid ARIMA-LSTM:\n",
      " - MAE: 0.0246\n",
      " - RMSE: 0.0310\n",
      " - MAPE: 24.85%\n",
      "\n",
      "Waktu Eksekusi: 0 jam, 34 menit, 23.18 detik\n",
      "\n",
      "Metrik Akhir (Hybrid ARIMA-LSTM pada Set Uji):\n",
      " - MAE  (Tingkat Stres): 0.0246\n",
      " - RMSE (Tingkat Stres): 0.0310\n",
      " - MAPE (Tingkat Stres): 24.85%\n",
      "\n",
      "Peramalan Masa Depan Dinamis (Contoh):\n",
      "        Date  Student ID  Forecasted Stress Level\n",
      "0 2024-12-31           1                 0.528459\n",
      "1 2025-01-01           1                 0.542548\n",
      "2 2025-01-02           1                 0.546893\n",
      "3 2025-01-03           1                 0.552832\n",
      "4 2025-01-04           1                 0.558552\n",
      "\n",
      "Grafik prediksi dan peramalan terpadu telah disimpan di folder 'hasil_model_stres_bertingkat'\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 1: FUNGSI DAN KELAS MODEL (TIDAK BERUBAH)\n",
    "# =============================================================================\n",
    "\n",
    "def setup_logging(model_dir):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    logging.basicConfig(filename=os.path.join(model_dir, 'student_model.log'), level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_mask = y_true != 0\n",
    "    if not np.any(non_zero_mask): return 0.0\n",
    "    return np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "\n",
    "def create_sequences(data, student_ids, target_cols, timesteps=1):\n",
    "    X, X_ids, y = [], [], []\n",
    "    for i in range(len(data) - timesteps):\n",
    "        X.append(data[i:i + timesteps])\n",
    "        X_ids.append(student_ids[i + timesteps])\n",
    "        y.append(data[i + timesteps, -len(target_cols):])\n",
    "    return np.array(X), np.array(X_ids), np.array(y)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_students, embed_dim, hidden_dim, timesteps=1, dropout_rate=0.4):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_students, embed_dim)\n",
    "        self.lstm = nn.LSTM(input_dim + embed_dim, hidden_dim, batch_first=True)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.risk_head = nn.Sequential(nn.Linear(hidden_dim, hidden_dim // 2), nn.ReLU(), nn.Dropout(dropout_rate - 0.1 if dropout_rate > 0.1 else 0.0), nn.Linear(hidden_dim // 2, 3))\n",
    "        self.fc_residual = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, student_ids):\n",
    "        if student_ids.ndim == 1: student_ids = student_ids.unsqueeze(1)\n",
    "        embed = self.embedding(student_ids.squeeze(1))\n",
    "        embed = embed.unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        x = torch.cat([x, embed], dim=2)\n",
    "        out, (h_n, _) = self.lstm(x)\n",
    "        out = h_n[-1]\n",
    "        out = self.bn(out)\n",
    "        out = self.dropout(out)\n",
    "        risk_logits = self.risk_head(out)\n",
    "        residual_pred = self.fc_residual(out)\n",
    "        return risk_logits, residual_pred.squeeze(1)\n",
    "\n",
    "def tune_arima(train_data, val_data, p_range=range(0, 5), d_range=range(0, 3), q_range=range(0, 5)):\n",
    "    best_mae = float('inf')\n",
    "    best_params = (1, 1, 1)\n",
    "    tscv = TimeSeriesSplit(n_splits=3) # Mengurangi split untuk kecepatan\n",
    "    for p in p_range:\n",
    "        for d in d_range:\n",
    "            for q in q_range:\n",
    "                try:\n",
    "                    mae_list = []\n",
    "                    for train_index, val_index in tscv.split(train_data):\n",
    "                        train_fold, val_fold = train_data.iloc[train_index], train_data.iloc[val_index]\n",
    "                        model = ARIMA(train_fold['Stress Level (GSR)'], order=(p, d, q)).fit()\n",
    "                        predictions = model.forecast(steps=len(val_fold))\n",
    "                        mae = mean_absolute_error(val_fold['Stress Level (GSR)'], predictions)\n",
    "                        mae_list.append(mae)\n",
    "                    mean_mae = np.mean(mae_list)\n",
    "                    if mean_mae < best_mae:\n",
    "                        best_mae, best_params = mean_mae, (p, d, q)\n",
    "                except Exception:\n",
    "                    continue\n",
    "    return best_params, best_mae\n",
    "\n",
    "def tune_lstm(X_train_tensor, X_train_ids_tensor, y_train_risk, y_train_residual, timesteps, num_students, device):\n",
    "    def objective(trial):\n",
    "        hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "        risk_weight = trial.suggest_float('risk_weight', 0.8, 2.0)\n",
    "        embed_dim = trial.suggest_int('embed_dim', 10, 50)\n",
    "        model = LSTMModel(input_dim=X_train_tensor.shape[2], num_students=num_students, embed_dim=embed_dim, hidden_dim=hidden_dim, timesteps=timesteps, dropout_rate=dropout_rate).to(device)\n",
    "        loss_risk, loss_residual = nn.CrossEntropyLoss(), nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        val_size = int(len(X_train_tensor) * 0.2)\n",
    "        X_train_lstm, X_val_lstm = X_train_tensor[:-val_size], X_train_tensor[-val_size:]\n",
    "        X_train_ids_lstm, X_val_ids_lstm = X_train_ids_tensor[:-val_size], X_train_ids_tensor[-val_size:]\n",
    "        y_train_risk_lstm, y_val_risk_lstm = y_train_risk[:-val_size], y_train_risk[-val_size:]\n",
    "        y_train_residual_lstm, y_val_residual_lstm = y_train_residual[:-val_size], y_train_residual[-val_size:]\n",
    "        train_dataset = TensorDataset(X_train_lstm, X_train_ids_lstm, y_train_risk_lstm, y_train_residual_lstm)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        best_val_loss = float('inf')\n",
    "        for epoch in range(40): # Mengurangi epoch untuk tuning\n",
    "            model.train()\n",
    "            for batch_x, batch_ids, batch_y_risk, batch_y_residual in train_loader:\n",
    "                batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                risk_logits, residual_pred = model(batch_x, batch_ids)\n",
    "                loss = risk_weight * loss_risk(risk_logits, batch_y_risk) + 1.0 * loss_residual(residual_pred, batch_y_residual)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_risk_logits, val_residual_pred = model(X_val_lstm, X_val_ids_lstm)\n",
    "                val_loss = (risk_weight * loss_risk(val_risk_logits, y_val_risk_lstm) + 1.0 * loss_residual(val_residual_pred, y_val_residual_lstm)).item()\n",
    "                if val_loss < best_val_loss: best_val_loss = val_loss\n",
    "        return best_val_loss\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=10, n_jobs=-1) # Mempercepat tuning\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 2: FUNGSI PERAMALAN BARU YANG SANGAT DINAMIS\n",
    "# =============================================================================\n",
    "\n",
    "def create_feature_forecasters(data, primary_feature_cols):\n",
    "    \"\"\"Membuat model peramalan sederhana untuk setiap fitur primer.\"\"\"\n",
    "    forecasters = {}\n",
    "    for col in primary_feature_cols:\n",
    "        try:\n",
    "            # Menggunakan model ARIMA sederhana untuk setiap fitur\n",
    "            model = ARIMA(data[col], order=(2,1,1)).fit()\n",
    "            forecasters[col] = model\n",
    "            logging.info(f\"Feature forecaster created for {col}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Could not create forecaster for {col}: {e}\")\n",
    "            forecasters[col] = None # Jika gagal, akan menggunakan last value\n",
    "    return forecasters\n",
    "\n",
    "def forecast_future(data, arima_stress_fit, model_lstm, le_student, feature_forecasters, timesteps=1, n_forecast=10, feature_cols=None, primary_feature_cols=None):\n",
    "    \"\"\"Meramalkan tingkat stres secara iteratif dengan meramalkan fitur inputnya juga.\"\"\"\n",
    "    logging.info(\"Memulai peramalan bertingkat yang dinamis...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_lstm.to(device).eval()\n",
    "\n",
    "    # Dapatkan prediksi dasar dari ARIMA untuk stres\n",
    "    arima_stress_forecast = arima_stress_fit.forecast(steps=n_forecast)\n",
    "    all_forecasts = []\n",
    "\n",
    "    for student_id in data['Student ID'].unique():\n",
    "        student_history = data[data['Student ID'] == student_id].copy().reset_index(drop=True)\n",
    "        student_id_encoded = le_student.transform([student_id])[0]\n",
    "\n",
    "        if 'residual' not in student_history.columns:\n",
    "            student_history['residual'] = 0.0\n",
    "        \n",
    "        student_future_predictions = []\n",
    "\n",
    "\n",
    "        # Dapatkan peramalan untuk semua fitur primer selama n_forecast hari\n",
    "        future_features_forecasts = {}\n",
    "        for col, forecaster in feature_forecasters.items():\n",
    "            if forecaster:\n",
    "                future_features_forecasts[col] = forecaster.forecast(steps=n_forecast)\n",
    "            else: # Fallback jika model fitur gagal dibuat\n",
    "                future_features_forecasts[col] = [student_history[col].iloc[-1]] * n_forecast\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(n_forecast):\n",
    "                input_data = student_history.tail(timesteps)\n",
    "                input_features_sequence = input_data[feature_cols].values.astype(np.float32)\n",
    "                input_residuals_sequence = input_data['residual'].values.astype(np.float32).reshape(-1, 1)\n",
    "                input_aug = np.concatenate((input_features_sequence, input_residuals_sequence), axis=1)\n",
    "                \n",
    "                current_sequence = torch.tensor(input_aug, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                current_id_tensor = torch.tensor([student_id_encoded], dtype=torch.long).to(device)\n",
    "\n",
    "                _, lstm_residual_pred = model_lstm(current_sequence, current_id_tensor)\n",
    "                lstm_residual_pred = lstm_residual_pred.cpu().item()\n",
    "                \n",
    "                final_stress_pred = arima_stress_forecast.iloc[i] + lstm_residual_pred\n",
    "                student_future_predictions.append(final_stress_pred)\n",
    "\n",
    "                # Buat baris baru dengan FITUR YANG SUDAH DIRAMALKAN\n",
    "                new_row_data = {\n",
    "                    'Date': student_history['Date'].iloc[-1] + pd.DateOffset(days=1),\n",
    "                    'Student ID': student_id,\n",
    "                    'Student ID Encoded': student_id_encoded,\n",
    "                    'Stress Level (GSR)': final_stress_pred,\n",
    "                    'residual': lstm_residual_pred,\n",
    "                }\n",
    "                # Masukkan nilai fitur yang sudah diramalkan untuk hari ke-i\n",
    "                for col in primary_feature_cols:\n",
    "                    new_row_data[col] = future_features_forecasts[col].iloc[i] if hasattr(future_features_forecasts[col], 'iloc') else future_features_forecasts[col][i]\n",
    "\n",
    "                new_row_df = pd.DataFrame([new_row_data])\n",
    "                student_history = pd.concat([student_history, new_row_df], ignore_index=True)\n",
    "                \n",
    "                # Hitung ulang fitur turunan\n",
    "                student_history['lag_1_stress'] = student_history['Stress Level (GSR)'].shift(1)\n",
    "                student_history['lag_1_sleep'] = student_history['Sleep Hours'].shift(1)\n",
    "                student_history['rolling_mean_stress'] = student_history['Stress Level (GSR)'].rolling(window=7, min_periods=1).mean()\n",
    "                student_history['rolling_std_stress'] = student_history['Stress Level (GSR)'].rolling(window=7, min_periods=1).std()\n",
    "                student_history.ffill(inplace=True)\n",
    "                student_history.bfill(inplace=True)\n",
    "\n",
    "        forecast_dates = pd.to_datetime([data[data['Student ID']==student_id]['Date'].max() + pd.DateOffset(days=j) for j in range(1, n_forecast + 1)])\n",
    "        forecast_df_student = pd.DataFrame({'Date': forecast_dates, 'Student ID': student_id, 'Forecasted Stress Level': student_future_predictions})\n",
    "        all_forecasts.append(forecast_df_student)\n",
    "\n",
    "    if not all_forecasts: return None\n",
    "    return pd.concat(all_forecasts, ignore_index=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 3: FUNGSI UTAMA YANG MENGGABUNGKAN KEDUANYA\n",
    "# =============================================================================\n",
    "\n",
    "def predict_global(data, model_dir='hasil_model', timesteps=1):\n",
    "    setup_logging(model_dir)\n",
    "    \n",
    "    required_cols = ['Student ID', 'Date', 'Stress Level (GSR)', 'Risk Level', 'Sleep Hours', 'Anxiety Level', 'Mood Score', 'Attendance Status (Data)', 'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']\n",
    "    primary_feature_cols = ['Sleep Hours', 'Anxiety Level', 'Mood Score', 'Attendance Status (Data)']\n",
    "    feature_cols = ['Sleep Hours', 'Anxiety Level', 'Mood Score', 'Attendance Status (Data)', 'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']\n",
    "    target_cols = ['Risk Level', 'Stress Level (GSR)']\n",
    "    \n",
    "    if any(col not in data.columns for col in required_cols): raise ValueError(\"Kolom yang dibutuhkan hilang\")\n",
    "    \n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data = data.sort_values(by=['Student ID', 'Date']).reset_index(drop=True)\n",
    "    \n",
    "    le_student = LabelEncoder()\n",
    "    data['Student ID Encoded'] = le_student.fit_transform(data['Student ID'])\n",
    "    with open(os.path.join(model_dir, 'label_encoder.pkl'), 'wb') as f: pickle.dump(le_student, f)\n",
    "    \n",
    "    unique_dates = data['Date'].dt.date.unique()\n",
    "    if len(unique_dates) < 30: raise ValueError(f\"Tanggal unik tidak cukup: {len(unique_dates)}\")\n",
    "    \n",
    "    train_dates, test_dates = unique_dates[:24], unique_dates[24:30]\n",
    "    train_data = data[data['Date'].dt.date.isin(train_dates)].copy().reset_index(drop=True)\n",
    "    test_data = data[data['Date'].dt.date.isin(test_dates)].copy().reset_index(drop=True)\n",
    "    if len(test_data) == 0 or len(train_data) == 0: raise ValueError(\"Data latih atau uji kosong\")\n",
    "\n",
    "    historical_data = data[data['Date'].dt.date.isin(unique_dates[:30])].copy() # solusi untuk prediksi 401 - 500\n",
    "\n",
    "    for col in feature_cols + target_cols:\n",
    "        for df in [train_data, test_data]:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(np.float32)\n",
    "            df[col] = df.groupby('Student ID')[col].transform(lambda x: x.ffill().bfill()).fillna(0)\n",
    "\n",
    "    # --- MEMBUAT PERAMAL FITUR (BARU) ---\n",
    "    print(\"Membuat model peramal untuk fitur-fitur primer...\")\n",
    "    feature_forecasters = create_feature_forecasters(train_data, primary_feature_cols)\n",
    "\n",
    "    arima_train_size = int(len(train_data) * 0.8)\n",
    "    train_arima, val_arima = train_data.iloc[:arima_train_size], train_data.iloc[arima_train_size:]\n",
    "    best_params_arima, best_mae_arima = tune_arima(train_arima, val_arima)\n",
    "    print(f\"Parameter ARIMA global: {best_params_arima} dengan MAE: {best_mae_arima}\")\n",
    "    \n",
    "    arima_stress_fit = ARIMA(train_data['Stress Level (GSR)'], order=best_params_arima).fit()\n",
    "    with open(os.path.join(model_dir, 'arima_stress_model.pkl'), 'wb') as f: pickle.dump(arima_stress_fit, f)\n",
    "\n",
    "    arima_train_pred = arima_stress_fit.predict(start=0, end=len(train_data) - 1)\n",
    "    arima_test_pred = arima_stress_fit.forecast(steps=len(test_data))\n",
    "    \n",
    "    data.loc[train_data.index, 'residual'] = train_data['Stress Level (GSR)'].values - arima_train_pred.values\n",
    "    data.loc[test_data.index, 'residual'] = test_data['Stress Level (GSR)'].values - arima_test_pred.values\n",
    "    \n",
    "    train_values = train_data[feature_cols + target_cols].values\n",
    "    test_values = test_data[feature_cols + target_cols].values\n",
    "    train_student_ids = train_data['Student ID Encoded'].values\n",
    "    test_student_ids = test_data['Student ID Encoded'].values\n",
    "    X_train, X_train_ids, y_train = create_sequences(train_values, train_student_ids, target_cols, timesteps)\n",
    "    X_test, X_test_ids, y_test = create_sequences(test_values, test_student_ids, target_cols, timesteps)\n",
    "    \n",
    "    residual_train_seq = data.loc[train_data.index[timesteps:], 'residual'].values[:len(X_train)].astype(np.float32)\n",
    "    residual_test_seq = data.loc[test_data.index[timesteps:], 'residual'].values[:len(X_test)].astype(np.float32)\n",
    "    \n",
    "    X_train_aug = np.concatenate((X_train[:, :, :-2], residual_train_seq.reshape(len(X_train), 1, 1).repeat(timesteps, axis=1)), axis=2).astype(np.float32)\n",
    "    X_test_aug = np.concatenate((X_test[:, :, :-2], residual_test_seq.reshape(len(X_test), 1, 1).repeat(timesteps, axis=1)), axis=2).astype(np.float32)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    best_params_lstm = tune_lstm(torch.tensor(X_train_aug).to(device), torch.tensor(X_train_ids).to(device), torch.tensor(y_train[:, 0], dtype=torch.long).to(device), torch.tensor(residual_train_seq).to(device), timesteps, len(le_student.classes_), device)\n",
    "    print(f\"Parameter LSTM Terbaik: {best_params_lstm}\")\n",
    "    \n",
    "    model_lstm = LSTMModel(input_dim=X_train_aug.shape[2], num_students=len(le_student.classes_), embed_dim=best_params_lstm['embed_dim'], hidden_dim=best_params_lstm['hidden_dim'], timesteps=timesteps, dropout_rate=best_params_lstm['dropout_rate']).to(device)\n",
    "    optimizer = torch.optim.Adam(model_lstm.parameters(), lr=best_params_lstm['lr'], weight_decay=1e-5)\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train_aug), torch.tensor(X_train_ids), torch.tensor(y_train[:, 0], dtype=torch.long), torch.tensor(residual_train_seq))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    for epoch in range(50):\n",
    "        model_lstm.train()\n",
    "        for batch_x, batch_ids, batch_y_risk, batch_y_residual in train_loader:\n",
    "            batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            risk_logits, residual_pred = model_lstm(batch_x, batch_ids)\n",
    "            loss = best_params_lstm['risk_weight'] * nn.CrossEntropyLoss()(risk_logits, batch_y_risk) + nn.MSELoss()(residual_pred, batch_y_residual)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    torch.save(model_lstm.state_dict(), os.path.join(model_dir, 'lstm_model.pth'))\n",
    "\n",
    "    model_lstm.eval()\n",
    "    with torch.no_grad():\n",
    "        lstm_residual_pred = model_lstm(torch.tensor(X_test_aug).to(device), torch.tensor(X_test_ids).to(device))[1].cpu().numpy()\n",
    "    \n",
    "    arima_test_pred_aligned = arima_test_pred.values[timesteps:][:len(lstm_residual_pred)]\n",
    "    hybrid_test_pred = arima_test_pred_aligned + lstm_residual_pred\n",
    "    y_true_test = y_test[:, -1]\n",
    "    \n",
    "    hybrid_mae = mean_absolute_error(y_true_test, hybrid_test_pred)\n",
    "    hybrid_rmse = np.sqrt(mean_squared_error(y_true_test, hybrid_test_pred))\n",
    "    hybrid_mape = mean_absolute_percentage_error(y_true_test, hybrid_test_pred)\n",
    "    print(f\"Kinerja Hybrid ARIMA-LSTM:\\n - MAE: {hybrid_mae:.4f}\\n - RMSE: {hybrid_rmse:.4f}\\n - MAPE: {hybrid_mape:.2f}%\")\n",
    "\n",
    "    test_dates_for_df = test_data['Date'].iloc[timesteps:].iloc[:len(y_true_test)]\n",
    "    test_student_ids_for_df = test_data['Student ID'].iloc[timesteps:].iloc[:len(y_true_test)]\n",
    "    \n",
    "    predictions_df = pd.DataFrame({'Date': test_dates_for_df, 'Student ID': test_student_ids_for_df, 'Predicted Stress Level': hybrid_test_pred, 'Actual Stress Level': y_true_test})\n",
    "    \n",
    "    # Memanggil fungsi peramalan yang baru\n",
    "    # future_forecasts = forecast_future(data, arima_stress_fit, model_lstm, le_student, feature_forecasters, timesteps, 10, feature_cols, primary_feature_cols)\n",
    "    future_forecasts = forecast_future(historical_data, arima_stress_fit, model_lstm, le_student, feature_forecasters, timesteps, 7, feature_cols, primary_feature_cols) # Mengganti n_forecast ke 7 sesuai permintaan awal\n",
    "\n",
    "    for student_id in data['Student ID'].unique():\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        # student_actual_data = data[data['Student ID'] == student_id] # Solusi untuk 401 - 500 \n",
    "        student_actual_data = historical_data[historical_data['Student ID'] == student_id]\n",
    "        plt.plot(student_actual_data['Date'], student_actual_data['Stress Level (GSR)'], label='Actual Stress Level', color='blue', linestyle='-')\n",
    "        student_pred_data = predictions_df[predictions_df['Student ID'] == student_id]\n",
    "        if not student_pred_data.empty:\n",
    "            plt.plot(student_pred_data['Date'], student_pred_data['Predicted Stress Level'], label='Hybrid ARIMA-LSTM Prediction', color='green', linestyle='--')\n",
    "            residuals = student_pred_data['Actual Stress Level'] - student_pred_data['Predicted Stress Level']\n",
    "            plt.plot(student_pred_data['Date'], residuals, label='Residuals', color='red', linestyle=':')\n",
    "        if future_forecasts is not None:\n",
    "            student_forecast_data = future_forecasts[future_forecasts['Student ID'] == student_id]\n",
    "            if not student_pred_data.empty and not student_forecast_data.empty:\n",
    "                last_pred_date = student_pred_data['Date'].iloc[-1]\n",
    "                last_pred_value = student_pred_data['Predicted Stress Level'].iloc[-1]\n",
    "                combined_forecast_dates = pd.concat([pd.Series(last_pred_date), student_forecast_data['Date']]).reset_index(drop=True)\n",
    "                combined_forecast_values = pd.concat([pd.Series(last_pred_value), student_forecast_data['Forecasted Stress Level']]).reset_index(drop=True)\n",
    "                plt.plot(combined_forecast_dates, combined_forecast_values, color='green', linestyle='--')\n",
    "                plt.plot(student_forecast_data['Date'], student_forecast_data['Forecasted Stress Level'], color='orange', marker='o', linestyle='--', label='Forecast')\n",
    "        plt.title(f'Stress Level Prediction for Student {student_id}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Stress Level (GSR)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=3))\n",
    "        plt.gcf().autofmt_xdate(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(model_dir, f'prediction_and_forecast_student_{student_id}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    return {'mae_stress': hybrid_mae, 'rmse_stress': hybrid_rmse, 'mape_stress': hybrid_mape, 'predictions': predictions_df, 'future_forecasts': future_forecasts}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data = pd.read_csv('dataset_baru.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File 'dataset_baru.csv' tidak ditemukan.\")\n",
    "        exit()\n",
    "\n",
    "    start_time = time.time()\n",
    "    output_dir = 'hasil_model_stres_bertingkat'\n",
    "    metrics = predict_global(data, model_dir=output_dir)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    hours, rem = divmod(duration, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f\"\\nWaktu Eksekusi: {int(hours)} jam, {int(minutes)} menit, {seconds:.2f} detik\")\n",
    "    if metrics:\n",
    "        print(f\"\\nMetrik Akhir (Hybrid ARIMA-LSTM pada Set Uji):\")\n",
    "        print(f\" - MAE  (Tingkat Stres): {metrics['mae_stress']:.4f}\")\n",
    "        print(f\" - RMSE (Tingkat Stres): {metrics['rmse_stress']:.4f}\")\n",
    "        print(f\" - MAPE (Tingkat Stres): {metrics['mape_stress']:.2f}%\")\n",
    "        if metrics['future_forecasts'] is not None:\n",
    "            print(\"\\nPeramalan Masa Depan Dinamis (Contoh):\")\n",
    "            print(metrics['future_forecasts'].head())\n",
    "            print(f\"\\nGrafik prediksi dan peramalan terpadu telah disimpan di folder '{output_dir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31456ce-53c4-48eb-a6ad-3581f8014264",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea035747-4c03-4aac-a84e-f9cb1fa4e93f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (2938787338.py, line 277)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 277\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "\n",
    "# # BAGIAN 1: FUNGSI DAN KELAS MODEL (TIDAK BERUBAH)\n",
    "\n",
    "# # =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# def setup_logging(model_dir):\n",
    "\n",
    "# Â  Â  os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Â  Â  logging.basicConfig(filename=os.path.join(model_dir, 'student_model.log'), level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "\n",
    "\n",
    "# def mean_absolute_percentage_error(y_true, y_pred):\n",
    "\n",
    "# Â  Â  y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "# Â  Â  non_zero_mask = y_true != 0\n",
    "\n",
    "# Â  Â  if not np.any(non_zero_mask): return 0.0\n",
    "\n",
    "# Â  Â  return np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "\n",
    "\n",
    "\n",
    "# def create_sequences(data, student_ids, target_cols, timesteps=1):\n",
    "\n",
    "# Â  Â  X, X_ids, y = [], [], []\n",
    "\n",
    "# Â  Â  for i in range(len(data) - timesteps):\n",
    "\n",
    "# Â  Â  Â  Â  X.append(data[i:i + timesteps])\n",
    "\n",
    "# Â  Â  Â  Â  X_ids.append(student_ids[i + timesteps])\n",
    "\n",
    "# Â  Â  Â  Â  y.append(data[i + timesteps, -len(target_cols):])\n",
    "\n",
    "# Â  Â  return np.array(X), np.array(X_ids), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "# class LSTMModel(nn.Module):\n",
    "\n",
    "# Â  Â  def __init__(self, input_dim, num_students, embed_dim, hidden_dim, timesteps=1, dropout_rate=0.4):\n",
    "\n",
    "# Â  Â  Â  Â  super(LSTMModel, self).__init__()\n",
    "\n",
    "# Â  Â  Â  Â  self.embedding = nn.Embedding(num_students, embed_dim)\n",
    "\n",
    "# Â  Â  Â  Â  self.lstm = nn.LSTM(input_dim + embed_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "# Â  Â  Â  Â  self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "# Â  Â  Â  Â  self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "# Â  Â  Â  Â  self.risk_head = nn.Sequential(nn.Linear(hidden_dim, hidden_dim // 2), nn.ReLU(), nn.Dropout(dropout_rate - 0.1 if dropout_rate > 0.1 else 0.0), nn.Linear(hidden_dim // 2, 3))\n",
    "\n",
    "# Â  Â  Â  Â  self.fc_residual = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  def forward(self, x, student_ids):\n",
    "\n",
    "# Â  Â  Â  Â  if student_ids.ndim == 1: student_ids = student_ids.unsqueeze(1)\n",
    "\n",
    "# Â  Â  Â  Â  embed = self.embedding(student_ids.squeeze(1))\n",
    "\n",
    "# Â  Â  Â  Â  embed = embed.unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "\n",
    "# Â  Â  Â  Â  x = torch.cat([x, embed], dim=2)\n",
    "\n",
    "# Â  Â  Â  Â  out, (h_n, _) = self.lstm(x)\n",
    "\n",
    "# Â  Â  Â  Â  out = h_n[-1]\n",
    "\n",
    "# Â  Â  Â  Â  out = self.bn(out)\n",
    "\n",
    "# Â  Â  Â  Â  out = self.dropout(out)\n",
    "\n",
    "# Â  Â  Â  Â  risk_logits = self.risk_head(out)\n",
    "\n",
    "# Â  Â  Â  Â  residual_pred = self.fc_residual(out)\n",
    "\n",
    "# Â  Â  Â  Â  return risk_logits, residual_pred.squeeze(1)\n",
    "\n",
    "\n",
    "\n",
    "# def tune_arima(train_data, val_data, p_range=range(0, 5), d_range=range(0, 3), q_range=range(0, 5)):\n",
    "\n",
    "# Â  Â  best_mae = float('inf')\n",
    "\n",
    "# Â  Â  best_params = (1, 1, 1)\n",
    "\n",
    "# Â  Â  tscv = TimeSeriesSplit(n_splits=3) # Mengurangi split untuk kecepatan\n",
    "\n",
    "# Â  Â  for p in p_range:\n",
    "\n",
    "# Â  Â  Â  Â  for d in d_range:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  for q in q_range:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  try:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mae_list = []\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for train_index, val_index in tscv.split(train_data):\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  train_fold, val_fold = train_data.iloc[train_index], train_data.iloc[val_index]\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model = ARIMA(train_fold['Stress Level (GSR)'], order=(p, d, q)).fit()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  predictions = model.forecast(steps=len(val_fold))\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mae = mean_absolute_error(val_fold['Stress Level (GSR)'], predictions)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mae_list.append(mae)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mean_mae = np.mean(mae_list)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if mean_mae < best_mae:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  best_mae, best_params = mean_mae, (p, d, q)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  except Exception:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue\n",
    "\n",
    "# Â  Â  return best_params, best_mae\n",
    "\n",
    "\n",
    "\n",
    "# def tune_lstm(X_train_tensor, X_train_ids_tensor, y_train_risk, y_train_residual, timesteps, num_students, device):\n",
    "\n",
    "# Â  Â  def objective(trial):\n",
    "\n",
    "# Â  Â  Â  Â  hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "\n",
    "# Â  Â  Â  Â  dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "\n",
    "# Â  Â  Â  Â  lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "\n",
    "# Â  Â  Â  Â  risk_weight = trial.suggest_float('risk_weight', 0.8, 2.0)\n",
    "\n",
    "# Â  Â  Â  Â  embed_dim = trial.suggest_int('embed_dim', 10, 50)\n",
    "\n",
    "# Â  Â  Â  Â  model = LSTMModel(input_dim=X_train_tensor.shape[2], num_students=num_students, embed_dim=embed_dim, hidden_dim=hidden_dim, timesteps=timesteps, dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "# Â  Â  Â  Â  loss_risk, loss_residual = nn.CrossEntropyLoss(), nn.MSELoss()\n",
    "\n",
    "# Â  Â  Â  Â  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# Â  Â  Â  Â  val_size = int(len(X_train_tensor) * 0.2)\n",
    "\n",
    "# Â  Â  Â  Â  X_train_lstm, X_val_lstm = X_train_tensor[:-val_size], X_train_tensor[-val_size:]\n",
    "\n",
    "# Â  Â  Â  Â  X_train_ids_lstm, X_val_ids_lstm = X_train_ids_tensor[:-val_size], X_train_ids_tensor[-val_size:]\n",
    "\n",
    "# Â  Â  Â  Â  y_train_risk_lstm, y_val_risk_lstm = y_train_risk[:-val_size], y_train_risk[-val_size:]\n",
    "\n",
    "# Â  Â  Â  Â  y_train_residual_lstm, y_val_residual_lstm = y_train_residual[:-val_size], y_train_residual[-val_size:]\n",
    "\n",
    "# Â  Â  Â  Â  train_dataset = TensorDataset(X_train_lstm, X_train_ids_lstm, y_train_risk_lstm, y_train_residual_lstm)\n",
    "\n",
    "# Â  Â  Â  Â  train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Â  Â  Â  Â  best_val_loss = float('inf')\n",
    "\n",
    "# Â  Â  Â  Â  for epoch in range(40): # Mengurangi epoch untuk tuning\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  model.train()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  for batch_x, batch_ids, batch_y_risk, batch_y_residual in train_loader:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  optimizer.zero_grad()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  risk_logits, residual_pred = model(batch_x, batch_ids)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  loss = risk_weight * loss_risk(risk_logits, batch_y_risk) + 1.0 * loss_residual(residual_pred, batch_y_residual)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  loss.backward()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  optimizer.step()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  model.eval()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  with torch.no_grad():\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  val_risk_logits, val_residual_pred = model(X_val_lstm, X_val_ids_lstm)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  val_loss = (risk_weight * loss_risk(val_risk_logits, y_val_risk_lstm) + 1.0 * loss_residual(val_residual_pred, y_val_residual_lstm)).item()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  if val_loss < best_val_loss: best_val_loss = val_loss\n",
    "\n",
    "# Â  Â  Â  Â  return best_val_loss\n",
    "\n",
    "# Â  Â  study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Â  Â  study.optimize(objective, n_trials=10, n_jobs=-1) # Mempercepat tuning\n",
    "\n",
    "# Â  Â  return study.best_params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "\n",
    "# # BAGIAN 2: FUNGSI PERAMALAN BARU YANG SANGAT DINAMIS\n",
    "\n",
    "# # =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# def create_feature_forecasters(data, primary_feature_cols):\n",
    "\n",
    "# Â  Â  \"\"\"Membuat model peramalan sederhana untuk setiap fitur primer.\"\"\"\n",
    "\n",
    "# Â  Â  forecasters = {}\n",
    "\n",
    "# Â  Â  for col in primary_feature_cols:\n",
    "\n",
    "# Â  Â  Â  Â  try:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  # Menggunakan model ARIMA sederhana untuk setiap fitur\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  model = ARIMA(data[col], order=(2,1,1)).fit()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  forecasters[col] = model\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  logging.info(f\"Feature forecaster created for {col}\")\n",
    "\n",
    "# Â  Â  Â  Â  except Exception as e:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  logging.error(f\"Could not create forecaster for {col}: {e}\")\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  forecasters[col] = None # Jika gagal, akan menggunakan last value\n",
    "\n",
    "# Â  Â  return forecasters\n",
    "\n",
    "\n",
    "\n",
    "# def forecast_future(data, arima_stress_fit, model_lstm, le_student, feature_forecasters, timesteps=1, n_forecast=10, feature_cols=None, primary_feature_cols=None):\n",
    "\n",
    "# Â  Â  \"\"\"Meramalkan tingkat stres secara iteratif dengan meramalkan fitur inputnya juga.\"\"\"\n",
    "\n",
    "# Â  Â  logging.info(\"Memulai peramalan bertingkat yang dinamis...\")\n",
    "\n",
    "# Â  Â  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Â  Â  model_lstm.to(device).eval()\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  # Dapatkan prediksi dasar dari ARIMA untuk stres\n",
    "\n",
    "# Â  Â  arima_stress_forecast = arima_stress_fit.forecast(steps=n_forecast)\n",
    "\n",
    "# Â  Â  all_forecasts = []\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  for student_id in data['Student ID'].unique():\n",
    "\n",
    "# Â  Â  Â  Â  student_history = data[data['Student ID'] == student_id].copy().reset_index(drop=True)\n",
    "\n",
    "# Â  Â  Â  Â  student_id_encoded = le_student.transform([student_id])[0]\n",
    "\n",
    "Â  Â  Â  Â Â \n",
    "\n",
    "# Â  Â  Â  Â  student_future_predictions = []\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  Â  Â  # Dapatkan peramalan untuk semua fitur primer selama n_forecast hari\n",
    "\n",
    "# Â  Â  Â  Â  future_features_forecasts = {}\n",
    "\n",
    "# Â  Â  Â  Â  for col, forecaster in feature_forecasters.items():\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  if forecaster:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  future_features_forecasts[col] = forecaster.forecast(steps=n_forecast)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  else: # Fallback jika model fitur gagal dibuat\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  future_features_forecasts[col] = [student_history[col].iloc[-1]] * n_forecast\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  Â  Â  with torch.no_grad():\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  for i in range(n_forecast):\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  input_data = student_history.tail(timesteps)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  input_features_sequence = input_data[feature_cols].values.astype(np.float32)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  input_residuals_sequence = input_data['residual'].values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  input_aug = np.concatenate((input_features_sequence, input_residuals_sequence), axis=1)\n",
    "\n",
    "Â  Â  Â  Â  Â  Â  Â  Â Â \n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  current_sequence = torch.tensor(input_aug, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  current_id_tensor = torch.tensor([student_id_encoded], dtype=torch.long).to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  _, lstm_residual_pred = model_lstm(current_sequence, current_id_tensor)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  lstm_residual_pred = lstm_residual_pred.cpu().item()\n",
    "\n",
    "Â  Â  Â  Â  Â  Â  Â  Â Â \n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  final_stress_pred = arima_stress_forecast.iloc[i] + lstm_residual_pred\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  student_future_predictions.append(final_stress_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  # Buat baris baru dengan FITUR YANG SUDAH DIRAMALKAN\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  new_row_data = {\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Date': student_history['Date'].iloc[-1] + pd.DateOffset(days=1),\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Student ID': student_id,\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Student ID Encoded': student_id_encoded,\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Stress Level (GSR)': final_stress_pred,\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'residual': lstm_residual_pred,\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  }\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  # Masukkan nilai fitur yang sudah diramalkan untuk hari ke-i\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  for col in primary_feature_cols:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_row_data[col] = future_features_forecasts[col].iloc[i] if hasattr(future_features_forecasts[col], 'iloc') else future_features_forecasts[col][i]\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  new_row_df = pd.DataFrame([new_row_data])\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  student_history = pd.concat([student_history, new_row_df], ignore_index=True)\n",
    "\n",
    "Â  Â  Â  Â  Â  Â  Â  Â Â \n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  # Hitung ulang fitur turunan\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  student_history['lag_1_stress'] = student_history['Stress Level (GSR)'].shift(1)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  student_history['lag_1_sleep'] = student_history['Sleep Hours'].shift(1)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  student_history['rolling_mean_stress'] = student_history['Stress Level (GSR)'].rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  student_history['rolling_std_stress'] = student_history['Stress Level (GSR)'].rolling(window=7, min_periods=1).std()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  student_history.ffill(inplace=True)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  student_history.bfill(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  Â  Â  forecast_dates = pd.to_datetime([data[data['Student ID']==student_id]['Date'].max() + pd.DateOffset(days=j) for j in range(1, n_forecast + 1)])\n",
    "\n",
    "# Â  Â  Â  Â  forecast_df_student = pd.DataFrame({'Date': forecast_dates, 'Student ID': student_id, 'Forecasted Stress Level': student_future_predictions})\n",
    "\n",
    "# Â  Â  Â  Â  all_forecasts.append(forecast_df_student)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  if not all_forecasts: return None\n",
    "\n",
    "# Â  Â  return pd.concat(all_forecasts, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "\n",
    "# # BAGIAN 3: FUNGSI UTAMA YANG MENGGABUNGKAN KEDUANYA\n",
    "\n",
    "# # =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# def predict_global(data, model_dir='hasil_model', timesteps=1):\n",
    "\n",
    "# Â  Â  setup_logging(model_dir)\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  required_cols = ['Student ID', 'Date', 'Stress Level (GSR)', 'Risk Level', 'Sleep Hours', 'Anxiety Level', 'Mood Score', 'Attendance Status (Data)', 'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']\n",
    "\n",
    "# Â  Â  primary_feature_cols = ['Sleep Hours', 'Anxiety Level', 'Mood Score', 'Attendance Status (Data)']\n",
    "\n",
    "# Â  Â  feature_cols = ['Sleep Hours', 'Anxiety Level', 'Mood Score', 'Attendance Status (Data)', 'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']\n",
    "\n",
    "# Â  Â  target_cols = ['Risk Level', 'Stress Level (GSR)']\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  if any(col not in data.columns for col in required_cols): raise ValueError(\"Kolom yang dibutuhkan hilang\")\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Â  Â  data = data.sort_values(by=['Student ID', 'Date']).reset_index(drop=True)\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  le_student = LabelEncoder()\n",
    "\n",
    "# Â  Â  data['Student ID Encoded'] = le_student.fit_transform(data['Student ID'])\n",
    "\n",
    "# Â  Â  with open(os.path.join(model_dir, 'label_encoder.pkl'), 'wb') as f: pickle.dump(le_student, f)\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  unique_dates = data['Date'].dt.date.unique()\n",
    "\n",
    "# Â  Â  if len(unique_dates) < 30: raise ValueError(f\"Tanggal unik tidak cukup: {len(unique_dates)}\")\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  train_dates, test_dates = unique_dates[:24], unique_dates[24:30]\n",
    "\n",
    "# Â  Â  train_data = data[data['Date'].dt.date.isin(train_dates)].copy().reset_index(drop=True)\n",
    "\n",
    "# Â  Â  test_data = data[data['Date'].dt.date.isin(test_dates)].copy().reset_index(drop=True)\n",
    "\n",
    "# Â  Â  if len(test_data) == 0 or len(train_data) == 0: raise ValueError(\"Data latih atau uji kosong\")\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  for col in feature_cols + target_cols:\n",
    "\n",
    "# Â  Â  Â  Â  for df in [train_data, test_data]:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  df[col] = pd.to_numeric(df[col], errors='coerce').astype(np.float32)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  df[col] = df.groupby('Student ID')[col].transform(lambda x: x.ffill().bfill()).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  # --- MEMBUAT PERAMAL FITUR (BARU) ---\n",
    "\n",
    "# Â  Â  print(\"Membuat model peramal untuk fitur-fitur primer...\")\n",
    "\n",
    "# Â  Â  feature_forecasters = create_feature_forecasters(train_data, primary_feature_cols)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  arima_train_size = int(len(train_data) * 0.8)\n",
    "\n",
    "# Â  Â  train_arima, val_arima = train_data.iloc[:arima_train_size], train_data.iloc[arima_train_size:]\n",
    "\n",
    "# Â  Â  best_params_arima, best_mae_arima = tune_arima(train_arima, val_arima)\n",
    "\n",
    "# Â  Â  print(f\"Parameter ARIMA global: {best_params_arima} dengan MAE: {best_mae_arima}\")\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  arima_stress_fit = ARIMA(train_data['Stress Level (GSR)'], order=best_params_arima).fit()\n",
    "\n",
    "# Â  Â  with open(os.path.join(model_dir, 'arima_stress_model.pkl'), 'wb') as f: pickle.dump(arima_stress_fit, f)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  arima_train_pred = arima_stress_fit.predict(start=0, end=len(train_data) - 1)\n",
    "\n",
    "# Â  Â  arima_test_pred = arima_stress_fit.forecast(steps=len(test_data))\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  data.loc[train_data.index, 'residual'] = train_data['Stress Level (GSR)'].values - arima_train_pred.values\n",
    "\n",
    "# Â  Â  data.loc[test_data.index, 'residual'] = test_data['Stress Level (GSR)'].values - arima_test_pred.values\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  train_values = train_data[feature_cols + target_cols].values\n",
    "\n",
    "# Â  Â  test_values = test_data[feature_cols + target_cols].values\n",
    "\n",
    "# Â  Â  train_student_ids = train_data['Student ID Encoded'].values\n",
    "\n",
    "# Â  Â  test_student_ids = test_data['Student ID Encoded'].values\n",
    "\n",
    "# Â  Â  X_train, X_train_ids, y_train = create_sequences(train_values, train_student_ids, target_cols, timesteps)\n",
    "\n",
    "# Â  Â  X_test, X_test_ids, y_test = create_sequences(test_values, test_student_ids, target_cols, timesteps)\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  residual_train_seq = data.loc[train_data.index[timesteps:], 'residual'].values[:len(X_train)].astype(np.float32)\n",
    "\n",
    "# Â  Â  residual_test_seq = data.loc[test_data.index[timesteps:], 'residual'].values[:len(X_test)].astype(np.float32)\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  X_train_aug = np.concatenate((X_train[:, :, :-2], residual_train_seq.reshape(len(X_train), 1, 1).repeat(timesteps, axis=1)), axis=2).astype(np.float32)\n",
    "\n",
    "# Â  Â  X_test_aug = np.concatenate((X_test[:, :, :-2], residual_test_seq.reshape(len(X_test), 1, 1).repeat(timesteps, axis=1)), axis=2).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Â  Â  best_params_lstm = tune_lstm(torch.tensor(X_train_aug).to(device), torch.tensor(X_train_ids).to(device), torch.tensor(y_train[:, 0], dtype=torch.long).to(device), torch.tensor(residual_train_seq).to(device), timesteps, len(le_student.classes_), device)\n",
    "\n",
    "# Â  Â  print(f\"Parameter LSTM Terbaik: {best_params_lstm}\")\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  model_lstm = LSTMModel(input_dim=X_train_aug.shape[2], num_students=len(le_student.classes_), embed_dim=best_params_lstm['embed_dim'], hidden_dim=best_params_lstm['hidden_dim'], timesteps=timesteps, dropout_rate=best_params_lstm['dropout_rate']).to(device)\n",
    "\n",
    "# Â  Â  optimizer = torch.optim.Adam(model_lstm.parameters(), lr=best_params_lstm['lr'], weight_decay=1e-5)\n",
    "\n",
    "# Â  Â  train_dataset = TensorDataset(torch.tensor(X_train_aug), torch.tensor(X_train_ids), torch.tensor(y_train[:, 0], dtype=torch.long), torch.tensor(residual_train_seq))\n",
    "\n",
    "# Â  Â  train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Â  Â  for epoch in range(50):\n",
    "\n",
    "# Â  Â  Â  Â  model_lstm.train()\n",
    "\n",
    "# Â  Â  Â  Â  for batch_x, batch_ids, batch_y_risk, batch_y_residual in train_loader:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  optimizer.zero_grad()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  risk_logits, residual_pred = model_lstm(batch_x, batch_ids)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  loss = best_params_lstm['risk_weight'] * nn.CrossEntropyLoss()(risk_logits, batch_y_risk) + nn.MSELoss()(residual_pred, batch_y_residual)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  loss.backward()\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  optimizer.step()\n",
    "\n",
    "# Â  Â  torch.save(model_lstm.state_dict(), os.path.join(model_dir, 'lstm_model.pth'))\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  model_lstm.eval()\n",
    "\n",
    "# Â  Â  with torch.no_grad():\n",
    "\n",
    "# Â  Â  Â  Â  lstm_residual_pred = model_lstm(torch.tensor(X_test_aug).to(device), torch.tensor(X_test_ids).to(device))[1].cpu().numpy()\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  arima_test_pred_aligned = arima_test_pred.values[timesteps:][:len(lstm_residual_pred)]\n",
    "\n",
    "# Â  Â  hybrid_test_pred = arima_test_pred_aligned + lstm_residual_pred\n",
    "\n",
    "# Â  Â  y_true_test = y_test[:, -1]\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  hybrid_mae = mean_absolute_error(y_true_test, hybrid_test_pred)\n",
    "\n",
    "# Â  Â  hybrid_rmse = np.sqrt(mean_squared_error(y_true_test, hybrid_test_pred))\n",
    "\n",
    "# Â  Â  hybrid_mape = mean_absolute_percentage_error(y_true_test, hybrid_test_pred)\n",
    "\n",
    "# Â  Â  print(f\"Kinerja Hybrid ARIMA-LSTM:\\n - MAE: {hybrid_mae:.4f}\\n - RMSE: {hybrid_rmse:.4f}\\n - MAPE: {hybrid_mape:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  test_dates_for_df = test_data['Date'].iloc[timesteps:].iloc[:len(y_true_test)]\n",
    "\n",
    "# Â  Â  test_student_ids_for_df = test_data['Student ID'].iloc[timesteps:].iloc[:len(y_true_test)]\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  predictions_df = pd.DataFrame({'Date': test_dates_for_df, 'Student ID': test_student_ids_for_df, 'Predicted Stress Level': hybrid_test_pred, 'Actual Stress Level': y_true_test})\n",
    "\n",
    "Â  Â Â \n",
    "\n",
    "# Â  Â  # Memanggil fungsi peramalan yang baru\n",
    "\n",
    "# Â  Â  future_forecasts = forecast_future(data, arima_stress_fit, model_lstm, le_student, feature_forecasters, timesteps, 10, feature_cols, primary_feature_cols)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  for student_id in data['Student ID'].unique():\n",
    "\n",
    "# Â  Â  Â  Â  plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Â  Â  Â  Â  student_actual_data = data[data['Student ID'] == student_id]\n",
    "\n",
    "# Â  Â  Â  Â  plt.plot(student_actual_data['Date'], student_actual_data['Stress Level (GSR)'], label='Actual Stress Level', color='blue', linestyle='-')\n",
    "\n",
    "# Â  Â  Â  Â  student_pred_data = predictions_df[predictions_df['Student ID'] == student_id]\n",
    "\n",
    "# Â  Â  Â  Â  if not student_pred_data.empty:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  plt.plot(student_pred_data['Date'], student_pred_data['Predicted Stress Level'], label='Hybrid ARIMA-LSTM Prediction', color='green', linestyle='--')\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  residuals = student_pred_data['Actual Stress Level'] - student_pred_data['Predicted Stress Level']\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  plt.plot(student_pred_data['Date'], residuals, label='Residuals', color='red', linestyle=':')\n",
    "\n",
    "# Â  Â  Â  Â  if future_forecasts is not None:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  student_forecast_data = future_forecasts[future_forecasts['Student ID'] == student_id]\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  if not student_pred_data.empty and not student_forecast_data.empty:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  last_pred_date = student_pred_data['Date'].iloc[-1]\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  last_pred_value = student_pred_data['Predicted Stress Level'].iloc[-1]\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  combined_forecast_dates = pd.concat([pd.Series(last_pred_date), student_forecast_data['Date']]).reset_index(drop=True)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  combined_forecast_values = pd.concat([pd.Series(last_pred_value), student_forecast_data['Forecasted Stress Level']]).reset_index(drop=True)\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  plt.plot(combined_forecast_dates, combined_forecast_values, color='green', linestyle='--')\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  Â  Â  plt.plot(student_forecast_data['Date'], student_forecast_data['Forecasted Stress Level'], color='orange', marker='o', linestyle='--', label='Forecast')\n",
    "\n",
    "# Â  Â  Â  Â  plt.title(f'Stress Level Prediction for Student {student_id}')\n",
    "\n",
    "# Â  Â  Â  Â  plt.xlabel('Date')\n",
    "\n",
    "# Â  Â  Â  Â  plt.ylabel('Stress Level (GSR)')\n",
    "\n",
    "# Â  Â  Â  Â  plt.legend()\n",
    "\n",
    "# Â  Â  Â  Â  plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Â  Â  Â  Â  plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# Â  Â  Â  Â  plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=3))\n",
    "\n",
    "# Â  Â  Â  Â  plt.gcf().autofmt_xdate(rotation=45)\n",
    "\n",
    "# Â  Â  Â  Â  plt.tight_layout()\n",
    "\n",
    "# Â  Â  Â  Â  plt.savefig(os.path.join(model_dir, f'prediction_and_forecast_student_{student_id}.png'))\n",
    "\n",
    "# Â  Â  Â  Â  plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  return {'mae_stress': hybrid_mae, 'rmse_stress': hybrid_rmse, 'mape_stress': hybrid_mape, 'predictions': predictions_df, 'future_forecasts': future_forecasts}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "# Â  Â  try:\n",
    "\n",
    "# Â  Â  Â  Â  data = pd.read_csv('dataset_baru.csv')\n",
    "\n",
    "# Â  Â  except FileNotFoundError:\n",
    "\n",
    "# Â  Â  Â  Â  print(\"Error: File 'dataset_baru.csv' tidak ditemukan.\")\n",
    "\n",
    "# Â  Â  Â  Â  exit()\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  start_time = time.time()\n",
    "\n",
    "# Â  Â  output_dir = 'hasil_model_stres_bertingkat'\n",
    "\n",
    "# Â  Â  metrics = predict_global(data, model_dir=output_dir)\n",
    "\n",
    "# Â  Â  end_time = time.time()\n",
    "\n",
    "# Â  Â  duration = end_time - start_time\n",
    "\n",
    "# Â  Â  hours, rem = divmod(duration, 3600)\n",
    "\n",
    "# Â  Â  minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "\n",
    "\n",
    "# Â  Â  print(f\"\\nWaktu Eksekusi: {int(hours)} jam, {int(minutes)} menit, {seconds:.2f} detik\")\n",
    "\n",
    "# Â  Â  if metrics:\n",
    "\n",
    "# Â  Â  Â  Â  print(f\"\\nMetrik Akhir (Hybrid ARIMA-LSTM pada Set Uji):\")\n",
    "\n",
    "# Â  Â  Â  Â  print(f\" - MAEÂ  (Tingkat Stres): {metrics['mae_stress']:.4f}\")\n",
    "\n",
    "# Â  Â  Â  Â  print(f\" - RMSE (Tingkat Stres): {metrics['rmse_stress']:.4f}\")\n",
    "\n",
    "# Â  Â  Â  Â  print(f\" - MAPE (Tingkat Stres): {metrics['mape_stress']:.2f}%\")\n",
    "\n",
    "# Â  Â  Â  Â  if metrics['future_forecasts'] is not None:\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  print(\"\\nPeramalan Masa Depan Dinamis (Contoh):\")\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  print(metrics['future_forecasts'].head())\n",
    "\n",
    "# Â  Â  Â  Â  Â  Â  print(f\"\\nGrafik prediksi dan peramalan terpadu telah disimpan di folder '{output_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d04c6-12c5-4cb6-898b-6d958abb1c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

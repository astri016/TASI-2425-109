{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980dab00-9b65-4439-abf4-0b6c47fc9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAFTAR lIBRARY\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import optuna\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, confusion_matrix\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from uuid import uuid4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c251f67f-09a7-4a5e-9df6-0b201a7e82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('student_monnitoring_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58619fa-b908-4c1b-842e-511598e0ea1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>4.56</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>3.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>3.93</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>9:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>1.30</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.07</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.67</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.99</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>500</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>9:00-16:00</td>\n",
       "      <td>Present</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Student ID        Date   Class Time Attendance Status  \\\n",
       "0               1  2024-12-01   9:00-15:00              Late   \n",
       "1               1  2024-12-02   8:00-16:00              Late   \n",
       "2               1  2024-12-03  11:00-14:00              Late   \n",
       "3               1  2024-12-04  11:00-16:00              Late   \n",
       "4               1  2024-12-05   9:00-13:00            Absent   \n",
       "...           ...         ...          ...               ...   \n",
       "14995         500  2024-12-26   9:00-16:00              Late   \n",
       "14996         500  2024-12-27   9:00-15:00            Absent   \n",
       "14997         500  2024-12-28  11:00-14:00            Absent   \n",
       "14998         500  2024-12-29  11:00-14:00              Late   \n",
       "14999         500  2024-12-30   9:00-16:00           Present   \n",
       "\n",
       "       Stress Level (GSR)  Sleep Hours  Anxiety Level  Mood Score Risk Level  \n",
       "0                    0.92          7.6              6           6        Low  \n",
       "1                    1.17          6.0              6           2     Medium  \n",
       "2                    4.56          6.3              4           8       High  \n",
       "3                    3.07          9.0              2          10        Low  \n",
       "4                    3.93          7.4              9           4       High  \n",
       "...                   ...          ...            ...         ...        ...  \n",
       "14995                1.30          7.2              7          10        Low  \n",
       "14996                1.07          7.9              4           6       High  \n",
       "14997                1.67          7.2              3           5       High  \n",
       "14998                0.99          7.2             10           9     Medium  \n",
       "14999                4.50          5.2              1           4       High  \n",
       "\n",
       "[15000 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Student ID          15000 non-null  int64  \n",
      " 1   Date                15000 non-null  object \n",
      " 2   Class Time          15000 non-null  object \n",
      " 3   Attendance Status   15000 non-null  object \n",
      " 4   Stress Level (GSR)  15000 non-null  float64\n",
      " 5   Sleep Hours         15000 non-null  float64\n",
      " 6   Anxiety Level       15000 non-null  int64  \n",
      " 7   Mood Score          15000 non-null  int64  \n",
      " 8   Risk Level          15000 non-null  object \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15000.00000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.50000</td>\n",
       "      <td>2.762538</td>\n",
       "      <td>6.996780</td>\n",
       "      <td>5.546867</td>\n",
       "      <td>5.471533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.34209</td>\n",
       "      <td>1.301927</td>\n",
       "      <td>1.150973</td>\n",
       "      <td>2.870323</td>\n",
       "      <td>2.868984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.75000</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.50000</td>\n",
       "      <td>2.760000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.25000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Student ID  Stress Level (GSR)   Sleep Hours  Anxiety Level  \\\n",
       "count  15000.00000        15000.000000  15000.000000   15000.000000   \n",
       "mean     250.50000            2.762538      6.996780       5.546867   \n",
       "std      144.34209            1.301927      1.150973       2.870323   \n",
       "min        1.00000            0.500000      5.000000       1.000000   \n",
       "25%      125.75000            1.640000      6.000000       3.000000   \n",
       "50%      250.50000            2.760000      7.000000       6.000000   \n",
       "75%      375.25000            3.900000      8.000000       8.000000   \n",
       "max      500.00000            5.000000      9.000000      10.000000   \n",
       "\n",
       "         Mood Score  \n",
       "count  15000.000000  \n",
       "mean       5.471533  \n",
       "std        2.868984  \n",
       "min        1.000000  \n",
       "25%        3.000000  \n",
       "50%        5.000000  \n",
       "75%        8.000000  \n",
       "max       10.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display((df))\n",
    "display(df.info())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c40d633-ff22-4370-be83-12fd9a111fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Missing Value pada setiap kolom:\n",
      "Student ID            0\n",
      "Date                  0\n",
      "Class Time            0\n",
      "Attendance Status     0\n",
      "Stress Level (GSR)    0\n",
      "Sleep Hours           0\n",
      "Anxiety Level         0\n",
      "Mood Score            0\n",
      "Risk Level            0\n",
      "dtype: int64\n",
      "\n",
      "Persentase Missing value pada setiap Kolim:\n",
      "Student ID            0.0\n",
      "Date                  0.0\n",
      "Class Time            0.0\n",
      "Attendance Status     0.0\n",
      "Stress Level (GSR)    0.0\n",
      "Sleep Hours           0.0\n",
      "Anxiety Level         0.0\n",
      "Mood Score            0.0\n",
      "Risk Level            0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Pengecekan Missing value pada setiap kolom\n",
    "missing_values = df.isna().sum()\n",
    "print(\"Jumlah Missing Value pada setiap kolom:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Pengecekan Presentasi Missing value per kolom\n",
    "missing_percentage = (df.isna().sum() / len(df)) * 100\n",
    "print(\"\\nPersentase Missing value pada setiap Kolim:\")\n",
    "print(missing_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9270f3a6-40b0-4555-a6aa-1963266fc757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected by Z-Score:\n",
      "Empty DataFrame\n",
      "Columns: [Student ID, Date, Class Time, Attendance Status, Stress Level (GSR), Sleep Hours, Anxiety Level, Mood Score, Risk Level]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Menghitung Z-Score untuk kolom-kolom numerik\n",
    "import numpy as np\n",
    "z_scores = zscore(df[['Stress Level (GSR)', 'Anxiety Level', 'Mood Score', 'Sleep Hours']])\n",
    "\n",
    "# Menyaring data dengan Z-Score > 3 atau < -3\n",
    "outliers_z = np.where(abs(z_scores) > 3)  # Menemukan posisi outlier berdasarkan Z-Score\n",
    "\n",
    "# Menampilkan data outlier berdasarkan Z-Score\n",
    "outliers_z_data = df.iloc[outliers_z[0]]\n",
    "print(\"Outliers detected by Z-Score:\")\n",
    "print(outliers_z_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fee54b8-9632-4157-b9de-be3f99104d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected by Z-Score per user:\n",
      "Empty DataFrame\n",
      "Columns: [Stress Level (GSR), Anxiety Level, Mood Score, Sleep Hours]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Menghitung Z-Score per user\n",
    "def calculate_zscore_per_user(df, columns):\n",
    "    outliers = []  # Untuk menyimpan hasil outlier per user\n",
    "    for user_id in df['Student ID'].unique():  # Loop melalui setiap user\n",
    "        user_data = df[df['Student ID'] == user_id][columns]\n",
    "        z_scores = zscore(user_data, axis=0)  # Menghitung Z-Score per kolom untuk user tertentu\n",
    "\n",
    "        # Mencari outlier untuk Z-Score > 3 atau < -3\n",
    "        outliers_for_user = user_data[(abs(z_scores) > 3).any(axis=1)]  # Filter baris dengan Z-Score > 3\n",
    "        outliers.append(outliers_for_user)\n",
    "\n",
    "    # Gabungkan semua outliers per user\n",
    "    return pd.concat(outliers)\n",
    "\n",
    "# Tentukan kolom yang ingin dianalisis (kolom numerik)\n",
    "columns_to_check = ['Stress Level (GSR)', 'Anxiety Level', 'Mood Score', 'Sleep Hours']\n",
    "\n",
    "# Temukan outliers untuk seluruh dataset\n",
    "outliers_z_data_per_user = calculate_zscore_per_user(df, columns_to_check)\n",
    "\n",
    "print(\"Outliers detected by Z-Score per user:\")\n",
    "print(outliers_z_data_per_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3249ab6-c8ad-4040-8891-2a05db87991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2024-12-01\n",
      "1   2024-12-02\n",
      "2   2024-12-03\n",
      "3   2024-12-04\n",
      "4   2024-12-05\n",
      "Name: Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Mengonversi kolom 'Date' menjadi format datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df['Date'].head())\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "df = df.sort_values(by=['Student ID', 'Date'])\n",
    "\n",
    "user_day_count = df.groupby('Student ID')['Date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a730061-cd44-418e-918f-b711d40a9256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>4.56</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>3.07</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>3.93</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late                0.92   \n",
       "1           1 2024-12-02   8:00-16:00              Late                1.17   \n",
       "2           1 2024-12-03  11:00-14:00              Late                4.56   \n",
       "3           1 2024-12-04  11:00-16:00              Late                3.07   \n",
       "4           1 2024-12-05   9:00-13:00            Absent                3.93   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0          7.6              6           6           1    1   \n",
       "1          6.0              6           2           2    2   \n",
       "2          6.3              4           8           0    3   \n",
       "3          9.0              2          10           1    4   \n",
       "4          7.4              9           4           0    5   \n",
       "\n",
       "   Attendance Status (Data)  \n",
       "0                         2  \n",
       "1                         2  \n",
       "2                         2  \n",
       "3                         2  \n",
       "4                         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label Encoding untuk Risk Level\n",
    "le = LabelEncoder()\n",
    "df['Risk Level'] = le.fit_transform(df['Risk Level'])\n",
    "\n",
    "\n",
    "# label Encoder Untuk ateendande Status\n",
    "attendance_mapping = {'Present': 0, 'Absent': 1, 'Late': 2}\n",
    "df['Attendance Status (Data)'] = df['Attendance Status'].map(attendance_mapping)\n",
    "df['Attendance Status (Data)'] = df['Attendance Status (Data)'].astype('Int64')\n",
    "df[['Attendance Status', 'Attendance Status (Data)']].head()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747cef87-3a89-49cc-b44b-761d50b06818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.350341</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late            0.093333   \n",
       "1           1 2024-12-02   8:00-16:00              Late            0.148889   \n",
       "2           1 2024-12-03  11:00-14:00              Late            0.902222   \n",
       "3           1 2024-12-04  11:00-16:00              Late            0.571111   \n",
       "4           1 2024-12-05   9:00-13:00            Absent            0.762222   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0     0.524113       0.555556    0.555556           1    1   \n",
       "1    -0.866061       0.555556    0.111111           2    2   \n",
       "2    -0.605403       0.333333    0.777778           0    3   \n",
       "3     1.740515       0.111111    1.000000           1    4   \n",
       "4     0.350341       0.888889    0.333333           0    5   \n",
       "\n",
       "   Attendance Status (Data)  \n",
       "0                         2  \n",
       "1                         2  \n",
       "2                         2  \n",
       "3                         2  \n",
       "4                         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Memilih kolom untuk Min-Max Scaling dan Standardization\n",
    "cols_min_max = ['Stress Level (GSR)', 'Anxiety Level', 'Mood Score']\n",
    "cols_standardize = ['Sleep Hours']\n",
    "\n",
    "# Membuat objek scaler untuk Min-Max dan Standardization\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Melakukan Min-Max Scaling pada kolom yang dipilih\n",
    "df[cols_min_max] = min_max_scaler.fit_transform(df[cols_min_max])\n",
    "\n",
    "# Melakukan Standardization pada kolom yang dipilih\n",
    "df[cols_standardize] = standard_scaler.fit_transform(df[cols_standardize])\n",
    "\n",
    "# Menampilkan hasil setelah scaling dan standardisasi\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e4bd196-1999-44e5-aef0-c58403f1abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "      <th>lag_1_stress</th>\n",
       "      <th>lag_1_sleep</th>\n",
       "      <th>rolling_mean_stress</th>\n",
       "      <th>rolling_std_stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.381481</td>\n",
       "      <td>0.451829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.350341</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.745185</td>\n",
       "      <td>0.166212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late            0.093333   \n",
       "1           1 2024-12-02   8:00-16:00              Late            0.148889   \n",
       "2           1 2024-12-03  11:00-14:00              Late            0.902222   \n",
       "3           1 2024-12-04  11:00-16:00              Late            0.571111   \n",
       "4           1 2024-12-05   9:00-13:00            Absent            0.762222   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0     0.524113       0.555556    0.555556           1    1   \n",
       "1    -0.866061       0.555556    0.111111           2    2   \n",
       "2    -0.605403       0.333333    0.777778           0    3   \n",
       "3     1.740515       0.111111    1.000000           1    4   \n",
       "4     0.350341       0.888889    0.333333           0    5   \n",
       "\n",
       "   Attendance Status (Data)  lag_1_stress  lag_1_sleep  rolling_mean_stress  \\\n",
       "0                         2           NaN          NaN                  NaN   \n",
       "1                         2      0.093333     0.524113                  NaN   \n",
       "2                         2      0.148889    -0.866061             0.381481   \n",
       "3                         2      0.902222    -0.605403             0.540741   \n",
       "4                         1      0.571111     1.740515             0.745185   \n",
       "\n",
       "   rolling_std_stress  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2            0.451829  \n",
       "3            0.377584  \n",
       "4            0.166212  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lag Features untuk Stress Level (GSR) dan Sleep Hours\n",
    "df['lag_1_stress'] = df.groupby('Student ID')['Stress Level (GSR)'].shift(1)\n",
    "df['lag_1_sleep'] = df.groupby('Student ID')['Sleep Hours'].shift(1)\n",
    "\n",
    "# Rolling Statistics untuk Stress Level (GSR) dengan window size 3 (misalnya 3 hari)\n",
    "df['rolling_mean_stress'] = df.groupby('Student ID')['Stress Level (GSR)'].rolling(window=3).mean().reset_index(0, drop=True)\n",
    "df['rolling_std_stress'] = df.groupby('Student ID')['Stress Level (GSR)'].rolling(window=3).std().reset_index(0, drop=True)\n",
    "\n",
    "# Menampilkan hasil setelah menambahkan lag features dan rolling statistics\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386eff1c-c31b-4de6-89fd-b7cd9136bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Fungsi untuk uji ADF pada setiap Student ID\n",
    "def check_stationarity(data, col):\n",
    "    result = adfuller(df[col].dropna())\n",
    "    return result[1]  # Mengembalikan p-value\n",
    "\n",
    "# Menguji stasioneritas untuk setiap Student ID\n",
    "p_values = df.groupby('Student ID').apply(lambda group: check_stationarity(group, 'Stress Level (GSR)'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b90567-b7e9-46f7-90f9-1996f155f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HASIL UJI STASIONERITAS =====\n",
      "Student ID yang STASIONER:\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]\n",
      "\n",
      "Student ID yang BELUM STASIONER:\n",
      "[6, 456]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Fungsi untuk mengecek stasioneritas\n",
    "def check_stationarity(data, col):\n",
    "    result = adfuller(data[col].dropna())\n",
    "    return result[1]  # Mengembalikan p-value\n",
    "\n",
    "# Fungsi untuk melakukan differencing\n",
    "def difference_data(data, col, d=1):\n",
    "    data_copy = data.copy()\n",
    "    for _ in range(d):\n",
    "        data_copy[col] = data_copy[col].diff()\n",
    "    return data_copy\n",
    "\n",
    "# Inisialisasi variabel\n",
    "stationary_ids = []\n",
    "non_stationary_ids = []\n",
    "p_values_initial = {}\n",
    "p_values_after_diff = {}\n",
    "df_processed = []\n",
    "\n",
    "# Loop per Student ID\n",
    "for student_id in df['Student ID'].unique():\n",
    "    data_sub = df[df['Student ID'] == student_id].copy()\n",
    "\n",
    "    # Cek stasioneritas awal\n",
    "    p_value = check_stationarity(data_sub, 'Stress Level (GSR)')\n",
    "    p_values_initial[student_id] = p_value\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        # Sudah stasioner\n",
    "        stationary_ids.append(student_id)\n",
    "        p_values_after_diff[student_id] = p_value\n",
    "    else:\n",
    "        # Belum stasioner, lakukan differencing pertama\n",
    "        data_sub = difference_data(data_sub, 'Stress Level (GSR)', d=1)\n",
    "        p_value = check_stationarity(data_sub, 'Stress Level (GSR)')\n",
    "        p_values_after_diff[student_id] = p_value\n",
    "\n",
    "        if p_value <= 0.05:\n",
    "            stationary_ids.append(student_id)\n",
    "        else:\n",
    "            # Lakukan differencing kedua\n",
    "            data_sub = difference_data(data_sub, 'Stress Level (GSR)', d=2)\n",
    "            p_value = check_stationarity(data_sub, 'Stress Level (GSR)')\n",
    "            p_values_after_diff[student_id] = p_value\n",
    "\n",
    "            if p_value <= 0.05:\n",
    "                stationary_ids.append(student_id)\n",
    "            else:\n",
    "                non_stationary_ids.append(student_id)\n",
    "\n",
    "    df_processed.append(data_sub)\n",
    "\n",
    "# Tampilkan daftar hasil akhir\n",
    "print(\"\\n===== HASIL UJI STASIONERITAS =====\")\n",
    "print(\"Student ID yang STASIONER:\")\n",
    "print(stationary_ids)\n",
    "\n",
    "print(\"\\nStudent ID yang BELUM STASIONER:\")\n",
    "print(non_stationary_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3058516e-9d11-4fd8-a631-5d040e0b3288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Class Time</th>\n",
       "      <th>Attendance Status</th>\n",
       "      <th>Stress Level (GSR)</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Anxiety Level</th>\n",
       "      <th>Mood Score</th>\n",
       "      <th>Risk Level</th>\n",
       "      <th>Day</th>\n",
       "      <th>Attendance Status (Data)</th>\n",
       "      <th>lag_1_stress</th>\n",
       "      <th>lag_1_sleep</th>\n",
       "      <th>rolling_mean_stress</th>\n",
       "      <th>rolling_std_stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>9:00-15:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>8:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.524113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-03</td>\n",
       "      <td>11:00-14:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.866061</td>\n",
       "      <td>0.381481</td>\n",
       "      <td>0.451829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-04</td>\n",
       "      <td>11:00-16:00</td>\n",
       "      <td>Late</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>-0.605403</td>\n",
       "      <td>0.540741</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>9:00-13:00</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.350341</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>1.740515</td>\n",
       "      <td>0.745185</td>\n",
       "      <td>0.166212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID       Date   Class Time Attendance Status  Stress Level (GSR)  \\\n",
       "0           1 2024-12-01   9:00-15:00              Late            0.093333   \n",
       "1           1 2024-12-02   8:00-16:00              Late            0.148889   \n",
       "2           1 2024-12-03  11:00-14:00              Late            0.902222   \n",
       "3           1 2024-12-04  11:00-16:00              Late            0.571111   \n",
       "4           1 2024-12-05   9:00-13:00            Absent            0.762222   \n",
       "\n",
       "   Sleep Hours  Anxiety Level  Mood Score  Risk Level  Day  \\\n",
       "0     0.524113       0.555556    0.555556           1    1   \n",
       "1    -0.866061       0.555556    0.111111           2    2   \n",
       "2    -0.605403       0.333333    0.777778           0    3   \n",
       "3     1.740515       0.111111    1.000000           1    4   \n",
       "4     0.350341       0.888889    0.333333           0    5   \n",
       "\n",
       "   Attendance Status (Data)  lag_1_stress  lag_1_sleep  rolling_mean_stress  \\\n",
       "0                         2           NaN          NaN                  NaN   \n",
       "1                         2      0.093333     0.524113                  NaN   \n",
       "2                         2      0.148889    -0.866061             0.381481   \n",
       "3                         2      0.902222    -0.605403             0.540741   \n",
       "4                         1      0.571111     1.740515             0.745185   \n",
       "\n",
       "   rolling_std_stress  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2            0.451829  \n",
       "3            0.377584  \n",
       "4            0.166212  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menggunakan interpolasi linear untuk mengisi NaN setelah differencing\n",
    "df[['Stress Level (GSR)', 'Sleep Hours', 'Anxiety Level', 'Mood Score',\n",
    "      'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']] = \\\n",
    "    df[['Stress Level (GSR)', 'Sleep Hours', 'Anxiety Level', 'Mood Score',\n",
    "          'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']].interpolate(method='linear')\n",
    "\n",
    "# Menampilkan data setelah interpolasi\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6dfb4b3-b100-4007-b21a-87b9d7ac0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== JUMLAH OBSERVASI PER STUDENT ID =====\n",
      "Student ID 1: 30 observasi\n",
      "Student ID 2: 30 observasi\n",
      "Student ID 3: 30 observasi\n",
      "Student ID 4: 30 observasi\n",
      "Student ID 5: 30 observasi\n",
      "Student ID 6: 30 observasi\n",
      "Student ID 7: 30 observasi\n",
      "Student ID 8: 30 observasi\n",
      "Student ID 9: 30 observasi\n",
      "Student ID 10: 30 observasi\n",
      "Student ID 11: 30 observasi\n",
      "Student ID 12: 30 observasi\n",
      "Student ID 13: 30 observasi\n",
      "Student ID 14: 30 observasi\n",
      "Student ID 15: 30 observasi\n",
      "Student ID 16: 30 observasi\n",
      "Student ID 17: 30 observasi\n",
      "Student ID 18: 30 observasi\n",
      "Student ID 19: 30 observasi\n",
      "Student ID 20: 30 observasi\n",
      "Student ID 21: 30 observasi\n",
      "Student ID 22: 30 observasi\n",
      "Student ID 23: 30 observasi\n",
      "Student ID 24: 30 observasi\n",
      "Student ID 25: 30 observasi\n",
      "Student ID 26: 30 observasi\n",
      "Student ID 27: 30 observasi\n",
      "Student ID 28: 30 observasi\n",
      "Student ID 29: 30 observasi\n",
      "Student ID 30: 30 observasi\n",
      "Student ID 31: 30 observasi\n",
      "Student ID 32: 30 observasi\n",
      "Student ID 33: 30 observasi\n",
      "Student ID 34: 30 observasi\n",
      "Student ID 35: 30 observasi\n",
      "Student ID 36: 30 observasi\n",
      "Student ID 37: 30 observasi\n",
      "Student ID 38: 30 observasi\n",
      "Student ID 39: 30 observasi\n",
      "Student ID 40: 30 observasi\n",
      "Student ID 41: 30 observasi\n",
      "Student ID 42: 30 observasi\n",
      "Student ID 43: 30 observasi\n",
      "Student ID 44: 30 observasi\n",
      "Student ID 45: 30 observasi\n",
      "Student ID 46: 30 observasi\n",
      "Student ID 47: 30 observasi\n",
      "Student ID 48: 30 observasi\n",
      "Student ID 49: 30 observasi\n",
      "Student ID 50: 30 observasi\n",
      "Student ID 51: 30 observasi\n",
      "Student ID 52: 30 observasi\n",
      "Student ID 53: 30 observasi\n",
      "Student ID 54: 30 observasi\n",
      "Student ID 55: 30 observasi\n",
      "Student ID 56: 30 observasi\n",
      "Student ID 57: 30 observasi\n",
      "Student ID 58: 30 observasi\n",
      "Student ID 59: 30 observasi\n",
      "Student ID 60: 30 observasi\n",
      "Student ID 61: 30 observasi\n",
      "Student ID 62: 30 observasi\n",
      "Student ID 63: 30 observasi\n",
      "Student ID 64: 30 observasi\n",
      "Student ID 65: 30 observasi\n",
      "Student ID 66: 30 observasi\n",
      "Student ID 67: 30 observasi\n",
      "Student ID 68: 30 observasi\n",
      "Student ID 69: 30 observasi\n",
      "Student ID 70: 30 observasi\n",
      "Student ID 71: 30 observasi\n",
      "Student ID 72: 30 observasi\n",
      "Student ID 73: 30 observasi\n",
      "Student ID 74: 30 observasi\n",
      "Student ID 75: 30 observasi\n",
      "Student ID 76: 30 observasi\n",
      "Student ID 77: 30 observasi\n",
      "Student ID 78: 30 observasi\n",
      "Student ID 79: 30 observasi\n",
      "Student ID 80: 30 observasi\n",
      "Student ID 81: 30 observasi\n",
      "Student ID 82: 30 observasi\n",
      "Student ID 83: 30 observasi\n",
      "Student ID 84: 30 observasi\n",
      "Student ID 85: 30 observasi\n",
      "Student ID 86: 30 observasi\n",
      "Student ID 87: 30 observasi\n",
      "Student ID 88: 30 observasi\n",
      "Student ID 89: 30 observasi\n",
      "Student ID 90: 30 observasi\n",
      "Student ID 91: 30 observasi\n",
      "Student ID 92: 30 observasi\n",
      "Student ID 93: 30 observasi\n",
      "Student ID 94: 30 observasi\n",
      "Student ID 95: 30 observasi\n",
      "Student ID 96: 30 observasi\n",
      "Student ID 97: 30 observasi\n",
      "Student ID 98: 30 observasi\n",
      "Student ID 99: 30 observasi\n",
      "Student ID 100: 30 observasi\n",
      "Student ID 101: 30 observasi\n",
      "Student ID 102: 30 observasi\n",
      "Student ID 103: 30 observasi\n",
      "Student ID 104: 30 observasi\n",
      "Student ID 105: 30 observasi\n",
      "Student ID 106: 30 observasi\n",
      "Student ID 107: 30 observasi\n",
      "Student ID 108: 30 observasi\n",
      "Student ID 109: 30 observasi\n",
      "Student ID 110: 30 observasi\n",
      "Student ID 111: 30 observasi\n",
      "Student ID 112: 30 observasi\n",
      "Student ID 113: 30 observasi\n",
      "Student ID 114: 30 observasi\n",
      "Student ID 115: 30 observasi\n",
      "Student ID 116: 30 observasi\n",
      "Student ID 117: 30 observasi\n",
      "Student ID 118: 30 observasi\n",
      "Student ID 119: 30 observasi\n",
      "Student ID 120: 30 observasi\n",
      "Student ID 121: 30 observasi\n",
      "Student ID 122: 30 observasi\n",
      "Student ID 123: 30 observasi\n",
      "Student ID 124: 30 observasi\n",
      "Student ID 125: 30 observasi\n",
      "Student ID 126: 30 observasi\n",
      "Student ID 127: 30 observasi\n",
      "Student ID 128: 30 observasi\n",
      "Student ID 129: 30 observasi\n",
      "Student ID 130: 30 observasi\n",
      "Student ID 131: 30 observasi\n",
      "Student ID 132: 30 observasi\n",
      "Student ID 133: 30 observasi\n",
      "Student ID 134: 30 observasi\n",
      "Student ID 135: 30 observasi\n",
      "Student ID 136: 30 observasi\n",
      "Student ID 137: 30 observasi\n",
      "Student ID 138: 30 observasi\n",
      "Student ID 139: 30 observasi\n",
      "Student ID 140: 30 observasi\n",
      "Student ID 141: 30 observasi\n",
      "Student ID 142: 30 observasi\n",
      "Student ID 143: 30 observasi\n",
      "Student ID 144: 30 observasi\n",
      "Student ID 145: 30 observasi\n",
      "Student ID 146: 30 observasi\n",
      "Student ID 147: 30 observasi\n",
      "Student ID 148: 30 observasi\n",
      "Student ID 149: 30 observasi\n",
      "Student ID 150: 30 observasi\n",
      "Student ID 151: 30 observasi\n",
      "Student ID 152: 30 observasi\n",
      "Student ID 153: 30 observasi\n",
      "Student ID 154: 30 observasi\n",
      "Student ID 155: 30 observasi\n",
      "Student ID 156: 30 observasi\n",
      "Student ID 157: 30 observasi\n",
      "Student ID 158: 30 observasi\n",
      "Student ID 159: 30 observasi\n",
      "Student ID 160: 30 observasi\n",
      "Student ID 161: 30 observasi\n",
      "Student ID 162: 30 observasi\n",
      "Student ID 163: 30 observasi\n",
      "Student ID 164: 30 observasi\n",
      "Student ID 165: 30 observasi\n",
      "Student ID 166: 30 observasi\n",
      "Student ID 167: 30 observasi\n",
      "Student ID 168: 30 observasi\n",
      "Student ID 169: 30 observasi\n",
      "Student ID 170: 30 observasi\n",
      "Student ID 171: 30 observasi\n",
      "Student ID 172: 30 observasi\n",
      "Student ID 173: 30 observasi\n",
      "Student ID 174: 30 observasi\n",
      "Student ID 175: 30 observasi\n",
      "Student ID 176: 30 observasi\n",
      "Student ID 177: 30 observasi\n",
      "Student ID 178: 30 observasi\n",
      "Student ID 179: 30 observasi\n",
      "Student ID 180: 30 observasi\n",
      "Student ID 181: 30 observasi\n",
      "Student ID 182: 30 observasi\n",
      "Student ID 183: 30 observasi\n",
      "Student ID 184: 30 observasi\n",
      "Student ID 185: 30 observasi\n",
      "Student ID 186: 30 observasi\n",
      "Student ID 187: 30 observasi\n",
      "Student ID 188: 30 observasi\n",
      "Student ID 189: 30 observasi\n",
      "Student ID 190: 30 observasi\n",
      "Student ID 191: 30 observasi\n",
      "Student ID 192: 30 observasi\n",
      "Student ID 193: 30 observasi\n",
      "Student ID 194: 30 observasi\n",
      "Student ID 195: 30 observasi\n",
      "Student ID 196: 30 observasi\n",
      "Student ID 197: 30 observasi\n",
      "Student ID 198: 30 observasi\n",
      "Student ID 199: 30 observasi\n",
      "Student ID 200: 30 observasi\n",
      "Student ID 201: 30 observasi\n",
      "Student ID 202: 30 observasi\n",
      "Student ID 203: 30 observasi\n",
      "Student ID 204: 30 observasi\n",
      "Student ID 205: 30 observasi\n",
      "Student ID 206: 30 observasi\n",
      "Student ID 207: 30 observasi\n",
      "Student ID 208: 30 observasi\n",
      "Student ID 209: 30 observasi\n",
      "Student ID 210: 30 observasi\n",
      "Student ID 211: 30 observasi\n",
      "Student ID 212: 30 observasi\n",
      "Student ID 213: 30 observasi\n",
      "Student ID 214: 30 observasi\n",
      "Student ID 215: 30 observasi\n",
      "Student ID 216: 30 observasi\n",
      "Student ID 217: 30 observasi\n",
      "Student ID 218: 30 observasi\n",
      "Student ID 219: 30 observasi\n",
      "Student ID 220: 30 observasi\n",
      "Student ID 221: 30 observasi\n",
      "Student ID 222: 30 observasi\n",
      "Student ID 223: 30 observasi\n",
      "Student ID 224: 30 observasi\n",
      "Student ID 225: 30 observasi\n",
      "Student ID 226: 30 observasi\n",
      "Student ID 227: 30 observasi\n",
      "Student ID 228: 30 observasi\n",
      "Student ID 229: 30 observasi\n",
      "Student ID 230: 30 observasi\n",
      "Student ID 231: 30 observasi\n",
      "Student ID 232: 30 observasi\n",
      "Student ID 233: 30 observasi\n",
      "Student ID 234: 30 observasi\n",
      "Student ID 235: 30 observasi\n",
      "Student ID 236: 30 observasi\n",
      "Student ID 237: 30 observasi\n",
      "Student ID 238: 30 observasi\n",
      "Student ID 239: 30 observasi\n",
      "Student ID 240: 30 observasi\n",
      "Student ID 241: 30 observasi\n",
      "Student ID 242: 30 observasi\n",
      "Student ID 243: 30 observasi\n",
      "Student ID 244: 30 observasi\n",
      "Student ID 245: 30 observasi\n",
      "Student ID 246: 30 observasi\n",
      "Student ID 247: 30 observasi\n",
      "Student ID 248: 30 observasi\n",
      "Student ID 249: 30 observasi\n",
      "Student ID 250: 30 observasi\n",
      "Student ID 251: 30 observasi\n",
      "Student ID 252: 30 observasi\n",
      "Student ID 253: 30 observasi\n",
      "Student ID 254: 30 observasi\n",
      "Student ID 255: 30 observasi\n",
      "Student ID 256: 30 observasi\n",
      "Student ID 257: 30 observasi\n",
      "Student ID 258: 30 observasi\n",
      "Student ID 259: 30 observasi\n",
      "Student ID 260: 30 observasi\n",
      "Student ID 261: 30 observasi\n",
      "Student ID 262: 30 observasi\n",
      "Student ID 263: 30 observasi\n",
      "Student ID 264: 30 observasi\n",
      "Student ID 265: 30 observasi\n",
      "Student ID 266: 30 observasi\n",
      "Student ID 267: 30 observasi\n",
      "Student ID 268: 30 observasi\n",
      "Student ID 269: 30 observasi\n",
      "Student ID 270: 30 observasi\n",
      "Student ID 271: 30 observasi\n",
      "Student ID 272: 30 observasi\n",
      "Student ID 273: 30 observasi\n",
      "Student ID 274: 30 observasi\n",
      "Student ID 275: 30 observasi\n",
      "Student ID 276: 30 observasi\n",
      "Student ID 277: 30 observasi\n",
      "Student ID 278: 30 observasi\n",
      "Student ID 279: 30 observasi\n",
      "Student ID 280: 30 observasi\n",
      "Student ID 281: 30 observasi\n",
      "Student ID 282: 30 observasi\n",
      "Student ID 283: 30 observasi\n",
      "Student ID 284: 30 observasi\n",
      "Student ID 285: 30 observasi\n",
      "Student ID 286: 30 observasi\n",
      "Student ID 287: 30 observasi\n",
      "Student ID 288: 30 observasi\n",
      "Student ID 289: 30 observasi\n",
      "Student ID 290: 30 observasi\n",
      "Student ID 291: 30 observasi\n",
      "Student ID 292: 30 observasi\n",
      "Student ID 293: 30 observasi\n",
      "Student ID 294: 30 observasi\n",
      "Student ID 295: 30 observasi\n",
      "Student ID 296: 30 observasi\n",
      "Student ID 297: 30 observasi\n",
      "Student ID 298: 30 observasi\n",
      "Student ID 299: 30 observasi\n",
      "Student ID 300: 30 observasi\n",
      "Student ID 301: 30 observasi\n",
      "Student ID 302: 30 observasi\n",
      "Student ID 303: 30 observasi\n",
      "Student ID 304: 30 observasi\n",
      "Student ID 305: 30 observasi\n",
      "Student ID 306: 30 observasi\n",
      "Student ID 307: 30 observasi\n",
      "Student ID 308: 30 observasi\n",
      "Student ID 309: 30 observasi\n",
      "Student ID 310: 30 observasi\n",
      "Student ID 311: 30 observasi\n",
      "Student ID 312: 30 observasi\n",
      "Student ID 313: 30 observasi\n",
      "Student ID 314: 30 observasi\n",
      "Student ID 315: 30 observasi\n",
      "Student ID 316: 30 observasi\n",
      "Student ID 317: 30 observasi\n",
      "Student ID 318: 30 observasi\n",
      "Student ID 319: 30 observasi\n",
      "Student ID 320: 30 observasi\n",
      "Student ID 321: 30 observasi\n",
      "Student ID 322: 30 observasi\n",
      "Student ID 323: 30 observasi\n",
      "Student ID 324: 30 observasi\n",
      "Student ID 325: 30 observasi\n",
      "Student ID 326: 30 observasi\n",
      "Student ID 327: 30 observasi\n",
      "Student ID 328: 30 observasi\n",
      "Student ID 329: 30 observasi\n",
      "Student ID 330: 30 observasi\n",
      "Student ID 331: 30 observasi\n",
      "Student ID 332: 30 observasi\n",
      "Student ID 333: 30 observasi\n",
      "Student ID 334: 30 observasi\n",
      "Student ID 335: 30 observasi\n",
      "Student ID 336: 30 observasi\n",
      "Student ID 337: 30 observasi\n",
      "Student ID 338: 30 observasi\n",
      "Student ID 339: 30 observasi\n",
      "Student ID 340: 30 observasi\n",
      "Student ID 341: 30 observasi\n",
      "Student ID 342: 30 observasi\n",
      "Student ID 343: 30 observasi\n",
      "Student ID 344: 30 observasi\n",
      "Student ID 345: 30 observasi\n",
      "Student ID 346: 30 observasi\n",
      "Student ID 347: 30 observasi\n",
      "Student ID 348: 30 observasi\n",
      "Student ID 349: 30 observasi\n",
      "Student ID 350: 30 observasi\n",
      "Student ID 351: 30 observasi\n",
      "Student ID 352: 30 observasi\n",
      "Student ID 353: 30 observasi\n",
      "Student ID 354: 30 observasi\n",
      "Student ID 355: 30 observasi\n",
      "Student ID 356: 30 observasi\n",
      "Student ID 357: 30 observasi\n",
      "Student ID 358: 30 observasi\n",
      "Student ID 359: 30 observasi\n",
      "Student ID 360: 30 observasi\n",
      "Student ID 361: 30 observasi\n",
      "Student ID 362: 30 observasi\n",
      "Student ID 363: 30 observasi\n",
      "Student ID 364: 30 observasi\n",
      "Student ID 365: 30 observasi\n",
      "Student ID 366: 30 observasi\n",
      "Student ID 367: 30 observasi\n",
      "Student ID 368: 30 observasi\n",
      "Student ID 369: 30 observasi\n",
      "Student ID 370: 30 observasi\n",
      "Student ID 371: 30 observasi\n",
      "Student ID 372: 30 observasi\n",
      "Student ID 373: 30 observasi\n",
      "Student ID 374: 30 observasi\n",
      "Student ID 375: 30 observasi\n",
      "Student ID 376: 30 observasi\n",
      "Student ID 377: 30 observasi\n",
      "Student ID 378: 30 observasi\n",
      "Student ID 379: 30 observasi\n",
      "Student ID 380: 30 observasi\n",
      "Student ID 381: 30 observasi\n",
      "Student ID 382: 30 observasi\n",
      "Student ID 383: 30 observasi\n",
      "Student ID 384: 30 observasi\n",
      "Student ID 385: 30 observasi\n",
      "Student ID 386: 30 observasi\n",
      "Student ID 387: 30 observasi\n",
      "Student ID 388: 30 observasi\n",
      "Student ID 389: 30 observasi\n",
      "Student ID 390: 30 observasi\n",
      "Student ID 391: 30 observasi\n",
      "Student ID 392: 30 observasi\n",
      "Student ID 393: 30 observasi\n",
      "Student ID 394: 30 observasi\n",
      "Student ID 395: 30 observasi\n",
      "Student ID 396: 30 observasi\n",
      "Student ID 397: 30 observasi\n",
      "Student ID 398: 30 observasi\n",
      "Student ID 399: 30 observasi\n",
      "Student ID 400: 30 observasi\n",
      "Student ID 401: 30 observasi\n",
      "Student ID 402: 30 observasi\n",
      "Student ID 403: 30 observasi\n",
      "Student ID 404: 30 observasi\n",
      "Student ID 405: 30 observasi\n",
      "Student ID 406: 30 observasi\n",
      "Student ID 407: 30 observasi\n",
      "Student ID 408: 30 observasi\n",
      "Student ID 409: 30 observasi\n",
      "Student ID 410: 30 observasi\n",
      "Student ID 411: 30 observasi\n",
      "Student ID 412: 30 observasi\n",
      "Student ID 413: 30 observasi\n",
      "Student ID 414: 30 observasi\n",
      "Student ID 415: 30 observasi\n",
      "Student ID 416: 30 observasi\n",
      "Student ID 417: 30 observasi\n",
      "Student ID 418: 30 observasi\n",
      "Student ID 419: 30 observasi\n",
      "Student ID 420: 30 observasi\n",
      "Student ID 421: 30 observasi\n",
      "Student ID 422: 30 observasi\n",
      "Student ID 423: 30 observasi\n",
      "Student ID 424: 30 observasi\n",
      "Student ID 425: 30 observasi\n",
      "Student ID 426: 30 observasi\n",
      "Student ID 427: 30 observasi\n",
      "Student ID 428: 30 observasi\n",
      "Student ID 429: 30 observasi\n",
      "Student ID 430: 30 observasi\n",
      "Student ID 431: 30 observasi\n",
      "Student ID 432: 30 observasi\n",
      "Student ID 433: 30 observasi\n",
      "Student ID 434: 30 observasi\n",
      "Student ID 435: 30 observasi\n",
      "Student ID 436: 30 observasi\n",
      "Student ID 437: 30 observasi\n",
      "Student ID 438: 30 observasi\n",
      "Student ID 439: 30 observasi\n",
      "Student ID 440: 30 observasi\n",
      "Student ID 441: 30 observasi\n",
      "Student ID 442: 30 observasi\n",
      "Student ID 443: 30 observasi\n",
      "Student ID 444: 30 observasi\n",
      "Student ID 445: 30 observasi\n",
      "Student ID 446: 30 observasi\n",
      "Student ID 447: 30 observasi\n",
      "Student ID 448: 30 observasi\n",
      "Student ID 449: 30 observasi\n",
      "Student ID 450: 30 observasi\n",
      "Student ID 451: 30 observasi\n",
      "Student ID 452: 30 observasi\n",
      "Student ID 453: 30 observasi\n",
      "Student ID 454: 30 observasi\n",
      "Student ID 455: 30 observasi\n",
      "Student ID 456: 30 observasi\n",
      "Student ID 457: 30 observasi\n",
      "Student ID 458: 30 observasi\n",
      "Student ID 459: 30 observasi\n",
      "Student ID 460: 30 observasi\n",
      "Student ID 461: 30 observasi\n",
      "Student ID 462: 30 observasi\n",
      "Student ID 463: 30 observasi\n",
      "Student ID 464: 30 observasi\n",
      "Student ID 465: 30 observasi\n",
      "Student ID 466: 30 observasi\n",
      "Student ID 467: 30 observasi\n",
      "Student ID 468: 30 observasi\n",
      "Student ID 469: 30 observasi\n",
      "Student ID 470: 30 observasi\n",
      "Student ID 471: 30 observasi\n",
      "Student ID 472: 30 observasi\n",
      "Student ID 473: 30 observasi\n",
      "Student ID 474: 30 observasi\n",
      "Student ID 475: 30 observasi\n",
      "Student ID 476: 30 observasi\n",
      "Student ID 477: 30 observasi\n",
      "Student ID 478: 30 observasi\n",
      "Student ID 479: 30 observasi\n",
      "Student ID 480: 30 observasi\n",
      "Student ID 481: 30 observasi\n",
      "Student ID 482: 30 observasi\n",
      "Student ID 483: 30 observasi\n",
      "Student ID 484: 30 observasi\n",
      "Student ID 485: 30 observasi\n",
      "Student ID 486: 30 observasi\n",
      "Student ID 487: 30 observasi\n",
      "Student ID 488: 30 observasi\n",
      "Student ID 489: 30 observasi\n",
      "Student ID 490: 30 observasi\n",
      "Student ID 491: 30 observasi\n",
      "Student ID 492: 30 observasi\n",
      "Student ID 493: 30 observasi\n",
      "Student ID 494: 30 observasi\n",
      "Student ID 495: 30 observasi\n",
      "Student ID 496: 30 observasi\n",
      "Student ID 497: 30 observasi\n",
      "Student ID 498: 30 observasi\n",
      "Student ID 499: 30 observasi\n",
      "Student ID 500: 30 observasi\n"
     ]
    }
   ],
   "source": [
    "# Menghitung jumlah observasi asli untuk setiap Student ID\n",
    "jumlah_observasi = df.groupby('Student ID').size()\n",
    "\n",
    "print(\"\\n===== JUMLAH OBSERVASI PER STUDENT ID =====\")\n",
    "for student_id, jumlah in jumlah_observasi.items():\n",
    "    print(f\"Student ID {student_id}: {jumlah} observasi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70301fa1-cbc1-4a2d-82ff-29e0267ae994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menyimpan dataset baru setelah preprocessing \n",
    "df.to_csv('dataset_baru.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46472597-61ec-437e-ac2f-9e9f7348b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEMULAI EKSPERIMEN: 1_Hybrid_NoAttn_FullFeatures\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 15:23:29,980] A new study created in memory with name: no-name-7c1cf55c-1266-4f24-8082-8e8526c63b49\n",
      "[I 2025-07-09 15:40:24,044] Trial 9 finished with value: 0.8210300207138062 and parameters: {'hidden_dim': 64, 'dropout_rate': 0.4987036546765926, 'lr': 0.007590430479735875, 'risk_weight': 1.945849032819175, 'embed_dim': 20}. Best is trial 9 with value: 0.8210300207138062.\n",
      "[I 2025-07-09 15:41:28,808] Trial 10 finished with value: 0.6541939377784729 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.23428870257605872, 'lr': 0.00018632033296342408, 'risk_weight': 1.348539465491759, 'embed_dim': 26}. Best is trial 10 with value: 0.6541939377784729.\n",
      "[I 2025-07-09 15:41:34,687] Trial 11 finished with value: 0.20377343893051147 and parameters: {'hidden_dim': 120, 'dropout_rate': 0.3149256470607706, 'lr': 0.0011410889437556008, 'risk_weight': 1.9646494152772715, 'embed_dim': 17}. Best is trial 11 with value: 0.20377343893051147.\n",
      "[I 2025-07-09 15:41:39,340] Trial 0 finished with value: 1.1239088773727417 and parameters: {'hidden_dim': 168, 'dropout_rate': 0.39813774389844836, 'lr': 0.00012989207083145683, 'risk_weight': 1.6967977994923684, 'embed_dim': 22}. Best is trial 11 with value: 0.20377343893051147.\n",
      "[I 2025-07-09 15:41:39,904] Trial 2 finished with value: 0.20930933952331543 and parameters: {'hidden_dim': 152, 'dropout_rate': 0.3241291649593567, 'lr': 0.007315965594447779, 'risk_weight': 1.9558302603455109, 'embed_dim': 22}. Best is trial 11 with value: 0.20377343893051147.\n",
      "[I 2025-07-09 15:41:52,259] Trial 13 finished with value: 0.6679422855377197 and parameters: {'hidden_dim': 136, 'dropout_rate': 0.4303490172119614, 'lr': 0.0006732484537005362, 'risk_weight': 1.6417457162388764, 'embed_dim': 20}. Best is trial 11 with value: 0.20377343893051147.\n",
      "[I 2025-07-09 15:41:53,534] Trial 6 finished with value: 0.9601789116859436 and parameters: {'hidden_dim': 224, 'dropout_rate': 0.33383934899940726, 'lr': 0.00016437784191424405, 'risk_weight': 1.496651465327398, 'embed_dim': 10}. Best is trial 11 with value: 0.20377343893051147.\n",
      "[I 2025-07-09 15:41:58,661] Trial 14 finished with value: 0.024459118023514748 and parameters: {'hidden_dim': 168, 'dropout_rate': 0.30267211019649876, 'lr': 0.0011351207386498265, 'risk_weight': 1.8304012646284398, 'embed_dim': 32}. Best is trial 14 with value: 0.024459118023514748.\n",
      "[I 2025-07-09 15:42:02,676] Trial 1 finished with value: 0.0108879953622818 and parameters: {'hidden_dim': 256, 'dropout_rate': 0.4002496828252633, 'lr': 0.0024870260556596677, 'risk_weight': 1.6105873247663571, 'embed_dim': 17}. Best is trial 1 with value: 0.0108879953622818.\n",
      "[I 2025-07-09 15:42:04,153] Trial 5 finished with value: 0.01425402332097292 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.37448193097329996, 'lr': 0.002276947114014007, 'risk_weight': 1.3199554676808214, 'embed_dim': 18}. Best is trial 1 with value: 0.0108879953622818.\n",
      "[I 2025-07-09 15:42:04,234] Trial 4 finished with value: 0.02078702300786972 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.21115251028864557, 'lr': 0.0025022280489338813, 'risk_weight': 1.4537202525644384, 'embed_dim': 14}. Best is trial 1 with value: 0.0108879953622818.\n",
      "[I 2025-07-09 15:42:06,253] Trial 8 finished with value: 0.7498980760574341 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.44103541100386834, 'lr': 0.009954028493580272, 'risk_weight': 1.0513151742768152, 'embed_dim': 48}. Best is trial 1 with value: 0.0108879953622818.\n",
      "[I 2025-07-09 15:42:08,979] Trial 12 finished with value: 0.7118310332298279 and parameters: {'hidden_dim': 216, 'dropout_rate': 0.4506084828696584, 'lr': 0.00016598139940665846, 'risk_weight': 1.1253726661964842, 'embed_dim': 26}. Best is trial 1 with value: 0.0108879953622818.\n",
      "[I 2025-07-09 15:42:10,284] Trial 7 finished with value: 0.05168944597244263 and parameters: {'hidden_dim': 208, 'dropout_rate': 0.4689433827027554, 'lr': 0.0008418000303972739, 'risk_weight': 1.368677909930462, 'embed_dim': 43}. Best is trial 1 with value: 0.0108879953622818.\n",
      "[I 2025-07-09 15:42:10,495] Trial 3 finished with value: 0.7333179712295532 and parameters: {'hidden_dim': 232, 'dropout_rate': 0.420244108659383, 'lr': 0.000313739400394778, 'risk_weight': 1.8476605907103723, 'embed_dim': 35}. Best is trial 1 with value: 0.0108879953622818.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- HASIL UNTUK: 1_Hybrid_NoAttn_FullFeatures ---\n",
      "  - MAE : 0.0458\n",
      "  - RMSE: 0.0573\n",
      "Waktu Eksekusi: 27.77 menit\n",
      "\n",
      "================================================================================\n",
      "MEMULAI EKSPERIMEN: 2_Hybrid_WithAttn_FullFeatures\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 15:51:14,051] A new study created in memory with name: no-name-6829198a-ff38-4b03-aacb-6ceb1c7fa0ed\n",
      "[I 2025-07-09 16:16:48,986] Trial 0 finished with value: 0.0565929189324379 and parameters: {'hidden_dim': 80, 'dropout_rate': 0.4281054335485103, 'lr': 0.0010845982754715004, 'risk_weight': 1.26508136521313, 'embed_dim': 36, 'num_heads': 4}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:17:00,915] Trial 3 finished with value: 0.386491984128952 and parameters: {'hidden_dim': 64, 'dropout_rate': 0.3858979122634386, 'lr': 0.004666302471622624, 'risk_weight': 1.1165191965988224, 'embed_dim': 26, 'num_heads': 2}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:17:03,966] Trial 11 finished with value: 0.16396038234233856 and parameters: {'hidden_dim': 64, 'dropout_rate': 0.3451849687563834, 'lr': 0.003942041307270116, 'risk_weight': 1.600962342603191, 'embed_dim': 26, 'num_heads': 4}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:17:34,859] Trial 9 finished with value: 0.2660914659500122 and parameters: {'hidden_dim': 104, 'dropout_rate': 0.20826119887438763, 'lr': 0.007216530893318177, 'risk_weight': 1.7208697898281076, 'embed_dim': 26, 'num_heads': 2}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:17:54,502] Trial 5 finished with value: 0.2554478347301483 and parameters: {'hidden_dim': 104, 'dropout_rate': 0.20380126106366558, 'lr': 0.0007664752585118702, 'risk_weight': 1.0387539317339352, 'embed_dim': 12, 'num_heads': 4}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:18:15,506] Trial 2 finished with value: 0.11503630876541138 and parameters: {'hidden_dim': 144, 'dropout_rate': 0.27956543832143066, 'lr': 0.006154447867657976, 'risk_weight': 1.453778663932013, 'embed_dim': 28, 'num_heads': 8}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:18:22,567] Trial 13 finished with value: 0.6482641696929932 and parameters: {'hidden_dim': 120, 'dropout_rate': 0.4221344997937452, 'lr': 0.000375166439585839, 'risk_weight': 1.0966721713181, 'embed_dim': 15, 'num_heads': 8}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:19:02,678] Trial 6 finished with value: 0.15926478803157806 and parameters: {'hidden_dim': 176, 'dropout_rate': 0.3864097093541706, 'lr': 0.0014428262929324115, 'risk_weight': 1.030694821503089, 'embed_dim': 15, 'num_heads': 2}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:19:18,965] Trial 1 finished with value: 0.39365360140800476 and parameters: {'hidden_dim': 184, 'dropout_rate': 0.2785237775282262, 'lr': 0.0016109013326634988, 'risk_weight': 1.3018506333497992, 'embed_dim': 14, 'num_heads': 8}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:19:40,586] Trial 7 finished with value: 0.06499751657247543 and parameters: {'hidden_dim': 248, 'dropout_rate': 0.3907943676063853, 'lr': 0.0016647715278923381, 'risk_weight': 1.324135510569557, 'embed_dim': 16, 'num_heads': 8}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:19:42,558] Trial 12 finished with value: 0.24264460802078247 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.45941757594531524, 'lr': 0.0058747248145029, 'risk_weight': 1.1047714199697678, 'embed_dim': 29, 'num_heads': 4}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:19:42,884] Trial 8 finished with value: 0.5885972380638123 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.25971706543601486, 'lr': 0.00011856294567440775, 'risk_weight': 1.1312925732640269, 'embed_dim': 37, 'num_heads': 2}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:19:45,791] Trial 14 finished with value: 0.6213827133178711 and parameters: {'hidden_dim': 200, 'dropout_rate': 0.2357831880253565, 'lr': 0.009622751996505124, 'risk_weight': 1.297168429172733, 'embed_dim': 38, 'num_heads': 2}. Best is trial 0 with value: 0.0565929189324379.\n",
      "[I 2025-07-09 16:19:50,427] Trial 10 finished with value: 0.022721102461218834 and parameters: {'hidden_dim': 240, 'dropout_rate': 0.4568448587889593, 'lr': 0.0009419447902826495, 'risk_weight': 0.8412529661582533, 'embed_dim': 33, 'num_heads': 8}. Best is trial 10 with value: 0.022721102461218834.\n",
      "[I 2025-07-09 16:19:52,591] Trial 4 finished with value: 0.8086803555488586 and parameters: {'hidden_dim': 256, 'dropout_rate': 0.3427161504146719, 'lr': 0.008614248784557537, 'risk_weight': 1.384789821896936, 'embed_dim': 20, 'num_heads': 2}. Best is trial 10 with value: 0.022721102461218834.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- HASIL UNTUK: 2_Hybrid_WithAttn_FullFeatures ---\n",
      "  - MAE : 0.0383\n",
      "  - RMSE: 0.0470\n",
      "Waktu Eksekusi: 38.60 menit\n",
      "\n",
      "================================================================================\n",
      "MEMULAI EKSPERIMEN: 3_Hybrid_WithAttn_ReducedFeatures\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 16:30:16,103] A new study created in memory with name: no-name-86cb0838-4a87-4bb7-97e8-06f6818c2423\n",
      "[I 2025-07-09 16:51:13,748] Trial 1 finished with value: 0.2510125935077667 and parameters: {'hidden_dim': 72, 'dropout_rate': 0.35778803028747935, 'lr': 0.002401608231850295, 'risk_weight': 1.3486756131642794, 'embed_dim': 17, 'num_heads': 8}. Best is trial 1 with value: 0.2510125935077667.\n",
      "[I 2025-07-09 16:51:22,789] Trial 13 finished with value: 0.13997648656368256 and parameters: {'hidden_dim': 80, 'dropout_rate': 0.3164274351884703, 'lr': 0.0021490508546645995, 'risk_weight': 1.8317256643008581, 'embed_dim': 48, 'num_heads': 8}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:51:39,584] Trial 5 finished with value: 0.3696882128715515 and parameters: {'hidden_dim': 80, 'dropout_rate': 0.42774375142811216, 'lr': 0.002930164264201446, 'risk_weight': 1.0341923358424308, 'embed_dim': 42, 'num_heads': 8}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:52:23,500] Trial 11 finished with value: 0.8010764122009277 and parameters: {'hidden_dim': 128, 'dropout_rate': 0.42865897097484185, 'lr': 0.0001046680595991426, 'risk_weight': 1.1395991958403968, 'embed_dim': 14, 'num_heads': 2}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:52:28,661] Trial 6 finished with value: 0.6358861327171326 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.32203190594236436, 'lr': 0.00140216127521343, 'risk_weight': 1.2344987817008257, 'embed_dim': 10, 'num_heads': 8}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:52:42,653] Trial 0 finished with value: 0.8363326787948608 and parameters: {'hidden_dim': 120, 'dropout_rate': 0.2142376077404424, 'lr': 0.000254139504416477, 'risk_weight': 1.4541520263297363, 'embed_dim': 33, 'num_heads': 8}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:52:50,994] Trial 2 finished with value: 0.8487870097160339 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.3592288635336065, 'lr': 0.00037772923738605085, 'risk_weight': 1.601161374715354, 'embed_dim': 31, 'num_heads': 2}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:53:15,728] Trial 9 finished with value: 0.7351921200752258 and parameters: {'hidden_dim': 176, 'dropout_rate': 0.4389128260554142, 'lr': 0.00022472066877449783, 'risk_weight': 1.1980900319900654, 'embed_dim': 34, 'num_heads': 4}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:53:23,846] Trial 10 finished with value: 0.6603001356124878 and parameters: {'hidden_dim': 176, 'dropout_rate': 0.4913430415711934, 'lr': 0.0006094726462304274, 'risk_weight': 1.4857222714452396, 'embed_dim': 29, 'num_heads': 8}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:53:26,250] Trial 3 finished with value: 0.7828114032745361 and parameters: {'hidden_dim': 176, 'dropout_rate': 0.30725381852854583, 'lr': 0.00046165587583922135, 'risk_weight': 1.9110738399994076, 'embed_dim': 36, 'num_heads': 8}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:53:34,993] Trial 14 finished with value: 0.7631962895393372 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.23583359855861621, 'lr': 0.00010893019432818334, 'risk_weight': 1.202032363562117, 'embed_dim': 43, 'num_heads': 2}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:53:44,076] Trial 8 finished with value: 0.6138617992401123 and parameters: {'hidden_dim': 240, 'dropout_rate': 0.3497656263634594, 'lr': 0.000589599117692077, 'risk_weight': 1.0341680054089495, 'embed_dim': 13, 'num_heads': 8}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:53:44,590] Trial 7 finished with value: 0.7929849028587341 and parameters: {'hidden_dim': 208, 'dropout_rate': 0.23612541807388457, 'lr': 0.00023034759415958443, 'risk_weight': 1.4959978047769833, 'embed_dim': 32, 'num_heads': 8}. Best is trial 13 with value: 0.13997648656368256.\n",
      "[I 2025-07-09 16:53:45,538] Trial 12 finished with value: 0.06677103787660599 and parameters: {'hidden_dim': 224, 'dropout_rate': 0.49641601008299546, 'lr': 0.0019637084806862276, 'risk_weight': 1.5117759207949488, 'embed_dim': 48, 'num_heads': 4}. Best is trial 12 with value: 0.06677103787660599.\n",
      "[I 2025-07-09 16:53:48,369] Trial 4 finished with value: 0.3887398838996887 and parameters: {'hidden_dim': 256, 'dropout_rate': 0.3123249158598684, 'lr': 0.006144842713748555, 'risk_weight': 0.837482082364105, 'embed_dim': 31, 'num_heads': 2}. Best is trial 12 with value: 0.06677103787660599.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- HASIL UNTUK: 3_Hybrid_WithAttn_ReducedFeatures ---\n",
      "  - MAE : 0.0404\n",
      "  - RMSE: 0.0487\n",
      "Waktu Eksekusi: 32.30 menit\n",
      "\n",
      "################################################################################\n",
      "SEMUA EKSPERIMEN SELESAI\n",
      "Total Waktu Eksekusi: 98.67 menit\n",
      "################################################################################\n",
      "Grafik perbandingan metrik disimpan di 'hasil_eksperimen_final_loss/comparison_metrics.png'\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 1: FUNGSI DAN KELAS MODEL\n",
    "# =============================================================================\n",
    "\n",
    "def setup_logging(model_dir, experiment_name):\n",
    "    \"\"\"Mengatur logging untuk menyimpan output ke file.\"\"\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    log_file = os.path.join(model_dir, f'log_{experiment_name}.log')\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "def create_sequences(data, student_ids, target_cols, timesteps=3):\n",
    "    \"\"\"Membuat sekuens data untuk model time series.\"\"\"\n",
    "    X, X_ids, y = [], [], []\n",
    "    for i in range(len(data) - timesteps):\n",
    "        X.append(data[i:i + timesteps])\n",
    "        X_ids.append(student_ids[i + timesteps])\n",
    "        y.append(data[i + timesteps, -len(target_cols):])\n",
    "    return np.array(X), np.array(X_ids), np.array(y)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Wrapper untuk nn.MultiheadAttention dari PyTorch.\"\"\"\n",
    "    def __init__(self, hidden_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert hidden_dim % num_heads == 0, \"hidden_dim must be divisible by num_heads\"\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, lstm_outputs):\n",
    "        attn_output, attn_weights = self.mha(lstm_outputs, lstm_outputs, lstm_outputs)\n",
    "        context_vector = attn_output[:, -1, :]\n",
    "        return context_vector, attn_weights.mean(dim=1)\n",
    "\n",
    "class LSTMAttentionModel(nn.Module):\n",
    "    \"\"\"Model LSTM yang diintegrasikan dengan Multi-Head Attention Mechanism.\"\"\"\n",
    "    def __init__(self, input_dim, num_students, embed_dim, hidden_dim, num_heads, timesteps=3, dropout_rate=0.4):\n",
    "        super(LSTMAttentionModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_students, embed_dim)\n",
    "        self.lstm = nn.LSTM(input_dim + embed_dim, hidden_dim, batch_first=True)\n",
    "        self.attention = MultiHeadAttention(hidden_dim, num_heads)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.risk_head = nn.Sequential(nn.Linear(hidden_dim, hidden_dim // 2), nn.ReLU(), nn.Dropout(dropout_rate - 0.1 if dropout_rate > 0.1 else 0.0), nn.Linear(hidden_dim // 2, 3))\n",
    "        self.fc_residual = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, student_ids):\n",
    "        if student_ids.ndim == 1: student_ids = student_ids.unsqueeze(1)\n",
    "        embed = self.embedding(student_ids.squeeze(1))\n",
    "        embed = embed.unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        x = torch.cat([x, embed], dim=2)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        context_vector, _ = self.attention(lstm_out)\n",
    "        out = self.bn(context_vector)\n",
    "        out = self.dropout(out)\n",
    "        risk_logits = self.risk_head(out)\n",
    "        residual_pred = self.fc_residual(out)\n",
    "        return risk_logits, residual_pred.squeeze(1)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"Model LSTM standar tanpa Attention Mechanism.\"\"\"\n",
    "    def __init__(self, input_dim, num_students, embed_dim, hidden_dim, timesteps=3, dropout_rate=0.4):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_students, embed_dim)\n",
    "        self.lstm = nn.LSTM(input_dim + embed_dim, hidden_dim, batch_first=True)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.risk_head = nn.Sequential(nn.Linear(hidden_dim, hidden_dim // 2), nn.ReLU(), nn.Dropout(dropout_rate - 0.1 if dropout_rate > 0.1 else 0.0), nn.Linear(hidden_dim // 2, 3))\n",
    "        self.fc_residual = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, student_ids):\n",
    "        if student_ids.ndim == 1: student_ids = student_ids.unsqueeze(1)\n",
    "        embed = self.embedding(student_ids.squeeze(1))\n",
    "        embed = embed.unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        x = torch.cat([x, embed], dim=2)\n",
    "        lstm_out, (h_n, _) = self.lstm(x)\n",
    "        last_hidden_state = h_n.squeeze(0)\n",
    "        out = self.bn(last_hidden_state)\n",
    "        out = self.dropout(out)\n",
    "        risk_logits = self.risk_head(out)\n",
    "        residual_pred = self.fc_residual(out)\n",
    "        return risk_logits, residual_pred.squeeze(1)\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 2: FUNGSI TUNING DAN PERAMALAN\n",
    "# =============================================================================\n",
    "\n",
    "# ### FUNGSI DIREVISI ###\n",
    "def tune_arima(train_data, p_range=range(0, 4), d_range=range(0, 3), q_range=range(0, 4)):\n",
    "    \"\"\"Mencari parameter ARIMA terbaik menggunakan time series cross-validation.\"\"\"\n",
    "    best_mae = float('inf')\n",
    "    # Inisialisasi dengan None untuk menunjukkan belum ada parameter terbaik yang ditemukan\n",
    "    best_params = None\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    # Membuat daftar semua kombinasi parameter untuk diiterasi\n",
    "    pdq = list(itertools.product(p_range, d_range, q_range))\n",
    "    \n",
    "    for order in pdq:\n",
    "        try:\n",
    "            mae_list = []\n",
    "            # Validasi silang untuk setiap kombinasi parameter\n",
    "            for train_index, val_index in tscv.split(train_data):\n",
    "                train_fold = train_data.iloc[train_index]\n",
    "                val_fold = train_data.iloc[val_index]\n",
    "                \n",
    "                # Hanya gunakan kolom target untuk ARIMA\n",
    "                model = ARIMA(train_fold['Stress Level (GSR)'], order=order).fit()\n",
    "                predictions = model.forecast(steps=len(val_fold))\n",
    "                mae = mean_absolute_error(val_fold['Stress Level (GSR)'], predictions)\n",
    "                mae_list.append(mae)\n",
    "            \n",
    "            mean_mae = np.mean(mae_list)\n",
    "            \n",
    "            # Jika MAE rata-rata lebih baik, perbarui parameter terbaik\n",
    "            if mean_mae < best_mae:\n",
    "                best_mae = mean_mae\n",
    "                best_params = order\n",
    "        except Exception:\n",
    "            # Lanjutkan ke kombinasi berikutnya jika terjadi error\n",
    "            continue\n",
    "            \n",
    "    # Jika tidak ada parameter yang ditemukan, kembalikan default yang aman\n",
    "    if best_params is None:\n",
    "        logging.warning(\"Grid search ARIMA tidak menemukan parameter yang valid. Menggunakan default (1,1,1).\")\n",
    "        return (1, 1, 1), best_mae\n",
    "        \n",
    "    return best_params, best_mae\n",
    "\n",
    "\n",
    "def find_best_arima_for_feature(series):\n",
    "    \"\"\"Mencari parameter ARIMA terbaik untuk satu fitur menggunakan AIC.\"\"\"\n",
    "    best_aic = float('inf')\n",
    "    best_order = None\n",
    "    \n",
    "    p_range = d_range = q_range = range(0, 3)  \n",
    "    pdq = list(itertools.product(p_range, d_range, q_range))\n",
    "    \n",
    "    for order in pdq:\n",
    "        try:\n",
    "            model = ARIMA(series, order=order, enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "            if model.aic < best_aic:\n",
    "                best_aic = model.aic\n",
    "                best_order = order\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    return best_order if best_order is not None else (1, 1, 1)\n",
    "\n",
    "def create_feature_forecasters(data, primary_feature_cols):\n",
    "    \"\"\"Membuat model peramalan untuk setiap fitur primer dengan mencari order ARIMA terbaik.\"\"\"\n",
    "    forecasters = {}\n",
    "    for col in primary_feature_cols:\n",
    "        logging.info(f\"Mencari order ARIMA terbaik untuk fitur: {col}...\")\n",
    "        try:\n",
    "            best_order = find_best_arima_for_feature(data[col])\n",
    "            logging.info(f\"Order ARIMA terbaik untuk {col} adalah {best_order}.\")\n",
    "            model = ARIMA(data[col], order=best_order).fit()\n",
    "            forecasters[col] = model\n",
    "            logging.info(f\"Feature forecaster dibuat untuk {col}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Tidak dapat membuat forecaster untuk {col}: {e}\")\n",
    "            forecasters[col] = None\n",
    "    return forecasters\n",
    "    \n",
    "def tune_lstm(X_train_tensor, X_train_ids_tensor, y_train_risk, y_train_residual, timesteps, num_students, device, use_attention):\n",
    "    \"\"\"Mencari hyperparameter terbaik untuk model LSTM menggunakan Optuna.\"\"\"\n",
    "    def objective(trial):\n",
    "        hidden_dim = trial.suggest_int('hidden_dim', 64, 256, step=8)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "        risk_weight = trial.suggest_float('risk_weight', 0.8, 2.0)\n",
    "        embed_dim = trial.suggest_int('embed_dim', 10, 50)\n",
    "        \n",
    "        if use_attention:\n",
    "            num_heads = trial.suggest_categorical('num_heads', [2, 4, 8])\n",
    "            model = LSTMAttentionModel(input_dim=X_train_tensor.shape[2], num_students=num_students, embed_dim=embed_dim, hidden_dim=hidden_dim, num_heads=num_heads, timesteps=timesteps, dropout_rate=dropout_rate).to(device)\n",
    "        else:\n",
    "            model = LSTMModel(input_dim=X_train_tensor.shape[2], num_students=num_students, embed_dim=embed_dim, hidden_dim=hidden_dim, timesteps=timesteps, dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        train_dataset = TensorDataset(X_train_tensor, X_train_ids_tensor, y_train_risk, y_train_residual)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(100):\n",
    "            for batch_x, batch_ids, batch_y_risk, batch_y_residual in train_loader:\n",
    "                batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                risk_logits, residual_pred = model(batch_x, batch_ids)\n",
    "                loss = risk_weight * nn.CrossEntropyLoss()(risk_logits, batch_y_risk) + nn.MSELoss()(residual_pred, batch_y_residual)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            risk_logits, residual_pred = model(X_train_tensor, X_train_ids_tensor)\n",
    "            final_loss = (risk_weight * nn.CrossEntropyLoss()(risk_logits, y_train_risk) + nn.MSELoss()(residual_pred, y_train_residual)).item()\n",
    "        return final_loss\n",
    "        \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=15, n_jobs=-1)\n",
    "    return study.best_params\n",
    "\n",
    "def forecast_future(data, arima_stress_fit, model_lstm, le_student, feature_forecasters, timesteps, n_forecast, feature_cols, primary_feature_cols):\n",
    "    \"\"\"Meramalkan tingkat stres secara iteratif.\"\"\"\n",
    "    logging.info(\"Memulai peramalan bertingkat yang dinamis...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_lstm.to(device).eval()\n",
    "\n",
    "    all_forecasts = []\n",
    "\n",
    "    for student_id in data['Student ID'].unique():\n",
    "        student_history = data[data['Student ID'] == student_id].copy().reset_index(drop=True)\n",
    "        if len(student_history) < timesteps:\n",
    "            continue\n",
    "            \n",
    "        student_id_encoded = le_student.transform([student_id])[0]\n",
    "        student_future_predictions = []\n",
    "        arima_forecasts = arima_stress_fit.get_forecast(steps=n_forecast).predicted_mean\n",
    "\n",
    "        future_features_forecasts = {}\n",
    "        for col, forecaster in feature_forecasters.items():\n",
    "            if forecaster:\n",
    "                future_features_forecasts[col] = forecaster.get_forecast(steps=n_forecast).predicted_mean\n",
    "            else:\n",
    "                future_features_forecasts[col] = pd.Series([student_history[col].iloc[-1]] * n_forecast, index=arima_forecasts.index)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(n_forecast):\n",
    "                input_data = student_history.tail(timesteps)\n",
    "                current_features_list = [col for col in feature_cols if col in input_data.columns]\n",
    "                \n",
    "                if len(current_features_list) != len(feature_cols):\n",
    "                    # This check might need refinement based on how you handle missing features in student_history\n",
    "                    # For now, it will break the loop if any feature is missing from the last 'timesteps' rows\n",
    "                    break\n",
    "\n",
    "                input_features_sequence = input_data[current_features_list].values.astype(np.float32)\n",
    "                input_residuals_sequence = input_data['residual'].values.astype(np.float32).reshape(-1, 1)\n",
    "                input_aug = np.concatenate((input_features_sequence, input_residuals_sequence), axis=1)\n",
    "                \n",
    "                current_sequence = torch.tensor(input_aug, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                current_id_tensor = torch.tensor([student_id_encoded], dtype=torch.long).to(device)\n",
    "\n",
    "                _, lstm_residual_pred = model_lstm(current_sequence, current_id_tensor)\n",
    "                lstm_residual_pred = lstm_residual_pred.cpu().item()\n",
    "                final_stress_pred = arima_forecasts.iloc[i] + lstm_residual_pred\n",
    "                student_future_predictions.append(final_stress_pred)\n",
    "\n",
    "                last_date = student_history['Date'].iloc[-1]\n",
    "                new_row_data = {\n",
    "                    'Date': last_date + pd.DateOffset(days=1),\n",
    "                    'Student ID': student_id,\n",
    "                    'Student ID Encoded': student_id_encoded,\n",
    "                    'Stress Level (GSR)': final_stress_pred,\n",
    "                    'residual': lstm_residual_pred,\n",
    "                }\n",
    "                for col in primary_feature_cols:\n",
    "                    new_row_data[col] = future_features_forecasts[col].iloc[i]\n",
    "\n",
    "                temp_df = pd.DataFrame([new_row_data])\n",
    "                student_history = pd.concat([student_history, temp_df], ignore_index=True)\n",
    "                student_history['lag_1_stress'] = student_history['Stress Level (GSR)'].shift(1)\n",
    "                if 'Sleep Hours' in student_history.columns:\n",
    "                    student_history['lag_1_sleep'] = student_history['Sleep Hours'].shift(1)\n",
    "                student_history['rolling_mean_stress'] = student_history['Stress Level (GSR)'].rolling(window=7, min_periods=1).mean()\n",
    "                student_history['rolling_std_stress'] = student_history['Stress Level (GSR)'].rolling(window=7, min_periods=1).std()\n",
    "                \n",
    "                student_history.ffill(inplace=True)\n",
    "                student_history.bfill(inplace=True)\n",
    "\n",
    "        if student_future_predictions:\n",
    "            forecast_dates = pd.to_datetime([data[data['Student ID']==student_id]['Date'].max() + pd.DateOffset(days=j) for j in range(1, len(student_future_predictions) + 1)])\n",
    "            forecast_df_student = pd.DataFrame({'Date': forecast_dates, 'Student ID': student_id, 'Forecasted Stress Level': student_future_predictions})\n",
    "            all_forecasts.append(forecast_df_student)\n",
    "\n",
    "    if not all_forecasts: return None\n",
    "    return pd.concat(all_forecasts, ignore_index=True)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 3: FUNGSI UTAMA EKSPERIMEN\n",
    "# =============================================================================\n",
    "\n",
    "def run_experiment(data, experiment_name, model_dir, feature_cols, primary_feature_cols, use_attention, timesteps=3):\n",
    "    \"\"\"Menjalankan satu siklus eksperimen penuh.\"\"\"\n",
    "    setup_logging(model_dir, experiment_name)\n",
    "    logging.info(f\"===== MEMULAI EKSPERIMEN: {experiment_name} =====\")\n",
    "    \n",
    "    data_exp = data.copy()\n",
    "    data_exp['Date'] = pd.to_datetime(data_exp['Date'])\n",
    "    data_exp = data_exp.sort_values(by=['Student ID', 'Date']).reset_index(drop=True)\n",
    "    \n",
    "    le_student = LabelEncoder()\n",
    "    data_exp['Student ID Encoded'] = le_student.fit_transform(data_exp['Student ID'])\n",
    "    with open(os.path.join(model_dir, f'label_encoder_{experiment_name}.pkl'), 'wb') as f: pickle.dump(le_student, f)\n",
    "    \n",
    "    unique_dates = sorted(data_exp['Date'].unique())\n",
    "    split_point = int(len(unique_dates) * 0.8)\n",
    "    train_dates, test_dates = unique_dates[:split_point], unique_dates[split_point:]\n",
    "    \n",
    "    train_data = data_exp[data_exp['Date'].isin(train_dates)].copy().reset_index(drop=True)\n",
    "    test_data = data_exp[data_exp['Date'].isin(test_dates)].copy().reset_index(drop=True)\n",
    "    \n",
    "    logging.info(f\"Data split: {len(train_data)} baris training, {len(test_data)} baris testing.\")\n",
    "    if len(test_data) == 0 or len(train_data) == 0: raise ValueError(\"Data latih atau uji kosong.\")\n",
    "\n",
    "    target_cols = ['Stress Level (GSR)']\n",
    "    for col in feature_cols + target_cols:\n",
    "        for df in [train_data, test_data]:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(np.float32)\n",
    "            df[col] = df.groupby('Student ID')[col].transform(lambda x: x.ffill().bfill())\n",
    "    train_data.fillna(train_data.mean(numeric_only=True), inplace=True)\n",
    "    test_data.fillna(train_data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    logging.info(\"Tuning dan melatih model ARIMA...\")\n",
    "    best_params_arima, _ = tune_arima(train_data)\n",
    "    logging.info(f\"Parameter ARIMA terbaik: {best_params_arima}\")\n",
    "    \n",
    "    arima_stress_fit = ARIMA(train_data['Stress Level (GSR)'], order=best_params_arima).fit()\n",
    "    with open(os.path.join(model_dir, f'arima_stress_model_{experiment_name}.pkl'), 'wb') as f: pickle.dump(arima_stress_fit, f)\n",
    "\n",
    "    train_data['residual'] = train_data['Stress Level (GSR)'] - arima_stress_fit.predict(start=train_data.index[0], end=train_data.index[-1])\n",
    "    test_forecast = arima_stress_fit.get_forecast(steps=len(test_data)).predicted_mean\n",
    "    test_data['residual'] = test_data['Stress Level (GSR)'].values - test_forecast.values\n",
    "    \n",
    "    train_values = train_data[feature_cols + target_cols].values\n",
    "    test_values = test_data[feature_cols + target_cols].values\n",
    "    train_student_ids = train_data['Student ID Encoded'].values\n",
    "    test_student_ids = test_data['Student ID Encoded'].values\n",
    "    X_train, X_train_ids, y_train = create_sequences(train_values, train_student_ids, target_cols, timesteps)\n",
    "    X_test, X_test_ids, y_test = create_sequences(test_values, test_student_ids, target_cols, timesteps)\n",
    "    \n",
    "    residual_train_seq = train_data.loc[timesteps:, 'residual'].values[:len(X_train)].astype(np.float32)\n",
    "    residual_test_seq = test_data.loc[timesteps:, 'residual'].values[:len(X_test)].astype(np.float32)\n",
    "    \n",
    "    X_train_aug = np.concatenate((X_train[:, :, :len(feature_cols)], residual_train_seq[:, np.newaxis, np.newaxis].repeat(timesteps, axis=1)), axis=2).astype(np.float32)\n",
    "    X_test_aug = np.concatenate((X_test[:, :, :len(feature_cols)], residual_test_seq[:, np.newaxis, np.newaxis].repeat(timesteps, axis=1)), axis=2).astype(np.float32)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f\"Tuning LSTM (use_attention={use_attention})...\")\n",
    "    \n",
    "    y_train_risk_tensor = torch.tensor(y_train[:, 0], dtype=torch.long).to(device)\n",
    "    y_train_residual_tensor = torch.tensor(residual_train_seq).to(device)\n",
    "    best_params_lstm = tune_lstm(torch.tensor(X_train_aug).to(device), torch.tensor(X_train_ids).to(device), y_train_risk_tensor, y_train_residual_tensor, timesteps, len(le_student.classes_), device, use_attention)\n",
    "    logging.info(f\"Parameter LSTM Terbaik: {best_params_lstm}\")\n",
    "\n",
    "    if use_attention:\n",
    "        model_lstm = LSTMAttentionModel(input_dim=X_train_aug.shape[2], num_students=len(le_student.classes_), embed_dim=best_params_lstm['embed_dim'], hidden_dim=best_params_lstm['hidden_dim'], num_heads=best_params_lstm['num_heads'], timesteps=timesteps, dropout_rate=best_params_lstm['dropout_rate']).to(device)\n",
    "    else:\n",
    "        model_lstm = LSTMModel(input_dim=X_train_aug.shape[2], num_students=len(le_student.classes_), embed_dim=best_params_lstm['embed_dim'], hidden_dim=best_params_lstm['hidden_dim'], timesteps=timesteps, dropout_rate=best_params_lstm['dropout_rate']).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model_lstm.parameters(), lr=best_params_lstm['lr'], weight_decay=1e-5)\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train_aug), torch.tensor(X_train_ids), torch.tensor(y_train[:, 0], dtype=torch.long), torch.tensor(residual_train_seq))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    logging.info(\"Memulai pelatihan akhir model LSTM...\")\n",
    "    # List to store loss values per epoch for plotting\n",
    "    epoch_losses = [] \n",
    "    for epoch in range(50):\n",
    "        model_lstm.train()\n",
    "        total_loss = 0\n",
    "        for batch_x, batch_ids, batch_y_risk, batch_y_residual in train_loader:\n",
    "            batch_x, batch_ids, batch_y_risk, batch_y_residual = batch_x.to(device), batch_ids.to(device), batch_y_risk.to(device), batch_y_residual.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            risk_logits, residual_pred = model_lstm(batch_x, batch_ids)\n",
    "            loss = best_params_lstm['risk_weight'] * nn.CrossEntropyLoss()(risk_logits, batch_y_risk) + nn.MSELoss()(residual_pred, batch_y_residual)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "        logging.info(f\"Epoch {epoch+1}/{50}, Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "    torch.save(model_lstm.state_dict(), os.path.join(model_dir, f'lstm_model_{experiment_name}.pth'))\n",
    "\n",
    "    # Save the epoch losses to a file for later plotting\n",
    "    with open(os.path.join(model_dir, f'lstm_training_losses_{experiment_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(epoch_losses, f)\n",
    "\n",
    "    model_lstm.eval()\n",
    "    with torch.no_grad():\n",
    "        lstm_residual_pred = model_lstm(torch.tensor(X_test_aug).to(device), torch.tensor(X_test_ids).to(device))[1].cpu().numpy()\n",
    "    \n",
    "    arima_test_pred_aligned = test_forecast.values[timesteps:][:len(lstm_residual_pred)]\n",
    "    hybrid_test_pred = arima_test_pred_aligned + lstm_residual_pred\n",
    "    y_true_test = y_test[:, -1]\n",
    "    \n",
    "    hybrid_mae = mean_absolute_error(y_true_test, hybrid_test_pred)\n",
    "    hybrid_rmse = np.sqrt(mean_squared_error(y_true_test, hybrid_test_pred))\n",
    "    logging.info(f\"Kinerja Hybrid {experiment_name}: MAE={hybrid_mae:.4f}, RMSE={hybrid_rmse:.4f}\")\n",
    "\n",
    "    logging.info(\"Membuat peramal fitur untuk peramalan masa depan...\")\n",
    "    full_historical_data = pd.concat([train_data, test_data]).sort_values('Date')\n",
    "    feature_forecasters = create_feature_forecasters(full_historical_data, primary_feature_cols)\n",
    "    \n",
    "    future_forecasts = forecast_future(full_historical_data, arima_stress_fit, model_lstm, le_student, feature_forecasters, timesteps, 10, feature_cols, primary_feature_cols)\n",
    "\n",
    "    logging.info(\"Membuat grafik...\")\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'Date': test_data['Date'].iloc[timesteps:].iloc[:len(y_true_test)], \n",
    "        'Student ID': test_data['Student ID'].iloc[timesteps:].iloc[:len(y_true_test)], \n",
    "        'Predicted Stress Level': hybrid_test_pred, \n",
    "        'Actual Stress Level': y_true_test\n",
    "    })\n",
    "\n",
    "    for student_id in data_exp['Student ID'].unique():\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        student_actual_data = data_exp[data_exp['Student ID'] == student_id]\n",
    "        plt.plot(student_actual_data['Date'], student_actual_data['Stress Level (GSR)'], label='Actual Stress Level', color='blue', linestyle='-')\n",
    "        \n",
    "        student_pred_data = predictions_df[predictions_df['Student ID'] == student_id]\n",
    "        if not student_pred_data.empty:\n",
    "            plt.plot(student_pred_data['Date'], student_pred_data['Predicted Stress Level'], label='Hybrid Prediction', color='green', linestyle='--')\n",
    "            residuals = student_pred_data['Actual Stress Level'] - student_pred_data['Predicted Stress Level']\n",
    "            plt.plot(student_pred_data['Date'], residuals, label='Residuals', color='red', linestyle=':')\n",
    "        \n",
    "        if future_forecasts is not None:\n",
    "            student_forecast_data = future_forecasts[future_forecasts['Student ID'] == student_id]\n",
    "            if not student_forecast_data.empty:\n",
    "                plt.plot(student_forecast_data['Date'], student_forecast_data['Forecasted Stress Level'], color='orange', marker='o', linestyle='--', label='Dynamic Forecast')\n",
    "        \n",
    "        plt.title(f'Stress Level Prediction for Student {student_id}\\nExperiment: {experiment_name}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Stress Level (GSR)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "        plt.gcf().autofmt_xdate(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(model_dir, f'plot_{experiment_name}_student_{student_id}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    logging.info(f\"===== EKSPERIMEN SELESAI: {experiment_name} =====\")\n",
    "    return {'mae_stress': hybrid_mae, 'rmse_stress': hybrid_rmse, 'epoch_losses': epoch_losses} # Return epoch_losses\n",
    "\n",
    "def plot_final_metrics(results, output_dir):\n",
    "    \"\"\"Membuat bar chart yang membandingkan metrik dari semua eksperimen.\"\"\"\n",
    "    experiment_names = list(results.keys())\n",
    "    mae_scores = [res['mae_stress'] for res in results.values()]\n",
    "    rmse_scores = [res['rmse_stress'] for res in results.values()]\n",
    "\n",
    "    x = np.arange(len(experiment_names))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    rects1 = ax.bar(x - width/2, mae_scores, width, label='MAE')\n",
    "    rects2 = ax.bar(x + width/2, rmse_scores, width, label='RMSE')\n",
    "\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title('Perbandingan Metrik Kinerja antar Eksperimen')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(experiment_names, rotation=25, ha=\"right\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax.bar_label(rects1, padding=3, fmt='%.4f')\n",
    "    ax.bar_label(rects2, padding=3, fmt='%.4f')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'comparison_metrics.png'))\n",
    "    plt.close()\n",
    "    print(f\"Grafik perbandingan metrik disimpan di '{output_dir}/comparison_metrics.png'\")\n",
    "\n",
    "def plot_loss_curves(all_results, output_dir):\n",
    "    \"\"\"Membuat grafik loss untuk setiap eksperimen.\"\"\"\n",
    "    logging.info(\"Membuat grafik kurva loss untuk setiap eksperimen...\")\n",
    "    for exp_name, metrics in all_results.items():\n",
    "        if 'epoch_losses' in metrics and metrics['epoch_losses']:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(metrics['epoch_losses'], label=f'{exp_name} Training Loss', color='purple')\n",
    "            plt.title(f'Training Loss Over Epochs for {exp_name}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'loss_curve_{exp_name}.png'))\n",
    "            plt.close()\n",
    "            logging.info(f\"Grafik kurva loss untuk {exp_name} disimpan di '{output_dir}/loss_curve_{exp_name}.png'\")\n",
    "        else:\n",
    "            logging.warning(f\"Tidak ada data loss ditemukan untuk eksperimen: {exp_name}\")\n",
    "\n",
    "# =============================================================================\n",
    "# BAGIAN 4: EKSEKUSI EKSPERIMEN\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data_main = pd.read_csv('dataset_baru.csv')\n",
    "        data_main['Date'] = pd.to_datetime(data_main['Date'])\n",
    "        data_main = data_main.sort_values(by=['Student ID', 'Date']).reset_index(drop=True)\n",
    "        data_main['lag_1_stress'] = data_main.groupby('Student ID')['Stress Level (GSR)'].shift(1)\n",
    "        data_main['lag_1_sleep'] = data_main.groupby('Student ID')['Sleep Hours'].shift(1)\n",
    "        data_main['rolling_mean_stress'] = data_main.groupby('Student ID')['Stress Level (GSR)'].rolling(window=7, min_periods=1).mean().reset_index(0,drop=True)\n",
    "        data_main['rolling_std_stress'] = data_main.groupby('Student ID')['Stress Level (GSR)'].rolling(window=7, min_periods=1).std().reset_index(0,drop=True)\n",
    "        data_main = data_main.groupby('Student ID').apply(lambda group: group.ffill().bfill()).reset_index(drop=True)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File 'dataset_baru.csv' tidak ditemukan.\")\n",
    "        exit()\n",
    "\n",
    "    features_full = ['Sleep Hours', 'Anxiety Level', 'Mood Score', 'lag_1_stress', 'lag_1_sleep', 'rolling_mean_stress', 'rolling_std_stress']\n",
    "    primary_features_full = ['Sleep Hours', 'Anxiety Level', 'Mood Score']\n",
    "    features_reduced = ['Anxiety Level', 'Mood Score', 'rolling_mean_stress']\n",
    "    primary_features_reduced = ['Anxiety Level', 'Mood Score']\n",
    "\n",
    "    base_output_dir = \"hasil_eksperimen_final\"\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "    experiments = [\n",
    "        {\"name\": \"1_Hybrid_NoAttn_FullFeatures\", \"dir\": os.path.join(base_output_dir, \"1_no_attn_full\"), \"features\": features_full, \"primary_features\": primary_features_full, \"use_attention\": False},\n",
    "        {\"name\": \"2_Hybrid_WithAttn_FullFeatures\", \"dir\": os.path.join(base_output_dir, \"2_with_attn_full\"), \"features\": features_full, \"primary_features\": primary_features_full, \"use_attention\": True},\n",
    "        {\"name\": \"3_Hybrid_WithAttn_ReducedFeatures\", \"dir\": os.path.join(base_output_dir, \"3_with_attn_reduced\"), \"features\": features_reduced, \"primary_features\": primary_features_reduced, \"use_attention\": True}\n",
    "    ]\n",
    "\n",
    "    total_start_time = time.time()\n",
    "    all_results = {}\n",
    "    \n",
    "    for exp in experiments:\n",
    "        print(f\"\\n{'='*80}\\nMEMULAI EKSPERIMEN: {exp['name']}\\n{'='*80}\")\n",
    "        exp_start_time = time.time()\n",
    "        results = run_experiment(data=data_main, experiment_name=exp['name'], model_dir=exp['dir'], feature_cols=exp['features'], primary_feature_cols=exp['primary_features'], use_attention=exp['use_attention'])\n",
    "        all_results[exp['name']] = results\n",
    "        exp_end_time = time.time()\n",
    "        duration = exp_end_time - exp_start_time\n",
    "        print(f\"--- HASIL UNTUK: {exp['name']} ---\")\n",
    "        if results:\n",
    "            print(f\"  - MAE : {results['mae_stress']:.4f}\")\n",
    "            print(f\"  - RMSE: {results['rmse_stress']:.4f}\")\n",
    "        print(f\"Waktu Eksekusi: {duration/60:.2f} menit\")\n",
    "        \n",
    "    total_duration = time.time() - total_start_time\n",
    "    print(f\"\\n{'#'*80}\\nSEMUA EKSPERIMEN SELESAI\\nTotal Waktu Eksekusi: {total_duration/60:.2f} menit\\n{'#'*80}\")\n",
    "    \n",
    "    if all_results:\n",
    "        plot_final_metrics(all_results, base_output_dir)\n",
    "        plot_loss_curves(all_results, base_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31456ce-53c4-48eb-a6ad-3581f8014264",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac5144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
